{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c5c0549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GAE,GCNConv,GATConv,SAGEConv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b318dbd7",
   "metadata": {},
   "source": [
    "1.导入数据、构图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bcf38eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hierarchical agglomerative clustering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>discipline topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data visualization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datadriven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4728</th>\n",
       "      <td>electronic waste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4729</th>\n",
       "      <td>environmentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4730</th>\n",
       "      <td>rat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4731</th>\n",
       "      <td>urban space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4732</th>\n",
       "      <td>online delivery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4733 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          0\n",
       "0                                       lda\n",
       "1     hierarchical agglomerative clustering\n",
       "2                          discipline topic\n",
       "3                        data visualization\n",
       "4                                datadriven\n",
       "...                                     ...\n",
       "4728                       electronic waste\n",
       "4729                       environmentalism\n",
       "4730                                    rat\n",
       "4731                            urban space\n",
       "4732                        online delivery\n",
       "\n",
       "[4733 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_data = pd.read_csv('E:\\\\GraphSAGE\\\\Scopus_2022_9_21_1\\\\net\\\\nodes_list.csv',header=None)\n",
    "nodes_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cc135eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>discipline topic</td>\n",
       "      <td>hierarchical agglomerative clustering</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>discipline topic</td>\n",
       "      <td>lda</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hierarchical agglomerative clustering</td>\n",
       "      <td>lda</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>citation pattern</td>\n",
       "      <td>data visualization</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>citation pattern</td>\n",
       "      <td>datadriven</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17278</th>\n",
       "      <td>archive</td>\n",
       "      <td>electronic text</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17279</th>\n",
       "      <td>archive</td>\n",
       "      <td>online delivery</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17280</th>\n",
       "      <td>electronic text</td>\n",
       "      <td>metadata</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17281</th>\n",
       "      <td>electronic text</td>\n",
       "      <td>online delivery</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17282</th>\n",
       "      <td>metadata</td>\n",
       "      <td>online delivery</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17283 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           0  \\\n",
       "0                           discipline topic   \n",
       "1                           discipline topic   \n",
       "2      hierarchical agglomerative clustering   \n",
       "3                           citation pattern   \n",
       "4                           citation pattern   \n",
       "...                                      ...   \n",
       "17278                                archive   \n",
       "17279                                archive   \n",
       "17280                        electronic text   \n",
       "17281                        electronic text   \n",
       "17282                               metadata   \n",
       "\n",
       "                                           1  2  \n",
       "0      hierarchical agglomerative clustering  1  \n",
       "1                                        lda  1  \n",
       "2                                        lda  1  \n",
       "3                         data visualization  1  \n",
       "4                                 datadriven  1  \n",
       "...                                      ... ..  \n",
       "17278                        electronic text  1  \n",
       "17279                        online delivery  1  \n",
       "17280                               metadata  1  \n",
       "17281                        online delivery  1  \n",
       "17282                        online delivery  1  \n",
       "\n",
       "[17283 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_data = pd.read_csv('E:\\\\GraphSAGE\\\\Scopus_2022_9_21_1\\\\net\\\\weighted_links.csv',header=None)\n",
    "edges_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b51079a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lda': 0,\n",
       " 'hierarchical agglomerative clustering': 1,\n",
       " 'discipline topic': 2,\n",
       " 'data visualization': 3,\n",
       " 'datadriven': 4,\n",
       " 'citation pattern': 5,\n",
       " 'hathi trust digital library': 6,\n",
       " 'potential tool development': 7,\n",
       " 'compute education': 8,\n",
       " 'liberal art compute': 9,\n",
       " 'liberal education': 10,\n",
       " 'coproduction': 11,\n",
       " 'climate change': 12,\n",
       " 'social science and humanity': 13,\n",
       " 'conceptual lens': 14,\n",
       " 'pest control technique': 15,\n",
       " 'agricultural improvement': 16,\n",
       " 'entomological investigation': 17,\n",
       " 'palaeography': 18,\n",
       " 'multidisciplinary collaboration': 19,\n",
       " 'computational mean': 20,\n",
       " 'humanity research': 21,\n",
       " 'bibliometric evaluation': 22,\n",
       " 'book review': 23,\n",
       " 'journal quality indicator': 24,\n",
       " 'lap': 25,\n",
       " 'library': 26,\n",
       " 'collaboration': 27,\n",
       " 'sustainability': 28,\n",
       " 'document': 29,\n",
       " 'use case': 30,\n",
       " 'activity theory': 31,\n",
       " 'compute community': 32,\n",
       " 'social science': 33,\n",
       " 'citation analysis': 34,\n",
       " 'isi': 35,\n",
       " 'internet outage': 36,\n",
       " 'disaster': 37,\n",
       " 'dependent': 38,\n",
       " 'interactive whiteboard': 39,\n",
       " 'creative teaching': 40,\n",
       " 'literacy': 41,\n",
       " 'mathematics': 42,\n",
       " 'wholeclass teaching': 43,\n",
       " 'safety argument deconstruction': 44,\n",
       " 'adversarial counterargument': 45,\n",
       " 'gsn': 46,\n",
       " 'annotation tool': 47,\n",
       " 'humanity compute': 48,\n",
       " 'online chopin variorum edition': 49,\n",
       " 'compute science': 50,\n",
       " 'digital scholarship': 51,\n",
       " 'cyberinfrastructure': 52,\n",
       " 'text creation partnership': 53,\n",
       " 'escience': 54,\n",
       " 'high performance computing tool': 55,\n",
       " 'frontend representation': 56,\n",
       " 'modern manuscript material': 57,\n",
       " 'corpus': 58,\n",
       " 'ancient french legend of roland': 59,\n",
       " 'xml semantic encoding': 60,\n",
       " 'information density': 61,\n",
       " 'history literary work': 62,\n",
       " 'longrange correlation': 63,\n",
       " 'human writing': 64,\n",
       " 'scholarly communication': 65,\n",
       " 'bibliometrics characteristic': 66,\n",
       " 'selfcitation ratio': 67,\n",
       " 'disciplinary turfpolity': 68,\n",
       " 'geopolitical metaphor': 69,\n",
       " 'operative conception': 70,\n",
       " 'feminist': 71,\n",
       " 'knowledge representation': 72,\n",
       " 'scholarly production model': 73,\n",
       " 'semantic markup': 74,\n",
       " 'database journal': 75,\n",
       " 'comparison': 76,\n",
       " 'manuscript review': 77,\n",
       " 'metric collection': 78,\n",
       " 'temporality effect': 79,\n",
       " 'literary': 80,\n",
       " 'text analysis': 81,\n",
       " 'time cognition': 82,\n",
       " 'computer science': 83,\n",
       " 'digital library': 84,\n",
       " 'ept': 85,\n",
       " 'dhi': 86,\n",
       " 'value chain': 87,\n",
       " 'project work': 88,\n",
       " 'virtual reality': 89,\n",
       " 'cultural history': 90,\n",
       " 'multiculture': 91,\n",
       " 'correlation': 92,\n",
       " 'literary text': 93,\n",
       " 'selfsimilarity': 94,\n",
       " 'additive markov chain': 95,\n",
       " 'longrange memory': 96,\n",
       " 'computer': 97,\n",
       " 'data processing': 98,\n",
       " 'gis': 99,\n",
       " 'cultural heritage': 100,\n",
       " 'digital resource': 101,\n",
       " 'historiography': 102,\n",
       " 'science and technology history': 103,\n",
       " 'tacit objectknowledge': 104,\n",
       " 'spatial data': 105,\n",
       " 'data analysis': 106,\n",
       " 'textual encoding': 107,\n",
       " 'stroke makeup': 108,\n",
       " 'roman text': 109,\n",
       " 'scientific literature': 110,\n",
       " 'associative concept': 111,\n",
       " 'concept space': 112,\n",
       " 'hebbian  information retrieval': 113,\n",
       " 'forensic linguistics': 114,\n",
       " 'tamper detection': 115,\n",
       " 'signal cutting identify': 116,\n",
       " 'text analysis tool': 117,\n",
       " 'critical analysis': 118,\n",
       " 'literary criticism': 119,\n",
       " 'public humanity program': 120,\n",
       " 'primitive set': 121,\n",
       " 'high education': 122,\n",
       " 'interdiscipline': 123,\n",
       " 'methodological': 124,\n",
       " 'exchange obstacle': 125,\n",
       " 'cooperation opportunity': 126,\n",
       " 'spectrum': 127,\n",
       " 'webtool': 128,\n",
       " 'internet resource': 129,\n",
       " 'university language learning': 130,\n",
       " 'implementation strategy': 131,\n",
       " 'ulysses': 132,\n",
       " 'text style': 133,\n",
       " 'multivariate statistic': 134,\n",
       " 'rom': 135,\n",
       " 'electronic text  enterprise': 136,\n",
       " 'information literacy': 137,\n",
       " 'key definition': 138,\n",
       " 'skill': 139,\n",
       " 'model': 140,\n",
       " 'limitation': 141,\n",
       " 'speculation': 142,\n",
       " 'science fiction  prediction': 143,\n",
       " 'textual feature overlap': 144,\n",
       " 'concurrent document hierarchy': 145,\n",
       " 'humanistic research': 146,\n",
       " 'thesaurus lingua graecae': 147,\n",
       " 'technological literacy': 148,\n",
       " 'education': 149,\n",
       " 'nonscience student': 150,\n",
       " 'large document': 151,\n",
       " 'indexing tool': 152,\n",
       " 'management technique': 153,\n",
       " 'routledge encyclopedia': 154,\n",
       " 'hypertext': 155,\n",
       " 'multisequential narrative': 156,\n",
       " 'little dorrit': 157,\n",
       " 'allcicch conference': 158,\n",
       " 'art': 159,\n",
       " 'british folklore collection': 160,\n",
       " 'student scholarship': 161,\n",
       " 'citation politics': 162,\n",
       " 'digital book': 163,\n",
       " 'postcolonial and decolonial approach': 164,\n",
       " 'physical rare book': 165,\n",
       " 'digital rare book': 166,\n",
       " 'visualization': 167,\n",
       " 'memory of german pow': 168,\n",
       " 'geographic information system': 169,\n",
       " 'memory culture': 170,\n",
       " 'information science': 171,\n",
       " 'deep neural network': 172,\n",
       " 'decision model': 173,\n",
       " 'indigenous': 174,\n",
       " 'margin group': 175,\n",
       " 'critical study': 176,\n",
       " 'ischool': 177,\n",
       " 'crossdisciplinary': 178,\n",
       " 'journal publication': 179,\n",
       " 'inscription': 180,\n",
       " 'parse and annotate corpus': 181,\n",
       " 'search system': 182,\n",
       " 'metadata': 183,\n",
       " 'political speech': 184,\n",
       " 'epigraph': 185,\n",
       " 'intertextual connection': 186,\n",
       " 'digital representation': 187,\n",
       " 'modernist study': 188,\n",
       " 'public humanity': 189,\n",
       " 'journal of cinema and medium study': 190,\n",
       " 'historic inequity': 191,\n",
       " 'humanitarian': 192,\n",
       " 'digitisation': 193,\n",
       " 'sovereign power': 194,\n",
       " 'digital sovereignty': 195,\n",
       " 'art and architectural history': 196,\n",
       " 'shanghai memory': 197,\n",
       " 'city history': 198,\n",
       " 'crowdsourcing': 199,\n",
       " 'motivation model': 200,\n",
       " 'psychologicalsociological model': 201,\n",
       " 'information mapping': 202,\n",
       " 'disinformation identify': 203,\n",
       " 'textual analysis': 204,\n",
       " 'digital documentation': 205,\n",
       " 'visualisation': 206,\n",
       " 'human digitalities': 207,\n",
       " 'occupational gender segregation': 208,\n",
       " 'language without gender': 209,\n",
       " 'gendered language': 210,\n",
       " 'textual analytics': 211,\n",
       " 'machine': 212,\n",
       " 'anthropocene': 213,\n",
       " 'archival document': 214,\n",
       " 'engineering historical memory': 215,\n",
       " 'social network analysis': 216,\n",
       " 'literary communication network': 217,\n",
       " 'cultural leverage': 218,\n",
       " 'poetry community': 219,\n",
       " 'environmental history': 220,\n",
       " 'environmental science': 221,\n",
       " 'heterogeneous text corpus': 222,\n",
       " 'digital history': 223,\n",
       " 'control vocabulary': 224,\n",
       " 'opensource data': 225,\n",
       " 'biographical profile': 226,\n",
       " 'freedom narrative': 227,\n",
       " 'streetonomics': 228,\n",
       " 'cultural quantification': 229,\n",
       " 'society value system': 230,\n",
       " 'conceptual model': 231,\n",
       " 'multimodal thesis and dissertation': 232,\n",
       " 'artificial intelligence': 233,\n",
       " 'crisisintervention': 234,\n",
       " 'paradise lose': 235,\n",
       " 'difference examing': 236,\n",
       " 'text annotation': 237,\n",
       " 'comedias sueltas usa': 238,\n",
       " 'sueltas': 239,\n",
       " 'special collection librarianship': 240,\n",
       " 'geolinguistic diversity': 241,\n",
       " 'language indifference': 242,\n",
       " 'face detection': 243,\n",
       " 'cluster analysis': 244,\n",
       " 'historical personage': 245,\n",
       " 'social relationship': 246,\n",
       " 'digital scholarly edition': 247,\n",
       " 'archive': 248,\n",
       " 'recontextualisation': 249,\n",
       " 'share task': 250,\n",
       " 'blaketint': 251,\n",
       " 'book history': 252,\n",
       " 'color analysis': 253,\n",
       " 'music': 254,\n",
       " 'new medium': 255,\n",
       " 'viral medium': 256,\n",
       " 'ethic': 257,\n",
       " 'ancient china': 258,\n",
       " 'humanist': 259,\n",
       " 'china': 260,\n",
       " 'digital academic competence': 261,\n",
       " 'ground theory': 262,\n",
       " 'competence evaluation indicator system': 263,\n",
       " 'database development': 264,\n",
       " 'text mining': 265,\n",
       " 'chinese local private document': 266,\n",
       " 'historical philology': 267,\n",
       " 'education  datasets': 268,\n",
       " 'analytical tool': 269,\n",
       " 'laboratory': 270,\n",
       " 'natural hazard': 271,\n",
       " 'technological system': 272,\n",
       " 'infrastructure': 273,\n",
       " 'historical poetics': 274,\n",
       " 'definition of epic': 275,\n",
       " 'ming dynasty': 276,\n",
       " 'geographical visualization': 277,\n",
       " 'knowledge organization': 278,\n",
       " 'ontology': 279,\n",
       " 'historical event': 280,\n",
       " 'chinese oral memory': 281,\n",
       " 'knowledge linkage': 282,\n",
       " 'hermeneutics': 283,\n",
       " 'algorithm': 284,\n",
       " 'romantic disciplinarity': 285,\n",
       " 'african study': 286,\n",
       " 'culture sustainable development': 287,\n",
       " 'memory map': 288,\n",
       " 'urban memory': 289,\n",
       " 'knowledge map': 290,\n",
       " 'beijing city gate': 291,\n",
       " 'evolution': 292,\n",
       " 'historical analysis': 293,\n",
       " 'bibliometrics': 294,\n",
       " 'scholarly common': 295,\n",
       " 'beijing normal university': 296,\n",
       " 'historical scholarship': 297,\n",
       " 'digital approach': 298,\n",
       " 'ongoing reward': 299,\n",
       " 'intermediality': 300,\n",
       " 'multivocality': 301,\n",
       " 'multimedia': 302,\n",
       " 'metanarrative analogy': 303,\n",
       " 'neural network': 304,\n",
       " 'holocaust memory': 305,\n",
       " 'sentiment analysis': 306,\n",
       " 'longlived resource': 307,\n",
       " 'interface': 308,\n",
       " 'visual design': 309,\n",
       " 'belgian web': 310,\n",
       " 'web archive strategy': 311,\n",
       " 'digital heritage': 312,\n",
       " 'patentometrics': 313,\n",
       " 'stylistics': 314,\n",
       " 'compute': 315,\n",
       " 'digital assistance': 316,\n",
       " 'cultural asset': 317,\n",
       " 'human right': 318,\n",
       " 'audio archive': 319,\n",
       " 'brazilian chamber of deputy': 320,\n",
       " 'university archive': 321,\n",
       " 'historical record': 322,\n",
       " 'dig into data': 323,\n",
       " 'data management': 324,\n",
       " 'semistructured interview': 325,\n",
       " 'geovisualization': 326,\n",
       " 'museum': 327,\n",
       " 'soft power': 328,\n",
       " 'evaluation framework': 329,\n",
       " 'hebrew literature': 330,\n",
       " 'text encoding': 331,\n",
       " 'misconception': 332,\n",
       " 'language pattern': 333,\n",
       " 'word embed': 334,\n",
       " 'machine learning': 335,\n",
       " 'close reading': 336,\n",
       " 'distant reading': 337,\n",
       " 'origin': 338,\n",
       " 'online digital object': 339,\n",
       " 'persistence': 340,\n",
       " 'shelf life': 341,\n",
       " 'coptic': 342,\n",
       " 'optical character recognition': 343,\n",
       " 'print text': 344,\n",
       " 'program diagnostics': 345,\n",
       " 'correctness  coherence': 346,\n",
       " 'historical document': 347,\n",
       " 'quantitative analysis': 348,\n",
       " 'large visual corpus': 349,\n",
       " 'semantic metadata': 350,\n",
       " 'distant viewing': 351,\n",
       " 'interpretability': 352,\n",
       " 'publish material': 353,\n",
       " 'predigital period': 354,\n",
       " 'place concept': 355,\n",
       " 'information system': 356,\n",
       " 'geographically intelligent system': 357,\n",
       " 'medical history': 358,\n",
       " 'author verification': 359,\n",
       " 'topic modeling': 360,\n",
       " 'lsi': 361,\n",
       " 'digitize humanity': 362,\n",
       " 'numerical humanity': 363,\n",
       " 'humanity of the digital': 364,\n",
       " 'technical labor': 365,\n",
       " 'information institution': 366,\n",
       " 'digitization': 367,\n",
       " 'publishing praxis': 368,\n",
       " 'classroom reflect': 369,\n",
       " 'network analysis': 370,\n",
       " 'science history': 371,\n",
       " 'computational method': 372,\n",
       " 'historical profession': 373,\n",
       " 'information infrastructure': 374,\n",
       " 'information barrier': 375,\n",
       " 'immigrant worker': 376,\n",
       " 'korean': 377,\n",
       " 'news reporting': 378,\n",
       " 'critical discourse analysis': 379,\n",
       " 'cooccurrence analysis': 380,\n",
       " 'medical heritage library': 381,\n",
       " 'art history': 382,\n",
       " 'public open collaborative creation': 383,\n",
       " 'collaborative authorship': 384,\n",
       " 'picture': 385,\n",
       " 'light condition': 386,\n",
       " 'last supper': 387,\n",
       " 'intellectual property right': 388,\n",
       " 'creative common': 389,\n",
       " 'academic librarian': 390,\n",
       " 'apply science': 391,\n",
       " 'voyant tool': 392,\n",
       " 'faculty research': 393,\n",
       " 'word pattern': 394,\n",
       " 'agricultural communication': 395,\n",
       " 'digital': 396,\n",
       " 'computer graphic': 397,\n",
       " 'poland': 398,\n",
       " 'history': 399,\n",
       " 'linguistics': 400,\n",
       " 'data warehouse': 401,\n",
       " 'critical digital humanity': 402,\n",
       " 'capitalism': 403,\n",
       " 'mixedmethods': 404,\n",
       " 'assemblage': 405,\n",
       " 'postcolonial theory': 406,\n",
       " 'digital humanity  machine learning': 407,\n",
       " 'big data': 408,\n",
       " 'cognitive process': 409,\n",
       " 'early modern': 410,\n",
       " 'cultural activity map': 411,\n",
       " 'cultural figure network': 412,\n",
       " 'spatial humanity': 413,\n",
       " 'openness': 414,\n",
       " 'victorian': 415,\n",
       " 'statistic': 416,\n",
       " 'scholar collaboration': 417,\n",
       " 'periodical study': 418,\n",
       " 'emigre periodical': 419,\n",
       " 'culture': 420,\n",
       " 'graphical environment': 421,\n",
       " 'nonrepresentational approach': 422,\n",
       " 'model interpretation': 423,\n",
       " 'digital infrastructure': 424,\n",
       " 'humlabx': 425,\n",
       " 'collection': 426,\n",
       " 'database': 427,\n",
       " 'digital literary': 428,\n",
       " 'mexico': 429,\n",
       " 'digital carework': 430,\n",
       " 'diversity work': 431,\n",
       " 'affective labor': 432,\n",
       " 'selfrepresentation': 433,\n",
       " 'syrian refugee': 434,\n",
       " 'selfie': 435,\n",
       " 'news medium representation': 436,\n",
       " 'historical lexicography': 437,\n",
       " 'text study': 438,\n",
       " 'app': 439,\n",
       " 'satisfaction': 440,\n",
       " 'augment reality': 441,\n",
       " 'computer vision': 442,\n",
       " 'hieroglyph': 443,\n",
       " 'hoosc': 444,\n",
       " 'multimodal research': 445,\n",
       " 'online user behaviour': 446,\n",
       " 'news consumption pattern': 447,\n",
       " 'dialogism': 448,\n",
       " 'spoken language': 449,\n",
       " 'grammatical feature': 450,\n",
       " 'computational model': 451,\n",
       " 'knowledge creation': 452,\n",
       " 'recommender system': 453,\n",
       " 'deep learning': 454,\n",
       " 'lemmatization': 455,\n",
       " 'temporal convolution': 456,\n",
       " 'word embeddings': 457,\n",
       " 'public engagement': 458,\n",
       " 'digital technology': 459,\n",
       " 'rethink humanity': 460,\n",
       " 'textuality': 461,\n",
       " 'research library': 462,\n",
       " 'digital pedagogy': 463,\n",
       " 'acrl': 464,\n",
       " 'academic library': 465,\n",
       " 'partnership model': 466,\n",
       " 'online academic library': 467,\n",
       " 'information need': 468,\n",
       " 'data analysis tool': 469,\n",
       " 'digitization of ticket receipt': 470,\n",
       " 'community interaction': 471,\n",
       " 'science concept': 472,\n",
       " 'data': 473,\n",
       " 'digital curation': 474,\n",
       " 'innovation': 475,\n",
       " 'dialectology': 476,\n",
       " 'journal editor': 477,\n",
       " 'publish program': 478,\n",
       " 'geography': 479,\n",
       " 'global vision': 480,\n",
       " 'local definition': 481,\n",
       " 'russian folktale': 482,\n",
       " 'propplearner': 483,\n",
       " 'formalist theory': 484,\n",
       " 'deep annotation': 485,\n",
       " 'small language': 486,\n",
       " 'digital divide': 487,\n",
       " 'repository': 488,\n",
       " 'encyclopedia': 489,\n",
       " 'religious cultural history': 490,\n",
       " 'r package': 491,\n",
       " 'computational social science': 492,\n",
       " 'open data': 493,\n",
       " 'video record': 494,\n",
       " 'motion analysis': 495,\n",
       " 'information work': 496,\n",
       " 'research through design': 497,\n",
       " 'ngram corpus': 498,\n",
       " 'political discussion': 499,\n",
       " 'language': 500,\n",
       " 'deliberative communication': 501,\n",
       " 'automatic annotation': 502,\n",
       " 'disambiguation': 503,\n",
       " 'makerspaces': 504,\n",
       " 'entrepreneurship': 505,\n",
       " 'archaeology': 506,\n",
       " 'technical art history': 507,\n",
       " 'conflict': 508,\n",
       " 'thematic research collection': 509,\n",
       " 'decadence': 510,\n",
       " 'feminism': 511,\n",
       " 'gendered reading': 512,\n",
       " 'spanish civil war': 513,\n",
       " 'entomology': 514,\n",
       " 'digital world': 515,\n",
       " 'dissertation requirement': 516,\n",
       " 'social': 517,\n",
       " 'communitiesbased': 518,\n",
       " 'classical geography': 519,\n",
       " 'spatial model': 520,\n",
       " 'genocide': 521,\n",
       " 'incomplete data set': 522,\n",
       " 'emerge data source': 523,\n",
       " 'spectral imaging technology': 524,\n",
       " 'manuscript': 525,\n",
       " 'material feature': 526,\n",
       " 'victorian text': 527,\n",
       " 'open annotation': 528,\n",
       " 'hypothes': 529,\n",
       " 'technopedagogical tool': 530,\n",
       " 'oral data': 531,\n",
       " 'transcribing and comment tool': 532,\n",
       " 'mediumsized and small library': 533,\n",
       " 'discretely purchase': 534,\n",
       " 'database product': 535,\n",
       " 'ancient material': 536,\n",
       " 'technology teach': 537,\n",
       " 'intellectual history': 538,\n",
       " 'museum compute': 539,\n",
       " 'citation segmentation': 540,\n",
       " 'sparse  noisy data': 541,\n",
       " 'markov logic network': 542,\n",
       " 'intertextuality': 543,\n",
       " 'natural language processing': 544,\n",
       " 'semantic analysis': 545,\n",
       " 'essayontology workflow': 546,\n",
       " 'formal method': 547,\n",
       " 'interpretive method': 548,\n",
       " 'generic corpus': 549,\n",
       " 'query': 550,\n",
       " 'annotationtriggered style sheet': 551,\n",
       " 'visual art': 552,\n",
       " 'creative research': 553,\n",
       " 'journal': 554,\n",
       " 'online publication': 555,\n",
       " 'stylometry': 556,\n",
       " 'stylo': 557,\n",
       " 'computational text analysis': 558,\n",
       " 'scalar': 559,\n",
       " 'research university': 560,\n",
       " 'digital publication platform': 561,\n",
       " 'user experience': 562,\n",
       " 'topic model': 563,\n",
       " 'online source': 564,\n",
       " 'historic document': 565,\n",
       " 'academic literacy': 566,\n",
       " 'democracy': 567,\n",
       " 'software development': 568,\n",
       " 'program': 569,\n",
       " 'trading consequence': 570,\n",
       " 'perform art': 571,\n",
       " 'notation': 572,\n",
       " 'annotation': 573,\n",
       " 'denotation': 574,\n",
       " 'textual materiality': 575,\n",
       " 'ecocriticism': 576,\n",
       " 'portuguese literary': 577,\n",
       " 'selfregulation': 578,\n",
       " 'conceptual cluster': 579,\n",
       " 'mobile classroom': 580,\n",
       " 'critical pedagogy': 581,\n",
       " 'material culture': 582,\n",
       " 'entity recognition': 583,\n",
       " 'term extraction': 584,\n",
       " 'unstructured metadata mining': 585,\n",
       " 'digital collection': 586,\n",
       " 'impact assessment': 587,\n",
       " 'method concept': 588,\n",
       " 'methodology': 589,\n",
       " 'prosopography': 590,\n",
       " 'community': 591,\n",
       " 'coword analysis': 592,\n",
       " 'native sovereignty': 593,\n",
       " 'occom': 594,\n",
       " 'medium archaeology': 595,\n",
       " 'archaeological analysis': 596,\n",
       " 'igital memorialization': 597,\n",
       " 'cultural technology': 598,\n",
       " 'aid quilt': 599,\n",
       " 'collaborative creation': 600,\n",
       " 'knowledge engineering': 601,\n",
       " 'territorial intelligence': 602,\n",
       " 'shakespeare': 603,\n",
       " 'digital database': 604,\n",
       " 'microtasking': 605,\n",
       " 'macrotasking': 606,\n",
       " 'collaborative interpretation of text': 607,\n",
       " 'hypertext literature': 608,\n",
       " 'lecture': 609,\n",
       " 'development': 610,\n",
       " 'internationalization': 611,\n",
       " 'geographical diversity': 612,\n",
       " 'linguistic diversity': 613,\n",
       " 'collaborative publication': 614,\n",
       " 'joint publication': 615,\n",
       " 'multiauthored publication': 616,\n",
       " 'digital index': 617,\n",
       " 'open science': 618,\n",
       " 'historic property': 619,\n",
       " 'inventory data': 620,\n",
       " 'aggregation service': 621,\n",
       " 'conceptual reference model': 622,\n",
       " 'oral history': 623,\n",
       " 'rhetorical study': 624,\n",
       " 'cultural economy': 625,\n",
       " 'datadriven analysis and interpreting': 626,\n",
       " 'train initiative': 627,\n",
       " 'text mining software': 628,\n",
       " 'usability': 629,\n",
       " 'preservation': 630,\n",
       " 'ancient architecture': 631,\n",
       " '3d model': 632,\n",
       " 'digital geography': 633,\n",
       " 'baroque art': 634,\n",
       " 'web content': 635,\n",
       " 'semantics augment': 636,\n",
       " 'machineprocessable data': 637,\n",
       " 'semantic annotation': 638,\n",
       " 'publication': 639,\n",
       " 'crosscutting categorization': 640,\n",
       " 'philosophical concept': 641,\n",
       " 'digital resource representation': 642,\n",
       " 'middle age manuscript': 643,\n",
       " 'hypertextual': 644,\n",
       " 'textual criticism': 645,\n",
       " 'digital medium': 646,\n",
       " 'literature': 647,\n",
       " 'encyclopedia  rhetoric': 648,\n",
       " 'european fairy tale': 649,\n",
       " 'gendered representation': 650,\n",
       " 'body': 651,\n",
       " 'handcoded database': 652,\n",
       " 'omputational stylometry': 653,\n",
       " 'psychological profiling': 654,\n",
       " 'author identification': 655,\n",
       " 'personality': 656,\n",
       " 'medieval': 657,\n",
       " 'computerassisted analysis': 658,\n",
       " 'virtual object': 659,\n",
       " 'text': 660,\n",
       " 'text discrete': 661,\n",
       " 'text relationship': 662,\n",
       " 'language representation': 663,\n",
       " 'communicate intent': 664,\n",
       " 'secondary student': 665,\n",
       " 'reading practice': 666,\n",
       " 'digital experience': 667,\n",
       " 'xml markup': 668,\n",
       " 'victorian study': 669,\n",
       " 'institutional structure': 670,\n",
       " 'publication form': 671,\n",
       " 'institutional language': 672,\n",
       " 'content analysis': 673,\n",
       " 'public sector s priority': 674,\n",
       " 'institutional discourse': 675,\n",
       " 'book trade': 676,\n",
       " 'code': 677,\n",
       " 'new positivism': 678,\n",
       " 'historical approach': 679,\n",
       " 'critical epistemology': 680,\n",
       " 'speculative formalism': 681,\n",
       " 'scholarly work': 682,\n",
       " 'digital humanity scholar': 683,\n",
       " 'web': 684,\n",
       " 'new and emerge social medium': 685,\n",
       " 'electronic scholarly edition': 686,\n",
       " 'social edition': 687,\n",
       " 'peer learning': 688,\n",
       " 'public digital humanity': 689,\n",
       " 'collaborative research': 690,\n",
       " 'undergraduate': 691,\n",
       " 'print culture': 692,\n",
       " 'mass culture': 693,\n",
       " 'marginal public': 694,\n",
       " 'attribution': 695,\n",
       " 'ownership': 696,\n",
       " 'heritage': 697,\n",
       " 'google ancient place': 698,\n",
       " 'book corpus': 699,\n",
       " 'location identify': 700,\n",
       " 'geographic clustering': 701,\n",
       " 'sculpture mapping': 702,\n",
       " 'online': 703,\n",
       " 'social medium': 704,\n",
       " 'assemblage theory': 705,\n",
       " 'actornetwork theory': 706,\n",
       " 'archival theory': 707,\n",
       " 'digital historiography': 708,\n",
       " 'computational standard': 709,\n",
       " 'elearning': 710,\n",
       " 'online education': 711,\n",
       " 'social and economic force': 712,\n",
       " 'current role': 713,\n",
       " 'literary computing': 714,\n",
       " 'semiautomatic generate instance': 715,\n",
       " 'literary character representation': 716,\n",
       " 'digital humanity community': 717,\n",
       " 'collaborative approach': 718,\n",
       " 'digital revolution': 719,\n",
       " 'digital humanity  scholar': 720,\n",
       " 'developed market': 721,\n",
       " 'emerge market': 722,\n",
       " 'humanity pedagogy': 723,\n",
       " 'eliteracy training': 724,\n",
       " 'computer mapping': 725,\n",
       " 'cognitive structure': 726,\n",
       " 'border protocol': 727,\n",
       " 'topic map': 728,\n",
       " 'metalanguage': 729,\n",
       " 'collaborative infrastructure': 730,\n",
       " 'data digging': 731,\n",
       " 'oral discourse': 732,\n",
       " 'multiple language': 733,\n",
       " 'citation map': 734,\n",
       " 'a  hci': 735,\n",
       " 'text comparison': 736,\n",
       " 'digital creativity': 737,\n",
       " 'textual scholarship': 738,\n",
       " 'text culture': 739,\n",
       " 'interpretation': 740,\n",
       " 'text encode initiative': 741,\n",
       " 'teach': 742,\n",
       " 'online tutorial': 743,\n",
       " 'implicit assumption': 744,\n",
       " 'data mining': 745,\n",
       " 'humanity scholarship': 746,\n",
       " 'text encoders': 747,\n",
       " 'xmlbased repository': 748,\n",
       " 'linguistic knowledge': 749,\n",
       " 'sentiment lexicon': 750,\n",
       " 'sentiment term classification': 751,\n",
       " 'sentiment term extraction': 752,\n",
       " 'cultural analytics': 753,\n",
       " 'language of art': 754,\n",
       " 'crepč central register of publication activity': 755,\n",
       " 'research area classification': 756,\n",
       " 'research organisation': 757,\n",
       " 'research project': 758,\n",
       " 'research result': 759,\n",
       " 'researcher': 760,\n",
       " 'current research information system': 761,\n",
       " 'web of science core collection': 762,\n",
       " 'action recognitio': 763,\n",
       " 'modify bagofwords': 764,\n",
       " 'prominent camer': 765,\n",
       " 'support vector machine': 766,\n",
       " 'circular graph': 767,\n",
       " 'fuzzy classification': 768,\n",
       " 'mental map': 769,\n",
       " 'naive geography': 770,\n",
       " 'pattern match': 771,\n",
       " 'visual analytics': 772,\n",
       " 'connect europe facility  cef': 773,\n",
       " 'digital preservation': 774,\n",
       " 'earchiving': 775,\n",
       " 'fair principle': 776,\n",
       " 'bidirectional lstm': 777,\n",
       " 'convolutional neural network': 778,\n",
       " 'dictionary': 779,\n",
       " 'levenshteindistance': 780,\n",
       " 'climate crisis': 781,\n",
       " 'decarbonization': 782,\n",
       " 'energy democracy': 783,\n",
       " 'energy justice': 784,\n",
       " 'equity': 785,\n",
       " 'automatic generation': 786,\n",
       " 'creative computing': 787,\n",
       " 'creativity rule': 788,\n",
       " 'filmstory creation': 789,\n",
       " 'humanlike scriptwriting': 790,\n",
       " 'elearning system': 791,\n",
       " 'education research': 792,\n",
       " 'educational data mining': 793,\n",
       " 'interactive learning environment': 794,\n",
       " 'learn analytics': 795,\n",
       " 'learn management system': 796,\n",
       " 'soft compute': 797,\n",
       " 'systematic literature review': 798,\n",
       " 'argumentation analysis': 799,\n",
       " 'discourse analysis': 800,\n",
       " 'information reuse': 801,\n",
       " 'information visualization': 802,\n",
       " 'software assistance': 803,\n",
       " 'viscourse': 804,\n",
       " 'crosslinguistic distant reading': 805,\n",
       " 'embodied ontology': 806,\n",
       " 'flat logic': 807,\n",
       " 'literary repetition': 808,\n",
       " 'psychodramatic effect': 809,\n",
       " 'textual surface': 810,\n",
       " 'thick compute': 811,\n",
       " 'translation': 812,\n",
       " 'health and medical data': 813,\n",
       " 'international data protection': 814,\n",
       " 'organ donation': 815,\n",
       " 'patient record': 816,\n",
       " 'postmortem privacy': 817,\n",
       " 'posthumous medical data donation': 818,\n",
       " 'core research cluster of disaster science planning session': 819,\n",
       " 'disaster medicine': 820,\n",
       " 'disaster preparedness': 821,\n",
       " 'train program': 822,\n",
       " 'world bosai forum2019': 823,\n",
       " 'genetic editing': 824,\n",
       " 'james joyce': 825,\n",
       " 'scholarly edit': 826,\n",
       " 'bollywood': 827,\n",
       " 'digital necropolitics': 828,\n",
       " 'partition': 829,\n",
       " 'postcolonial study': 830,\n",
       " 'emotion recognition': 831,\n",
       " 'pca': 832,\n",
       " 'prosody': 833,\n",
       " 'recognition rate': 834,\n",
       " 'historical concept': 835,\n",
       " 'information retrieval': 836,\n",
       " 'knowledge retrieval': 837,\n",
       " 'ontologybased knowledge retrieval': 838,\n",
       " 'semantic web': 839,\n",
       " 'apply compute → art and humanity': 840,\n",
       " 'concept and paradigm': 841,\n",
       " 'humancentered compute → visualization': 842,\n",
       " 'visualization theory': 843,\n",
       " 'classical arabic corpus': 844,\n",
       " 'hadith authenticity': 845,\n",
       " 'hadith science': 846,\n",
       " 'hadith text mining': 847,\n",
       " 'islamic knowledge': 848,\n",
       " 'survey': 849,\n",
       " 'digital study': 850,\n",
       " 'informatics': 851,\n",
       " 'korea': 852,\n",
       " 'new frontier': 853,\n",
       " 'technological advance': 854,\n",
       " 'cultural analysis humanity': 855,\n",
       " 'genetic ancestry': 856,\n",
       " 'historical society': 857,\n",
       " 'intersectionality': 858,\n",
       " 'bucknell university': 859,\n",
       " 'liberal art': 860,\n",
       " 'wellesley college': 861,\n",
       " 'domaindriven data mining': 862,\n",
       " 'historical musicology': 863,\n",
       " 'music informatics': 864,\n",
       " 'music information retrieval': 865,\n",
       " 'optical music recognition': 866,\n",
       " 'incentive': 867,\n",
       " 'information asymmetry': 868,\n",
       " 'quality improvement': 869,\n",
       " 'supplier failure': 870,\n",
       " 'citespace': 871,\n",
       " 'digital cultural heritage': 872,\n",
       " 'library and information service': 873,\n",
       " 'visualization analysis': 874,\n",
       " 'vosviewer': 875,\n",
       " 'folktale': 876,\n",
       " 'gm': 877,\n",
       " 'great mekong subregion': 878,\n",
       " 'music librarianship': 879,\n",
       " 'music theory': 880,\n",
       " 'musicology': 881,\n",
       " 'law': 882,\n",
       " 'policy': 883,\n",
       " 'principle of robotics': 884,\n",
       " 'robot': 885,\n",
       " 'blockbased programming': 886,\n",
       " 'computer science education': 887,\n",
       " 'explicit parallel compute': 888,\n",
       " 'language for pdc and hpc': 889,\n",
       " 'parallel computational pattern': 890,\n",
       " 'pedagogical tool': 891,\n",
       " 'program environment': 892,\n",
       " 'visual programming': 893,\n",
       " 'c curriculum': 894,\n",
       " 'parallel and distribute compute': 895,\n",
       " 'alloy': 896,\n",
       " 'corrosion': 897,\n",
       " 'crystallographic structure': 898,\n",
       " 'scan electron microscopy': 899,\n",
       " 'corpus analysis': 900,\n",
       " 'webbased platform': 901,\n",
       " 'context': 902,\n",
       " 'cultural difference': 903,\n",
       " 'fan': 904,\n",
       " 'statistical analysis': 905,\n",
       " 'biblical study': 906,\n",
       " 'canon': 907,\n",
       " 'cultural capital': 908,\n",
       " 'encode': 909,\n",
       " 'marginalia': 910,\n",
       " 'markup': 911,\n",
       " 'religious study': 912,\n",
       " 'theory': 913,\n",
       " 'historical method': 914,\n",
       " 'humanity research and education': 915,\n",
       " 'philology': 916,\n",
       " 'scholarly ethic': 917,\n",
       " 'domain vocabulary': 918,\n",
       " 'hierarchical model': 919,\n",
       " 'image annotation': 920,\n",
       " 'semantic description': 921,\n",
       " 'friend recommendation': 922,\n",
       " 'social network': 923,\n",
       " 'virtual world': 924,\n",
       " 'digital object preservation': 925,\n",
       " 'world wide web': 926,\n",
       " 'decline of humanity': 927,\n",
       " 'compute history': 928,\n",
       " 'software engineering': 929,\n",
       " 'aggadic midrash': 930,\n",
       " 'bible exegesis': 931,\n",
       " 'explanation': 932,\n",
       " 'hebrewaramaic corpus': 933,\n",
       " 'homiletics': 934,\n",
       " 'information extraction': 935,\n",
       " 'question answer': 936,\n",
       " 'rabbinic literature': 937,\n",
       " 'text generation': 938,\n",
       " 'ancient text transcription': 939,\n",
       " 'handwritten text recognition': 940,\n",
       " 'iterative system': 941,\n",
       " 'language modelling': 942,\n",
       " 'multimodal system': 943,\n",
       " 'speech dictation': 944,\n",
       " 'cloud compute': 945,\n",
       " 'dataintensive research': 946,\n",
       " 'highperformance computing': 947,\n",
       " 'infrastructure a a service': 948,\n",
       " 'aurignacian': 949,\n",
       " 'heinrich stadial 4': 950,\n",
       " 'iberian peninsula': 951,\n",
       " 'neanderthal': 952,\n",
       " 'paleoenvironment': 953,\n",
       " 'upper pleistocene': 954,\n",
       " 'amplified reading': 955,\n",
       " 'digital reading': 956,\n",
       " 'ebooks': 957,\n",
       " 'enhance ebooks': 958,\n",
       " 'neurocognitive': 959,\n",
       " 'data integration': 960,\n",
       " 'link data': 961,\n",
       " 'information science history': 962,\n",
       " 'bibliographic system': 963,\n",
       " 'library system': 964,\n",
       " 'acm curriculum design': 965,\n",
       " 'philosophy': 966,\n",
       " 'social psychology': 967,\n",
       " 'methodological common': 968,\n",
       " 'primitive': 969,\n",
       " 'digital archive': 970,\n",
       " 'gcube': 971,\n",
       " 'virtual research environment': 972,\n",
       " 'blogosphere': 973,\n",
       " 'digital method': 974,\n",
       " 'hyperlink analysis': 975,\n",
       " 'internet archive': 976,\n",
       " 'social networking site': 977,\n",
       " 'wikipedia': 978,\n",
       " 'cybercartographic atlas framework': 979,\n",
       " 'cybercartographic atlas': 980,\n",
       " 'cybercartography': 981,\n",
       " 'indigenous mapping': 982,\n",
       " 'iteration': 983,\n",
       " 'theory and practice': 984,\n",
       " 'access grid': 985,\n",
       " 'high performance compute': 986,\n",
       " 'virtual workbench': 987,\n",
       " 'academic staff': 988,\n",
       " 'electronic book': 989,\n",
       " 'monographics': 990,\n",
       " 'communication technology': 991,\n",
       " 'electronic medium': 992,\n",
       " 'humanistic philosophy': 993,\n",
       " 'research': 994,\n",
       " 'science': 995,\n",
       " 'program language curriculum': 996,\n",
       " 'affect': 997,\n",
       " 'information task': 998,\n",
       " 'search pattern': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_dict = dict(zip(nodes_data[0],nodes_data.index))\n",
    "project_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3a9a6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17278</th>\n",
       "      <td>248.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17279</th>\n",
       "      <td>248.0</td>\n",
       "      <td>4732.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17280</th>\n",
       "      <td>1070.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17281</th>\n",
       "      <td>1070.0</td>\n",
       "      <td>4732.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17282</th>\n",
       "      <td>183.0</td>\n",
       "      <td>4732.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17283 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1    2\n",
       "0         2.0     1.0  1.0\n",
       "1         2.0     0.0  1.0\n",
       "2         1.0     0.0  1.0\n",
       "3         5.0     3.0  1.0\n",
       "4         5.0     4.0  1.0\n",
       "...       ...     ...  ...\n",
       "17278   248.0  1070.0  1.0\n",
       "17279   248.0  4732.0  1.0\n",
       "17280  1070.0   183.0  1.0\n",
       "17281  1070.0  4732.0  1.0\n",
       "17282   183.0  4732.0  1.0\n",
       "\n",
       "[17283 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_data_num=pd.DataFrame(np.zeros(edges_data.shape))\n",
    "for i in range(edges_data.shape[0]):\n",
    "    edges_data_num[0][i]=project_dict[edges_data[0][i]]\n",
    "    edges_data_num[1][i]=project_dict[edges_data[1][i]]\n",
    "    edges_data_num[2][i]=edges_data[2][i]\n",
    "edges_data_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5ddd587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17278</th>\n",
       "      <td>1070.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17279</th>\n",
       "      <td>4732.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17280</th>\n",
       "      <td>183.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17281</th>\n",
       "      <td>4732.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17282</th>\n",
       "      <td>4732.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17283 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1    2\n",
       "0         1.0     2.0  1.0\n",
       "1         0.0     2.0  1.0\n",
       "2         0.0     1.0  1.0\n",
       "3         3.0     5.0  1.0\n",
       "4         4.0     5.0  1.0\n",
       "...       ...     ...  ...\n",
       "17278  1070.0   248.0  1.0\n",
       "17279  4732.0   248.0  1.0\n",
       "17280   183.0  1070.0  1.0\n",
       "17281  4732.0  1070.0  1.0\n",
       "17282  4732.0   183.0  1.0\n",
       "\n",
       "[17283 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_data_num__reverse=pd.DataFrame(np.zeros(edges_data.shape))\n",
    "for i in range(edges_data_num__reverse.shape[0]):\n",
    "    edges_data_num__reverse[0][i]=edges_data_num[1][i]\n",
    "    edges_data_num__reverse[1][i]=edges_data_num[0][i]\n",
    "    edges_data_num__reverse[2][i]=edges_data_num[2][i]\n",
    "edges_data_num__reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f6139ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17278</th>\n",
       "      <td>1070.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17279</th>\n",
       "      <td>4732.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17280</th>\n",
       "      <td>183.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17281</th>\n",
       "      <td>4732.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17282</th>\n",
       "      <td>4732.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34566 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1    2\n",
       "0         2.0     1.0  1.0\n",
       "1         2.0     0.0  1.0\n",
       "2         1.0     0.0  1.0\n",
       "3         5.0     3.0  1.0\n",
       "4         5.0     4.0  1.0\n",
       "...       ...     ...  ...\n",
       "17278  1070.0   248.0  1.0\n",
       "17279  4732.0   248.0  1.0\n",
       "17280   183.0  1070.0  1.0\n",
       "17281  4732.0  1070.0  1.0\n",
       "17282  4732.0   183.0  1.0\n",
       "\n",
       "[34566 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_data_biderect=pd.concat([edges_data_num,edges_data_num__reverse],axis=0)\n",
    "edges_data_biderect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02101886",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_pyg=[np.array(edges_data_biderect[0]).astype(dtype=int).tolist(),np.array(edges_data_biderect[1]).astype(dtype=int).tolist()]\n",
    "edge_index = torch.LongTensor(edge_pyg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49c70325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008700</td>\n",
       "      <td>0.081825</td>\n",
       "      <td>-0.523698</td>\n",
       "      <td>0.597906</td>\n",
       "      <td>0.122714</td>\n",
       "      <td>-0.456218</td>\n",
       "      <td>0.034991</td>\n",
       "      <td>0.114024</td>\n",
       "      <td>-0.086931</td>\n",
       "      <td>0.642463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.413814</td>\n",
       "      <td>-0.025329</td>\n",
       "      <td>0.142052</td>\n",
       "      <td>-0.637284</td>\n",
       "      <td>0.176882</td>\n",
       "      <td>0.215634</td>\n",
       "      <td>-0.151164</td>\n",
       "      <td>0.226083</td>\n",
       "      <td>0.392156</td>\n",
       "      <td>0.268685</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.300186</td>\n",
       "      <td>-0.116646</td>\n",
       "      <td>-1.282686</td>\n",
       "      <td>-0.217487</td>\n",
       "      <td>0.804696</td>\n",
       "      <td>-0.097120</td>\n",
       "      <td>-0.126476</td>\n",
       "      <td>0.157971</td>\n",
       "      <td>-0.266505</td>\n",
       "      <td>-0.364618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.101645</td>\n",
       "      <td>-0.148383</td>\n",
       "      <td>0.098534</td>\n",
       "      <td>-0.528029</td>\n",
       "      <td>0.473487</td>\n",
       "      <td>0.039792</td>\n",
       "      <td>-0.012690</td>\n",
       "      <td>0.492727</td>\n",
       "      <td>-0.129925</td>\n",
       "      <td>0.473836</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.308094</td>\n",
       "      <td>-0.107835</td>\n",
       "      <td>-0.641750</td>\n",
       "      <td>0.090987</td>\n",
       "      <td>0.248216</td>\n",
       "      <td>-0.264086</td>\n",
       "      <td>0.253395</td>\n",
       "      <td>0.222335</td>\n",
       "      <td>-0.125950</td>\n",
       "      <td>0.117572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4728</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4729</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4730</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4731</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4732</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4733 rows × 384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3    -0.413814 -0.025329  0.142052 -0.637284  0.176882  0.215634 -0.151164   \n",
       "4    -0.101645 -0.148383  0.098534 -0.528029  0.473487  0.039792 -0.012690   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4728  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4729  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4730  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4731  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4732  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "           7         8         9    ...       118       119       120  \\\n",
       "0     0.000000  0.000000  0.000000  ... -0.008700  0.081825 -0.523698   \n",
       "1     0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "2     0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "3     0.226083  0.392156  0.268685  ... -0.300186 -0.116646 -1.282686   \n",
       "4     0.492727 -0.129925  0.473836  ... -0.308094 -0.107835 -0.641750   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4728  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "4729  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "4730  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "4731  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "4732  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "\n",
       "           121       122       123       124       125       126       127  \n",
       "0     0.597906  0.122714 -0.456218  0.034991  0.114024 -0.086931  0.642463  \n",
       "1     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3    -0.217487  0.804696 -0.097120 -0.126476  0.157971 -0.266505 -0.364618  \n",
       "4     0.090987  0.248216 -0.264086  0.253395  0.222335 -0.125950  0.117572  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4728  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4729  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4730  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4731  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4732  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[4733 rows x 384 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#embed=pd.read_csv('E:\\\\GraphSAGE\\\\Scopus_2022_9_21_1\\\\bert_embedding_whitening128.csv',header=None)\n",
    "#embed=np.eye(nodes_data.shape[0])\n",
    "#embed=np.ones([nodes_data.shape[0],128])\n",
    "embed1=pd.read_csv('E:\\\\GraphSAGE\\\\Scopus_2022_9_21_1\\\\embedding2.csv',header=None)\n",
    "embed2=pd.read_csv('E:\\\\GraphSAGE\\\\Scopus_2022_9_21_1\\\\bert_embedding_whitening128.csv',header=None)\n",
    "embed3=pd.read_csv('E:\\\\GraphSAGE\\\\Scopus_2022_9_21_1\\\\embedding1.csv',header=None)\n",
    "#embed=pd.concat([embed2,embed1],axis=1)\n",
    "embed=pd.concat([embed1,embed2,embed3],axis=1)\n",
    "#embed=pd.read_csv('E:\\\\GraphSAGE\\\\Scopus_2022_9_21_1\\\\embedding2.csv',header=None)\n",
    "embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "551e71f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import diags\n",
    "def preprocess_features(features):\n",
    "    rowsum=np.array(features.sum(1))\n",
    "    r_inv=np.power(rowsum,-1).flatten()\n",
    "    r_inv[np.isinf(r_inv)]=0.\n",
    "    r_mat_inv=diags(r_inv)\n",
    "    features=r_mat_inv.dot(features)\n",
    "    return torch.tensor(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d4d6bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=torch.tensor(np.array(embed),dtype=torch.float)\n",
    "x=preprocess_features(features)\n",
    "edge_weight = torch.tensor(np.array(edges_data_biderect[2]).astype(dtype=float),dtype=torch.float)\n",
    "edge_attr=edge_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4506d94e",
   "metadata": {},
   "source": [
    "创建Data对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0267c480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[4733, 384], edge_index=[2, 34566], edge_attr=[34566])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "395a3b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1\n",
       "0   0.0  0.0\n",
       "1   0.0  0.0\n",
       "2   0.0  0.0\n",
       "3   0.0  0.0\n",
       "4   0.0  0.0\n",
       "5   0.0  0.0\n",
       "6   0.0  0.0\n",
       "7   0.0  0.0\n",
       "8   0.0  0.0\n",
       "9   0.0  0.0\n",
       "10  0.0  0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=pd.DataFrame(np.zeros([11,2]))\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cf2cf7",
   "metadata": {},
   "source": [
    "2.训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c628316",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001,train AUC: 0.7939, train AP: 0.7790, loss:1.4414,val AUC: 0.7226, val AP: 0.7191,test AUC: 0.7192, test AP: 0.7034\n",
      "Epoch: 002,train AUC: 0.7933, train AP: 0.7841, loss:1.3439,val AUC: 0.7373, val AP: 0.7372,test AUC: 0.7276, test AP: 0.7164\n",
      "Epoch: 003,train AUC: 0.7851, train AP: 0.7787, loss:1.2980,val AUC: 0.7281, val AP: 0.7298,test AUC: 0.7160, test AP: 0.7133\n",
      "Epoch: 004,train AUC: 0.8008, train AP: 0.7921, loss:1.3091,val AUC: 0.7468, val AP: 0.7500,test AUC: 0.7330, test AP: 0.7276\n",
      "Epoch: 005,train AUC: 0.8190, train AP: 0.8095, loss:1.2989,val AUC: 0.7566, val AP: 0.7607,test AUC: 0.7508, test AP: 0.7436\n",
      "Epoch: 006,train AUC: 0.8326, train AP: 0.8220, loss:1.2937,val AUC: 0.7673, val AP: 0.7698,test AUC: 0.7633, test AP: 0.7553\n",
      "Epoch: 007,train AUC: 0.8404, train AP: 0.8298, loss:1.2877,val AUC: 0.7726, val AP: 0.7766,test AUC: 0.7680, test AP: 0.7588\n",
      "Epoch: 008,train AUC: 0.8420, train AP: 0.8332, loss:1.2631,val AUC: 0.7690, val AP: 0.7758,test AUC: 0.7644, test AP: 0.7574\n",
      "Epoch: 009,train AUC: 0.8399, train AP: 0.8339, loss:1.2479,val AUC: 0.7689, val AP: 0.7767,test AUC: 0.7642, test AP: 0.7605\n",
      "Epoch: 010,train AUC: 0.8425, train AP: 0.8361, loss:1.2602,val AUC: 0.7729, val AP: 0.7808,test AUC: 0.7707, test AP: 0.7652\n",
      "Epoch: 011,train AUC: 0.8439, train AP: 0.8373, loss:1.2417,val AUC: 0.7722, val AP: 0.7806,test AUC: 0.7729, test AP: 0.7660\n",
      "Epoch: 012,train AUC: 0.8462, train AP: 0.8403, loss:1.2313,val AUC: 0.7744, val AP: 0.7866,test AUC: 0.7729, test AP: 0.7688\n",
      "Epoch: 013,train AUC: 0.8494, train AP: 0.8438, loss:1.2512,val AUC: 0.7777, val AP: 0.7900,test AUC: 0.7756, test AP: 0.7729\n",
      "Epoch: 014,train AUC: 0.8526, train AP: 0.8475, loss:1.2381,val AUC: 0.7799, val AP: 0.7915,test AUC: 0.7812, test AP: 0.7777\n",
      "Epoch: 015,train AUC: 0.8571, train AP: 0.8515, loss:1.2248,val AUC: 0.7894, val AP: 0.7989,test AUC: 0.7849, test AP: 0.7809\n",
      "Epoch: 016,train AUC: 0.8662, train AP: 0.8590, loss:1.2131,val AUC: 0.7970, val AP: 0.8052,test AUC: 0.7948, test AP: 0.7894\n",
      "Epoch: 017,train AUC: 0.8744, train AP: 0.8646, loss:1.2146,val AUC: 0.8025, val AP: 0.8112,test AUC: 0.8021, test AP: 0.7942\n",
      "Epoch: 018,train AUC: 0.8782, train AP: 0.8676, loss:1.2354,val AUC: 0.8075, val AP: 0.8172,test AUC: 0.8074, test AP: 0.7972\n",
      "Epoch: 019,train AUC: 0.8807, train AP: 0.8711, loss:1.2160,val AUC: 0.8087, val AP: 0.8213,test AUC: 0.8078, test AP: 0.7969\n",
      "Epoch: 020,train AUC: 0.8823, train AP: 0.8728, loss:1.2219,val AUC: 0.8061, val AP: 0.8230,test AUC: 0.8057, test AP: 0.7960\n",
      "Epoch: 021,train AUC: 0.8821, train AP: 0.8737, loss:1.2064,val AUC: 0.8005, val AP: 0.8190,test AUC: 0.8015, test AP: 0.7970\n",
      "Epoch: 022,train AUC: 0.8834, train AP: 0.8758, loss:1.2076,val AUC: 0.8061, val AP: 0.8231,test AUC: 0.8005, test AP: 0.7987\n",
      "Epoch: 023,train AUC: 0.8887, train AP: 0.8798, loss:1.1941,val AUC: 0.8153, val AP: 0.8278,test AUC: 0.8089, test AP: 0.8051\n",
      "Epoch: 024,train AUC: 0.8934, train AP: 0.8829, loss:1.2087,val AUC: 0.8243, val AP: 0.8329,test AUC: 0.8170, test AP: 0.8080\n",
      "Epoch: 025,train AUC: 0.8958, train AP: 0.8842, loss:1.1993,val AUC: 0.8281, val AP: 0.8362,test AUC: 0.8223, test AP: 0.8104\n",
      "Epoch: 026,train AUC: 0.8971, train AP: 0.8859, loss:1.2028,val AUC: 0.8312, val AP: 0.8386,test AUC: 0.8236, test AP: 0.8124\n",
      "Epoch: 027,train AUC: 0.8977, train AP: 0.8870, loss:1.1886,val AUC: 0.8295, val AP: 0.8369,test AUC: 0.8214, test AP: 0.8124\n",
      "Epoch: 028,train AUC: 0.8974, train AP: 0.8880, loss:1.1702,val AUC: 0.8271, val AP: 0.8352,test AUC: 0.8220, test AP: 0.8151\n",
      "Epoch: 029,train AUC: 0.8990, train AP: 0.8897, loss:1.1709,val AUC: 0.8307, val AP: 0.8388,test AUC: 0.8238, test AP: 0.8170\n",
      "Epoch: 030,train AUC: 0.9030, train AP: 0.8924, loss:1.1480,val AUC: 0.8400, val AP: 0.8460,test AUC: 0.8323, test AP: 0.8219\n",
      "Epoch: 031,train AUC: 0.9041, train AP: 0.8931, loss:1.1438,val AUC: 0.8446, val AP: 0.8512,test AUC: 0.8368, test AP: 0.8270\n",
      "Epoch: 032,train AUC: 0.9046, train AP: 0.8930, loss:1.1547,val AUC: 0.8448, val AP: 0.8520,test AUC: 0.8362, test AP: 0.8277\n",
      "Epoch: 033,train AUC: 0.9049, train AP: 0.8940, loss:1.1446,val AUC: 0.8423, val AP: 0.8523,test AUC: 0.8354, test AP: 0.8281\n",
      "Epoch: 034,train AUC: 0.9054, train AP: 0.8944, loss:1.1556,val AUC: 0.8417, val AP: 0.8514,test AUC: 0.8382, test AP: 0.8304\n",
      "Epoch: 035,train AUC: 0.9080, train AP: 0.8962, loss:1.1450,val AUC: 0.8447, val AP: 0.8501,test AUC: 0.8431, test AP: 0.8347\n",
      "Epoch: 036,train AUC: 0.9112, train AP: 0.8989, loss:1.1272,val AUC: 0.8462, val AP: 0.8503,test AUC: 0.8464, test AP: 0.8377\n",
      "Epoch: 037,train AUC: 0.9148, train AP: 0.9019, loss:1.1146,val AUC: 0.8521, val AP: 0.8546,test AUC: 0.8501, test AP: 0.8422\n",
      "Epoch: 038,train AUC: 0.9169, train AP: 0.9047, loss:1.1261,val AUC: 0.8579, val AP: 0.8587,test AUC: 0.8536, test AP: 0.8462\n",
      "Epoch: 039,train AUC: 0.9174, train AP: 0.9060, loss:1.1309,val AUC: 0.8566, val AP: 0.8568,test AUC: 0.8533, test AP: 0.8470\n",
      "Epoch: 040,train AUC: 0.9187, train AP: 0.9073, loss:1.1305,val AUC: 0.8581, val AP: 0.8578,test AUC: 0.8565, test AP: 0.8508\n",
      "Epoch: 041,train AUC: 0.9199, train AP: 0.9079, loss:1.1421,val AUC: 0.8577, val AP: 0.8578,test AUC: 0.8559, test AP: 0.8493\n",
      "Epoch: 042,train AUC: 0.9208, train AP: 0.9079, loss:1.0963,val AUC: 0.8550, val AP: 0.8559,test AUC: 0.8558, test AP: 0.8479\n",
      "Epoch: 043,train AUC: 0.9207, train AP: 0.9074, loss:1.1215,val AUC: 0.8546, val AP: 0.8578,test AUC: 0.8597, test AP: 0.8509\n",
      "Epoch: 044,train AUC: 0.9199, train AP: 0.9069, loss:1.1153,val AUC: 0.8523, val AP: 0.8558,test AUC: 0.8610, test AP: 0.8528\n",
      "Epoch: 045,train AUC: 0.9198, train AP: 0.9074, loss:1.1284,val AUC: 0.8521, val AP: 0.8544,test AUC: 0.8624, test AP: 0.8552\n",
      "Epoch: 046,train AUC: 0.9189, train AP: 0.9063, loss:1.0969,val AUC: 0.8511, val AP: 0.8558,test AUC: 0.8633, test AP: 0.8542\n",
      "Epoch: 047,train AUC: 0.9194, train AP: 0.9065, loss:1.1412,val AUC: 0.8554, val AP: 0.8590,test AUC: 0.8648, test AP: 0.8547\n",
      "Epoch: 048,train AUC: 0.9217, train AP: 0.9087, loss:1.0973,val AUC: 0.8620, val AP: 0.8641,test AUC: 0.8690, test AP: 0.8582\n",
      "Epoch: 049,train AUC: 0.9228, train AP: 0.9101, loss:1.0957,val AUC: 0.8643, val AP: 0.8686,test AUC: 0.8716, test AP: 0.8605\n",
      "Epoch: 050,train AUC: 0.9232, train AP: 0.9099, loss:1.1227,val AUC: 0.8625, val AP: 0.8678,test AUC: 0.8713, test AP: 0.8612\n",
      "Epoch: 051,train AUC: 0.9222, train AP: 0.9081, loss:1.1147,val AUC: 0.8577, val AP: 0.8633,test AUC: 0.8688, test AP: 0.8585\n",
      "Epoch: 052,train AUC: 0.9216, train AP: 0.9075, loss:1.1109,val AUC: 0.8534, val AP: 0.8573,test AUC: 0.8680, test AP: 0.8596\n",
      "Epoch: 053,train AUC: 0.9223, train AP: 0.9088, loss:1.1076,val AUC: 0.8538, val AP: 0.8581,test AUC: 0.8680, test AP: 0.8606\n",
      "Epoch: 054,train AUC: 0.9236, train AP: 0.9118, loss:1.1010,val AUC: 0.8569, val AP: 0.8611,test AUC: 0.8711, test AP: 0.8645\n",
      "Epoch: 055,train AUC: 0.9244, train AP: 0.9136, loss:1.0869,val AUC: 0.8624, val AP: 0.8658,test AUC: 0.8737, test AP: 0.8665\n",
      "Epoch: 056,train AUC: 0.9261, train AP: 0.9149, loss:1.0985,val AUC: 0.8678, val AP: 0.8716,test AUC: 0.8754, test AP: 0.8684\n",
      "Epoch: 057,train AUC: 0.9266, train AP: 0.9149, loss:1.0904,val AUC: 0.8680, val AP: 0.8722,test AUC: 0.8744, test AP: 0.8693\n",
      "Epoch: 058,train AUC: 0.9257, train AP: 0.9140, loss:1.1075,val AUC: 0.8632, val AP: 0.8668,test AUC: 0.8721, test AP: 0.8650\n",
      "Epoch: 059,train AUC: 0.9243, train AP: 0.9126, loss:1.0938,val AUC: 0.8585, val AP: 0.8631,test AUC: 0.8691, test AP: 0.8631\n",
      "Epoch: 060,train AUC: 0.9243, train AP: 0.9127, loss:1.1093,val AUC: 0.8557, val AP: 0.8597,test AUC: 0.8675, test AP: 0.8621\n",
      "Epoch: 061,train AUC: 0.9244, train AP: 0.9123, loss:1.0704,val AUC: 0.8555, val AP: 0.8584,test AUC: 0.8667, test AP: 0.8612\n",
      "Epoch: 062,train AUC: 0.9270, train AP: 0.9144, loss:1.1092,val AUC: 0.8591, val AP: 0.8593,test AUC: 0.8697, test AP: 0.8618\n",
      "Epoch: 063,train AUC: 0.9291, train AP: 0.9166, loss:1.0997,val AUC: 0.8622, val AP: 0.8634,test AUC: 0.8714, test AP: 0.8609\n",
      "Epoch: 064,train AUC: 0.9290, train AP: 0.9169, loss:1.0999,val AUC: 0.8628, val AP: 0.8616,test AUC: 0.8715, test AP: 0.8593\n",
      "Epoch: 065,train AUC: 0.9285, train AP: 0.9164, loss:1.0927,val AUC: 0.8604, val AP: 0.8597,test AUC: 0.8701, test AP: 0.8590\n",
      "Epoch: 066,train AUC: 0.9290, train AP: 0.9167, loss:1.0756,val AUC: 0.8615, val AP: 0.8621,test AUC: 0.8717, test AP: 0.8614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 067,train AUC: 0.9295, train AP: 0.9172, loss:1.1057,val AUC: 0.8597, val AP: 0.8598,test AUC: 0.8692, test AP: 0.8580\n",
      "Epoch: 068,train AUC: 0.9297, train AP: 0.9181, loss:1.0818,val AUC: 0.8559, val AP: 0.8551,test AUC: 0.8671, test AP: 0.8559\n",
      "Epoch: 069,train AUC: 0.9310, train AP: 0.9205, loss:1.0768,val AUC: 0.8558, val AP: 0.8553,test AUC: 0.8694, test AP: 0.8586\n",
      "Epoch: 070,train AUC: 0.9328, train AP: 0.9226, loss:1.0880,val AUC: 0.8599, val AP: 0.8586,test AUC: 0.8738, test AP: 0.8627\n",
      "Epoch: 071,train AUC: 0.9337, train AP: 0.9225, loss:1.0863,val AUC: 0.8630, val AP: 0.8627,test AUC: 0.8761, test AP: 0.8648\n",
      "Epoch: 072,train AUC: 0.9338, train AP: 0.9224, loss:1.1005,val AUC: 0.8632, val AP: 0.8637,test AUC: 0.8781, test AP: 0.8671\n",
      "Epoch: 073,train AUC: 0.9335, train AP: 0.9216, loss:1.0860,val AUC: 0.8597, val AP: 0.8615,test AUC: 0.8781, test AP: 0.8672\n",
      "Epoch: 074,train AUC: 0.9329, train AP: 0.9210, loss:1.0802,val AUC: 0.8550, val AP: 0.8576,test AUC: 0.8767, test AP: 0.8679\n",
      "Epoch: 075,train AUC: 0.9328, train AP: 0.9206, loss:1.0738,val AUC: 0.8543, val AP: 0.8570,test AUC: 0.8755, test AP: 0.8661\n",
      "Epoch: 076,train AUC: 0.9341, train AP: 0.9225, loss:1.0479,val AUC: 0.8588, val AP: 0.8609,test AUC: 0.8772, test AP: 0.8661\n",
      "Epoch: 077,train AUC: 0.9366, train AP: 0.9263, loss:1.0524,val AUC: 0.8652, val AP: 0.8685,test AUC: 0.8804, test AP: 0.8701\n",
      "Epoch: 078,train AUC: 0.9377, train AP: 0.9283, loss:1.0600,val AUC: 0.8665, val AP: 0.8714,test AUC: 0.8814, test AP: 0.8724\n",
      "Epoch: 079,train AUC: 0.9369, train AP: 0.9278, loss:1.0322,val AUC: 0.8643, val AP: 0.8697,test AUC: 0.8788, test AP: 0.8703\n",
      "Epoch: 080,train AUC: 0.9362, train AP: 0.9268, loss:1.0313,val AUC: 0.8608, val AP: 0.8671,test AUC: 0.8767, test AP: 0.8677\n",
      "Epoch: 081,train AUC: 0.9364, train AP: 0.9264, loss:1.0540,val AUC: 0.8592, val AP: 0.8634,test AUC: 0.8788, test AP: 0.8698\n",
      "Epoch: 082,train AUC: 0.9370, train AP: 0.9269, loss:1.0438,val AUC: 0.8620, val AP: 0.8649,test AUC: 0.8833, test AP: 0.8744\n",
      "Epoch: 083,train AUC: 0.9388, train AP: 0.9291, loss:1.0441,val AUC: 0.8671, val AP: 0.8701,test AUC: 0.8861, test AP: 0.8786\n",
      "Epoch: 084,train AUC: 0.9396, train AP: 0.9303, loss:1.0485,val AUC: 0.8708, val AP: 0.8738,test AUC: 0.8868, test AP: 0.8806\n",
      "Epoch: 085,train AUC: 0.9399, train AP: 0.9310, loss:1.0456,val AUC: 0.8725, val AP: 0.8756,test AUC: 0.8881, test AP: 0.8852\n",
      "Epoch: 086,train AUC: 0.9399, train AP: 0.9312, loss:1.0447,val AUC: 0.8729, val AP: 0.8770,test AUC: 0.8868, test AP: 0.8844\n",
      "Epoch: 087,train AUC: 0.9402, train AP: 0.9317, loss:1.0296,val AUC: 0.8747, val AP: 0.8788,test AUC: 0.8877, test AP: 0.8853\n",
      "Epoch: 088,train AUC: 0.9395, train AP: 0.9304, loss:1.0140,val AUC: 0.8738, val AP: 0.8785,test AUC: 0.8854, test AP: 0.8814\n",
      "Epoch: 089,train AUC: 0.9383, train AP: 0.9280, loss:1.0393,val AUC: 0.8717, val AP: 0.8770,test AUC: 0.8811, test AP: 0.8726\n",
      "Epoch: 090,train AUC: 0.9387, train AP: 0.9282, loss:1.0460,val AUC: 0.8703, val AP: 0.8758,test AUC: 0.8828, test AP: 0.8749\n",
      "Epoch: 091,train AUC: 0.9395, train AP: 0.9293, loss:1.0496,val AUC: 0.8722, val AP: 0.8766,test AUC: 0.8872, test AP: 0.8811\n",
      "Epoch: 092,train AUC: 0.9405, train AP: 0.9304, loss:1.0124,val AUC: 0.8753, val AP: 0.8785,test AUC: 0.8906, test AP: 0.8851\n",
      "Epoch: 093,train AUC: 0.9410, train AP: 0.9306, loss:1.0227,val AUC: 0.8755, val AP: 0.8788,test AUC: 0.8925, test AP: 0.8876\n",
      "Epoch: 094,train AUC: 0.9404, train AP: 0.9301, loss:1.0296,val AUC: 0.8725, val AP: 0.8770,test AUC: 0.8926, test AP: 0.8885\n",
      "Epoch: 095,train AUC: 0.9409, train AP: 0.9307, loss:1.0196,val AUC: 0.8725, val AP: 0.8776,test AUC: 0.8934, test AP: 0.8880\n",
      "Epoch: 096,train AUC: 0.9414, train AP: 0.9315, loss:1.0149,val AUC: 0.8743, val AP: 0.8793,test AUC: 0.8932, test AP: 0.8867\n",
      "Epoch: 097,train AUC: 0.9419, train AP: 0.9325, loss:1.0269,val AUC: 0.8764, val AP: 0.8826,test AUC: 0.8932, test AP: 0.8875\n",
      "Epoch: 098,train AUC: 0.9421, train AP: 0.9331, loss:1.0179,val AUC: 0.8778, val AP: 0.8841,test AUC: 0.8898, test AP: 0.8854\n",
      "Epoch: 099,train AUC: 0.9425, train AP: 0.9340, loss:1.0054,val AUC: 0.8782, val AP: 0.8843,test AUC: 0.8879, test AP: 0.8846\n",
      "Epoch: 100,train AUC: 0.9440, train AP: 0.9360, loss:1.0048,val AUC: 0.8803, val AP: 0.8869,test AUC: 0.8901, test AP: 0.8887\n",
      "Epoch: 101,train AUC: 0.9438, train AP: 0.9356, loss:1.0075,val AUC: 0.8816, val AP: 0.8870,test AUC: 0.8917, test AP: 0.8912\n",
      "Epoch: 102,train AUC: 0.9442, train AP: 0.9356, loss:1.0117,val AUC: 0.8814, val AP: 0.8860,test AUC: 0.8920, test AP: 0.8909\n",
      "Epoch: 103,train AUC: 0.9434, train AP: 0.9343, loss:1.0157,val AUC: 0.8805, val AP: 0.8837,test AUC: 0.8909, test AP: 0.8915\n",
      "Epoch: 104,train AUC: 0.9419, train AP: 0.9324, loss:1.0080,val AUC: 0.8777, val AP: 0.8809,test AUC: 0.8883, test AP: 0.8887\n",
      "Epoch: 105,train AUC: 0.9431, train AP: 0.9343, loss:1.0146,val AUC: 0.8797, val AP: 0.8833,test AUC: 0.8901, test AP: 0.8912\n",
      "Epoch: 106,train AUC: 0.9450, train AP: 0.9367, loss:1.0120,val AUC: 0.8830, val AP: 0.8860,test AUC: 0.8933, test AP: 0.8950\n",
      "Epoch: 107,train AUC: 0.9448, train AP: 0.9364, loss:1.0001,val AUC: 0.8822, val AP: 0.8854,test AUC: 0.8938, test AP: 0.8936\n",
      "Epoch: 108,train AUC: 0.9437, train AP: 0.9349, loss:1.0042,val AUC: 0.8801, val AP: 0.8829,test AUC: 0.8923, test AP: 0.8911\n",
      "Epoch: 109,train AUC: 0.9427, train AP: 0.9336, loss:0.9878,val AUC: 0.8785, val AP: 0.8813,test AUC: 0.8900, test AP: 0.8883\n",
      "Epoch: 110,train AUC: 0.9428, train AP: 0.9337, loss:0.9969,val AUC: 0.8803, val AP: 0.8831,test AUC: 0.8908, test AP: 0.8872\n",
      "Epoch: 111,train AUC: 0.9441, train AP: 0.9351, loss:1.0114,val AUC: 0.8829, val AP: 0.8862,test AUC: 0.8945, test AP: 0.8910\n",
      "Epoch: 112,train AUC: 0.9452, train AP: 0.9368, loss:0.9945,val AUC: 0.8853, val AP: 0.8882,test AUC: 0.8971, test AP: 0.8931\n",
      "Epoch: 113,train AUC: 0.9457, train AP: 0.9370, loss:1.0241,val AUC: 0.8859, val AP: 0.8888,test AUC: 0.8963, test AP: 0.8928\n",
      "Epoch: 114,train AUC: 0.9454, train AP: 0.9367, loss:1.0163,val AUC: 0.8856, val AP: 0.8905,test AUC: 0.8941, test AP: 0.8910\n",
      "Epoch: 115,train AUC: 0.9456, train AP: 0.9366, loss:0.9965,val AUC: 0.8845, val AP: 0.8888,test AUC: 0.8940, test AP: 0.8896\n",
      "Epoch: 116,train AUC: 0.9457, train AP: 0.9367, loss:0.9958,val AUC: 0.8853, val AP: 0.8907,test AUC: 0.8948, test AP: 0.8917\n",
      "Epoch: 117,train AUC: 0.9460, train AP: 0.9366, loss:0.9955,val AUC: 0.8852, val AP: 0.8904,test AUC: 0.8947, test AP: 0.8921\n",
      "Epoch: 118,train AUC: 0.9468, train AP: 0.9375, loss:1.0137,val AUC: 0.8864, val AP: 0.8929,test AUC: 0.8959, test AP: 0.8942\n",
      "Epoch: 119,train AUC: 0.9467, train AP: 0.9373, loss:1.0082,val AUC: 0.8858, val AP: 0.8915,test AUC: 0.8958, test AP: 0.8939\n",
      "Epoch: 120,train AUC: 0.9469, train AP: 0.9374, loss:1.0006,val AUC: 0.8865, val AP: 0.8931,test AUC: 0.8962, test AP: 0.8940\n",
      "Epoch: 121,train AUC: 0.9476, train AP: 0.9382, loss:1.0199,val AUC: 0.8863, val AP: 0.8937,test AUC: 0.8970, test AP: 0.8953\n",
      "Epoch: 122,train AUC: 0.9469, train AP: 0.9374, loss:1.0114,val AUC: 0.8847, val AP: 0.8916,test AUC: 0.8952, test AP: 0.8935\n",
      "Epoch: 123,train AUC: 0.9472, train AP: 0.9381, loss:1.0025,val AUC: 0.8849, val AP: 0.8922,test AUC: 0.8953, test AP: 0.8967\n",
      "Epoch: 124,train AUC: 0.9479, train AP: 0.9390, loss:0.9865,val AUC: 0.8857, val AP: 0.8932,test AUC: 0.8955, test AP: 0.8971\n",
      "Epoch: 125,train AUC: 0.9493, train AP: 0.9413, loss:1.0089,val AUC: 0.8888, val AP: 0.8960,test AUC: 0.8970, test AP: 0.8984\n",
      "Epoch: 126,train AUC: 0.9494, train AP: 0.9415, loss:0.9891,val AUC: 0.8897, val AP: 0.8966,test AUC: 0.8979, test AP: 0.9000\n",
      "Epoch: 127,train AUC: 0.9488, train AP: 0.9405, loss:0.9995,val AUC: 0.8889, val AP: 0.8961,test AUC: 0.8978, test AP: 0.9002\n",
      "Epoch: 128,train AUC: 0.9476, train AP: 0.9389, loss:1.0017,val AUC: 0.8861, val AP: 0.8939,test AUC: 0.8971, test AP: 0.8999\n",
      "Epoch: 129,train AUC: 0.9468, train AP: 0.9379, loss:1.0094,val AUC: 0.8837, val AP: 0.8911,test AUC: 0.8962, test AP: 0.8992\n",
      "Epoch: 130,train AUC: 0.9480, train AP: 0.9397, loss:1.0113,val AUC: 0.8861, val AP: 0.8939,test AUC: 0.8978, test AP: 0.9013\n",
      "Epoch: 131,train AUC: 0.9492, train AP: 0.9417, loss:0.9781,val AUC: 0.8903, val AP: 0.8977,test AUC: 0.8994, test AP: 0.9027\n",
      "Epoch: 132,train AUC: 0.9495, train AP: 0.9420, loss:0.9898,val AUC: 0.8924, val AP: 0.8993,test AUC: 0.9003, test AP: 0.9034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 133,train AUC: 0.9497, train AP: 0.9424, loss:0.9980,val AUC: 0.8930, val AP: 0.8995,test AUC: 0.9009, test AP: 0.9033\n",
      "Epoch: 134,train AUC: 0.9494, train AP: 0.9421, loss:0.9937,val AUC: 0.8920, val AP: 0.8984,test AUC: 0.9006, test AP: 0.9031\n",
      "Epoch: 135,train AUC: 0.9485, train AP: 0.9409, loss:0.9881,val AUC: 0.8881, val AP: 0.8943,test AUC: 0.8980, test AP: 0.9005\n",
      "Epoch: 136,train AUC: 0.9481, train AP: 0.9400, loss:1.0112,val AUC: 0.8866, val AP: 0.8932,test AUC: 0.8964, test AP: 0.8984\n",
      "Epoch: 137,train AUC: 0.9494, train AP: 0.9414, loss:0.9791,val AUC: 0.8882, val AP: 0.8940,test AUC: 0.8991, test AP: 0.9005\n",
      "Epoch: 138,train AUC: 0.9504, train AP: 0.9427, loss:1.0085,val AUC: 0.8905, val AP: 0.8955,test AUC: 0.9020, test AP: 0.9034\n",
      "Epoch: 139,train AUC: 0.9514, train AP: 0.9438, loss:0.9890,val AUC: 0.8924, val AP: 0.8975,test AUC: 0.9038, test AP: 0.9054\n",
      "Epoch: 140,train AUC: 0.9527, train AP: 0.9446, loss:1.0090,val AUC: 0.8944, val AP: 0.9001,test AUC: 0.9065, test AP: 0.9087\n",
      "Epoch: 141,train AUC: 0.9530, train AP: 0.9447, loss:0.9968,val AUC: 0.8931, val AP: 0.8994,test AUC: 0.9057, test AP: 0.9087\n",
      "Epoch: 142,train AUC: 0.9517, train AP: 0.9432, loss:1.0000,val AUC: 0.8896, val AP: 0.8962,test AUC: 0.9026, test AP: 0.9059\n",
      "Epoch: 143,train AUC: 0.9520, train AP: 0.9438, loss:0.9739,val AUC: 0.8913, val AP: 0.8974,test AUC: 0.9034, test AP: 0.9054\n",
      "Epoch: 144,train AUC: 0.9527, train AP: 0.9448, loss:0.9755,val AUC: 0.8943, val AP: 0.9002,test AUC: 0.9053, test AP: 0.9072\n",
      "Epoch: 145,train AUC: 0.9524, train AP: 0.9447, loss:0.9852,val AUC: 0.8954, val AP: 0.8997,test AUC: 0.9059, test AP: 0.9075\n",
      "Epoch: 146,train AUC: 0.9521, train AP: 0.9440, loss:0.9705,val AUC: 0.8959, val AP: 0.9001,test AUC: 0.9053, test AP: 0.9068\n",
      "Epoch: 147,train AUC: 0.9521, train AP: 0.9439, loss:0.9837,val AUC: 0.8961, val AP: 0.9020,test AUC: 0.9050, test AP: 0.9077\n",
      "Epoch: 148,train AUC: 0.9522, train AP: 0.9439, loss:0.9967,val AUC: 0.8956, val AP: 0.9020,test AUC: 0.9053, test AP: 0.9087\n",
      "Epoch: 149,train AUC: 0.9526, train AP: 0.9443, loss:0.9927,val AUC: 0.8964, val AP: 0.9028,test AUC: 0.9074, test AP: 0.9107\n",
      "Epoch: 150,train AUC: 0.9522, train AP: 0.9442, loss:0.9839,val AUC: 0.8955, val AP: 0.9024,test AUC: 0.9076, test AP: 0.9105\n",
      "Epoch: 151,train AUC: 0.9520, train AP: 0.9442, loss:0.9583,val AUC: 0.8949, val AP: 0.9017,test AUC: 0.9078, test AP: 0.9110\n",
      "Epoch: 152,train AUC: 0.9527, train AP: 0.9451, loss:0.9709,val AUC: 0.8967, val AP: 0.9027,test AUC: 0.9096, test AP: 0.9124\n",
      "Epoch: 153,train AUC: 0.9531, train AP: 0.9454, loss:0.9834,val AUC: 0.8977, val AP: 0.9038,test AUC: 0.9102, test AP: 0.9128\n",
      "Epoch: 154,train AUC: 0.9537, train AP: 0.9460, loss:0.9819,val AUC: 0.8991, val AP: 0.9058,test AUC: 0.9110, test AP: 0.9140\n",
      "Epoch: 155,train AUC: 0.9542, train AP: 0.9465, loss:0.9835,val AUC: 0.9002, val AP: 0.9078,test AUC: 0.9107, test AP: 0.9147\n",
      "Epoch: 156,train AUC: 0.9545, train AP: 0.9464, loss:0.9911,val AUC: 0.9006, val AP: 0.9094,test AUC: 0.9108, test AP: 0.9148\n",
      "Epoch: 157,train AUC: 0.9541, train AP: 0.9461, loss:0.9868,val AUC: 0.8996, val AP: 0.9088,test AUC: 0.9103, test AP: 0.9144\n",
      "Epoch: 158,train AUC: 0.9537, train AP: 0.9455, loss:0.9685,val AUC: 0.8989, val AP: 0.9071,test AUC: 0.9098, test AP: 0.9141\n",
      "Epoch: 159,train AUC: 0.9548, train AP: 0.9468, loss:0.9855,val AUC: 0.9010, val AP: 0.9083,test AUC: 0.9123, test AP: 0.9163\n",
      "Epoch: 160,train AUC: 0.9562, train AP: 0.9482, loss:0.9765,val AUC: 0.9032, val AP: 0.9101,test AUC: 0.9140, test AP: 0.9175\n",
      "Epoch: 161,train AUC: 0.9560, train AP: 0.9480, loss:1.0021,val AUC: 0.9035, val AP: 0.9102,test AUC: 0.9123, test AP: 0.9152\n",
      "Epoch: 162,train AUC: 0.9554, train AP: 0.9473, loss:0.9669,val AUC: 0.9010, val AP: 0.9078,test AUC: 0.9105, test AP: 0.9133\n",
      "Epoch: 163,train AUC: 0.9559, train AP: 0.9477, loss:0.9756,val AUC: 0.8995, val AP: 0.9070,test AUC: 0.9108, test AP: 0.9131\n",
      "Epoch: 164,train AUC: 0.9567, train AP: 0.9488, loss:0.9844,val AUC: 0.8996, val AP: 0.9066,test AUC: 0.9125, test AP: 0.9146\n",
      "Epoch: 165,train AUC: 0.9570, train AP: 0.9498, loss:0.9672,val AUC: 0.9001, val AP: 0.9052,test AUC: 0.9132, test AP: 0.9152\n",
      "Epoch: 166,train AUC: 0.9562, train AP: 0.9492, loss:0.9628,val AUC: 0.8967, val AP: 0.9020,test AUC: 0.9104, test AP: 0.9132\n",
      "Epoch: 167,train AUC: 0.9557, train AP: 0.9485, loss:0.9642,val AUC: 0.8944, val AP: 0.8997,test AUC: 0.9073, test AP: 0.9103\n",
      "Epoch: 168,train AUC: 0.9577, train AP: 0.9508, loss:0.9682,val AUC: 0.8970, val AP: 0.9024,test AUC: 0.9101, test AP: 0.9118\n",
      "Epoch: 169,train AUC: 0.9580, train AP: 0.9509, loss:0.9589,val AUC: 0.8973, val AP: 0.9027,test AUC: 0.9115, test AP: 0.9129\n",
      "Epoch: 170,train AUC: 0.9569, train AP: 0.9492, loss:0.9594,val AUC: 0.8972, val AP: 0.9019,test AUC: 0.9107, test AP: 0.9124\n",
      "Epoch: 171,train AUC: 0.9562, train AP: 0.9486, loss:0.9709,val AUC: 0.8966, val AP: 0.9011,test AUC: 0.9098, test AP: 0.9127\n",
      "Epoch: 172,train AUC: 0.9560, train AP: 0.9483, loss:0.9696,val AUC: 0.8963, val AP: 0.9012,test AUC: 0.9105, test AP: 0.9143\n",
      "Epoch: 173,train AUC: 0.9570, train AP: 0.9490, loss:0.9633,val AUC: 0.8978, val AP: 0.9028,test AUC: 0.9132, test AP: 0.9176\n",
      "Epoch: 174,train AUC: 0.9571, train AP: 0.9489, loss:0.9503,val AUC: 0.8990, val AP: 0.9038,test AUC: 0.9128, test AP: 0.9172\n",
      "Epoch: 175,train AUC: 0.9565, train AP: 0.9482, loss:0.9590,val AUC: 0.8989, val AP: 0.9040,test AUC: 0.9107, test AP: 0.9147\n",
      "Epoch: 176,train AUC: 0.9571, train AP: 0.9488, loss:0.9670,val AUC: 0.8991, val AP: 0.9028,test AUC: 0.9098, test AP: 0.9142\n",
      "Epoch: 177,train AUC: 0.9581, train AP: 0.9505, loss:0.9727,val AUC: 0.9023, val AP: 0.9064,test AUC: 0.9121, test AP: 0.9174\n",
      "Epoch: 178,train AUC: 0.9581, train AP: 0.9513, loss:0.9609,val AUC: 0.9025, val AP: 0.9067,test AUC: 0.9144, test AP: 0.9192\n",
      "Epoch: 179,train AUC: 0.9578, train AP: 0.9515, loss:0.9721,val AUC: 0.9018, val AP: 0.9063,test AUC: 0.9151, test AP: 0.9190\n",
      "Epoch: 180,train AUC: 0.9575, train AP: 0.9512, loss:0.9607,val AUC: 0.9001, val AP: 0.9052,test AUC: 0.9149, test AP: 0.9180\n",
      "Epoch: 181,train AUC: 0.9573, train AP: 0.9502, loss:0.9525,val AUC: 0.8991, val AP: 0.9042,test AUC: 0.9153, test AP: 0.9179\n",
      "Epoch: 182,train AUC: 0.9575, train AP: 0.9499, loss:0.9723,val AUC: 0.9003, val AP: 0.9043,test AUC: 0.9149, test AP: 0.9171\n",
      "Epoch: 183,train AUC: 0.9585, train AP: 0.9517, loss:0.9654,val AUC: 0.9006, val AP: 0.9046,test AUC: 0.9159, test AP: 0.9190\n",
      "Epoch: 184,train AUC: 0.9586, train AP: 0.9524, loss:0.9642,val AUC: 0.8995, val AP: 0.9033,test AUC: 0.9156, test AP: 0.9196\n",
      "Epoch: 185,train AUC: 0.9582, train AP: 0.9520, loss:0.9691,val AUC: 0.8987, val AP: 0.9022,test AUC: 0.9154, test AP: 0.9192\n",
      "Epoch: 186,train AUC: 0.9579, train AP: 0.9516, loss:0.9587,val AUC: 0.8961, val AP: 0.8999,test AUC: 0.9153, test AP: 0.9175\n",
      "Epoch: 187,train AUC: 0.9566, train AP: 0.9491, loss:0.9759,val AUC: 0.8956, val AP: 0.8979,test AUC: 0.9158, test AP: 0.9151\n",
      "Epoch: 188,train AUC: 0.9563, train AP: 0.9482, loss:0.9788,val AUC: 0.8942, val AP: 0.8979,test AUC: 0.9133, test AP: 0.9114\n",
      "Epoch: 189,train AUC: 0.9570, train AP: 0.9491, loss:0.9725,val AUC: 0.8971, val AP: 0.9018,test AUC: 0.9144, test AP: 0.9120\n",
      "Epoch: 190,train AUC: 0.9567, train AP: 0.9484, loss:0.9705,val AUC: 0.8970, val AP: 0.9010,test AUC: 0.9135, test AP: 0.9116\n",
      "Epoch: 191,train AUC: 0.9560, train AP: 0.9476, loss:0.9791,val AUC: 0.8955, val AP: 0.8993,test AUC: 0.9111, test AP: 0.9107\n",
      "Epoch: 192,train AUC: 0.9563, train AP: 0.9474, loss:0.9803,val AUC: 0.8955, val AP: 0.8976,test AUC: 0.9109, test AP: 0.9093\n",
      "Epoch: 193,train AUC: 0.9576, train AP: 0.9487, loss:0.9681,val AUC: 0.8968, val AP: 0.8992,test AUC: 0.9127, test AP: 0.9102\n",
      "Epoch: 194,train AUC: 0.9587, train AP: 0.9501, loss:0.9713,val AUC: 0.9003, val AP: 0.9025,test AUC: 0.9137, test AP: 0.9112\n",
      "Epoch: 195,train AUC: 0.9601, train AP: 0.9524, loss:0.9895,val AUC: 0.9044, val AP: 0.9060,test AUC: 0.9158, test AP: 0.9146\n",
      "Epoch: 196,train AUC: 0.9602, train AP: 0.9534, loss:0.9662,val AUC: 0.9033, val AP: 0.9058,test AUC: 0.9142, test AP: 0.9147\n",
      "Epoch: 197,train AUC: 0.9597, train AP: 0.9530, loss:0.9645,val AUC: 0.9023, val AP: 0.9057,test AUC: 0.9117, test AP: 0.9140\n",
      "Epoch: 198,train AUC: 0.9606, train AP: 0.9539, loss:0.9659,val AUC: 0.9026, val AP: 0.9055,test AUC: 0.9129, test AP: 0.9143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 199,train AUC: 0.9609, train AP: 0.9539, loss:0.9578,val AUC: 0.9016, val AP: 0.9040,test AUC: 0.9148, test AP: 0.9153\n",
      "Epoch: 200,train AUC: 0.9604, train AP: 0.9534, loss:0.9419,val AUC: 0.9000, val AP: 0.9026,test AUC: 0.9138, test AP: 0.9141\n",
      "Final Test epoch:195.0000,Final Test AUC: 0.9158,Final Test AP:0.9146\n",
      "Epoch: 001,train AUC: 0.7910, train AP: 0.7708, loss:1.5475,val AUC: 0.7349, val AP: 0.7406,test AUC: 0.7450, test AP: 0.7324\n",
      "Epoch: 002,train AUC: 0.7932, train AP: 0.7744, loss:1.3370,val AUC: 0.7581, val AP: 0.7546,test AUC: 0.7544, test AP: 0.7407\n",
      "Epoch: 003,train AUC: 0.7816, train AP: 0.7694, loss:1.3454,val AUC: 0.7352, val AP: 0.7351,test AUC: 0.7458, test AP: 0.7389\n",
      "Epoch: 004,train AUC: 0.7865, train AP: 0.7749, loss:1.3081,val AUC: 0.7384, val AP: 0.7418,test AUC: 0.7491, test AP: 0.7413\n",
      "Epoch: 005,train AUC: 0.7941, train AP: 0.7827, loss:1.2933,val AUC: 0.7476, val AP: 0.7504,test AUC: 0.7534, test AP: 0.7480\n",
      "Epoch: 006,train AUC: 0.7981, train AP: 0.7879, loss:1.2798,val AUC: 0.7529, val AP: 0.7569,test AUC: 0.7571, test AP: 0.7521\n",
      "Epoch: 007,train AUC: 0.7995, train AP: 0.7916, loss:1.2834,val AUC: 0.7534, val AP: 0.7604,test AUC: 0.7573, test AP: 0.7532\n",
      "Epoch: 008,train AUC: 0.8021, train AP: 0.7948, loss:1.2876,val AUC: 0.7551, val AP: 0.7648,test AUC: 0.7590, test AP: 0.7572\n",
      "Epoch: 009,train AUC: 0.8102, train AP: 0.8031, loss:1.2610,val AUC: 0.7682, val AP: 0.7762,test AUC: 0.7693, test AP: 0.7678\n",
      "Epoch: 010,train AUC: 0.8197, train AP: 0.8114, loss:1.2818,val AUC: 0.7697, val AP: 0.7780,test AUC: 0.7751, test AP: 0.7762\n",
      "Epoch: 011,train AUC: 0.8263, train AP: 0.8181, loss:1.2596,val AUC: 0.7770, val AP: 0.7860,test AUC: 0.7832, test AP: 0.7844\n",
      "Epoch: 012,train AUC: 0.8331, train AP: 0.8238, loss:1.2465,val AUC: 0.7824, val AP: 0.7921,test AUC: 0.7887, test AP: 0.7894\n",
      "Epoch: 013,train AUC: 0.8349, train AP: 0.8269, loss:1.2423,val AUC: 0.7814, val AP: 0.7900,test AUC: 0.7901, test AP: 0.7936\n",
      "Epoch: 014,train AUC: 0.8354, train AP: 0.8286, loss:1.2540,val AUC: 0.7756, val AP: 0.7855,test AUC: 0.7884, test AP: 0.7938\n",
      "Epoch: 015,train AUC: 0.8374, train AP: 0.8309, loss:1.2789,val AUC: 0.7766, val AP: 0.7875,test AUC: 0.7894, test AP: 0.7956\n",
      "Epoch: 016,train AUC: 0.8391, train AP: 0.8329, loss:1.2576,val AUC: 0.7787, val AP: 0.7917,test AUC: 0.7918, test AP: 0.7984\n",
      "Epoch: 017,train AUC: 0.8444, train AP: 0.8379, loss:1.2684,val AUC: 0.7848, val AP: 0.7971,test AUC: 0.7972, test AP: 0.8027\n",
      "Epoch: 018,train AUC: 0.8498, train AP: 0.8418, loss:1.2527,val AUC: 0.7883, val AP: 0.8009,test AUC: 0.8017, test AP: 0.8068\n",
      "Epoch: 019,train AUC: 0.8547, train AP: 0.8446, loss:1.2011,val AUC: 0.7860, val AP: 0.7987,test AUC: 0.8029, test AP: 0.8086\n",
      "Epoch: 020,train AUC: 0.8563, train AP: 0.8466, loss:1.2175,val AUC: 0.7833, val AP: 0.7983,test AUC: 0.8030, test AP: 0.8099\n",
      "Epoch: 021,train AUC: 0.8587, train AP: 0.8493, loss:1.2027,val AUC: 0.7875, val AP: 0.8033,test AUC: 0.8042, test AP: 0.8097\n",
      "Epoch: 022,train AUC: 0.8605, train AP: 0.8502, loss:1.2164,val AUC: 0.7970, val AP: 0.8108,test AUC: 0.8082, test AP: 0.8103\n",
      "Epoch: 023,train AUC: 0.8656, train AP: 0.8553, loss:1.2001,val AUC: 0.7970, val AP: 0.8129,test AUC: 0.8111, test AP: 0.8142\n",
      "Epoch: 024,train AUC: 0.8665, train AP: 0.8559, loss:1.2018,val AUC: 0.7984, val AP: 0.8161,test AUC: 0.8106, test AP: 0.8160\n",
      "Epoch: 025,train AUC: 0.8667, train AP: 0.8562, loss:1.1991,val AUC: 0.8034, val AP: 0.8222,test AUC: 0.8121, test AP: 0.8177\n",
      "Epoch: 026,train AUC: 0.8697, train AP: 0.8588, loss:1.2087,val AUC: 0.8084, val AP: 0.8273,test AUC: 0.8175, test AP: 0.8217\n",
      "Epoch: 027,train AUC: 0.8730, train AP: 0.8618, loss:1.2074,val AUC: 0.8140, val AP: 0.8263,test AUC: 0.8201, test AP: 0.8235\n",
      "Epoch: 028,train AUC: 0.8776, train AP: 0.8653, loss:1.1806,val AUC: 0.8173, val AP: 0.8272,test AUC: 0.8220, test AP: 0.8255\n",
      "Epoch: 029,train AUC: 0.8792, train AP: 0.8668, loss:1.2271,val AUC: 0.8184, val AP: 0.8267,test AUC: 0.8220, test AP: 0.8253\n",
      "Epoch: 030,train AUC: 0.8810, train AP: 0.8680, loss:1.1972,val AUC: 0.8220, val AP: 0.8277,test AUC: 0.8261, test AP: 0.8290\n",
      "Epoch: 031,train AUC: 0.8839, train AP: 0.8707, loss:1.1899,val AUC: 0.8256, val AP: 0.8323,test AUC: 0.8321, test AP: 0.8344\n",
      "Epoch: 032,train AUC: 0.8866, train AP: 0.8734, loss:1.2122,val AUC: 0.8280, val AP: 0.8357,test AUC: 0.8349, test AP: 0.8360\n",
      "Epoch: 033,train AUC: 0.8862, train AP: 0.8725, loss:1.1570,val AUC: 0.8243, val AP: 0.8367,test AUC: 0.8340, test AP: 0.8344\n",
      "Epoch: 034,train AUC: 0.8841, train AP: 0.8714, loss:1.1865,val AUC: 0.8207, val AP: 0.8350,test AUC: 0.8301, test AP: 0.8333\n",
      "Epoch: 035,train AUC: 0.8828, train AP: 0.8709, loss:1.1754,val AUC: 0.8178, val AP: 0.8330,test AUC: 0.8304, test AP: 0.8334\n",
      "Epoch: 036,train AUC: 0.8847, train AP: 0.8724, loss:1.1621,val AUC: 0.8208, val AP: 0.8349,test AUC: 0.8345, test AP: 0.8367\n",
      "Epoch: 037,train AUC: 0.8892, train AP: 0.8766, loss:1.1578,val AUC: 0.8276, val AP: 0.8396,test AUC: 0.8390, test AP: 0.8423\n",
      "Epoch: 038,train AUC: 0.8927, train AP: 0.8783, loss:1.1480,val AUC: 0.8271, val AP: 0.8389,test AUC: 0.8402, test AP: 0.8436\n",
      "Epoch: 039,train AUC: 0.8950, train AP: 0.8806, loss:1.1718,val AUC: 0.8313, val AP: 0.8409,test AUC: 0.8435, test AP: 0.8476\n",
      "Epoch: 040,train AUC: 0.8966, train AP: 0.8834, loss:1.1474,val AUC: 0.8379, val AP: 0.8461,test AUC: 0.8484, test AP: 0.8525\n",
      "Epoch: 041,train AUC: 0.8974, train AP: 0.8852, loss:1.1669,val AUC: 0.8390, val AP: 0.8489,test AUC: 0.8504, test AP: 0.8555\n",
      "Epoch: 042,train AUC: 0.8984, train AP: 0.8863, loss:1.1383,val AUC: 0.8396, val AP: 0.8507,test AUC: 0.8522, test AP: 0.8574\n",
      "Epoch: 043,train AUC: 0.8996, train AP: 0.8861, loss:1.1443,val AUC: 0.8396, val AP: 0.8525,test AUC: 0.8523, test AP: 0.8583\n",
      "Epoch: 044,train AUC: 0.8999, train AP: 0.8850, loss:1.1378,val AUC: 0.8390, val AP: 0.8538,test AUC: 0.8506, test AP: 0.8571\n",
      "Epoch: 045,train AUC: 0.9017, train AP: 0.8871, loss:1.1444,val AUC: 0.8447, val AP: 0.8575,test AUC: 0.8549, test AP: 0.8596\n",
      "Epoch: 046,train AUC: 0.9023, train AP: 0.8887, loss:1.1529,val AUC: 0.8502, val AP: 0.8623,test AUC: 0.8562, test AP: 0.8612\n",
      "Epoch: 047,train AUC: 0.9045, train AP: 0.8900, loss:1.1134,val AUC: 0.8523, val AP: 0.8635,test AUC: 0.8588, test AP: 0.8620\n",
      "Epoch: 048,train AUC: 0.9059, train AP: 0.8901, loss:1.1307,val AUC: 0.8515, val AP: 0.8624,test AUC: 0.8579, test AP: 0.8604\n",
      "Epoch: 049,train AUC: 0.9050, train AP: 0.8886, loss:1.1170,val AUC: 0.8497, val AP: 0.8609,test AUC: 0.8538, test AP: 0.8559\n",
      "Epoch: 050,train AUC: 0.9061, train AP: 0.8910, loss:1.1212,val AUC: 0.8502, val AP: 0.8610,test AUC: 0.8530, test AP: 0.8568\n",
      "Epoch: 051,train AUC: 0.9078, train AP: 0.8951, loss:1.1371,val AUC: 0.8551, val AP: 0.8647,test AUC: 0.8579, test AP: 0.8618\n",
      "Epoch: 052,train AUC: 0.9085, train AP: 0.8974, loss:1.1171,val AUC: 0.8589, val AP: 0.8679,test AUC: 0.8594, test AP: 0.8626\n",
      "Epoch: 053,train AUC: 0.9108, train AP: 0.8984, loss:1.1021,val AUC: 0.8665, val AP: 0.8709,test AUC: 0.8617, test AP: 0.8601\n",
      "Epoch: 054,train AUC: 0.9130, train AP: 0.8986, loss:1.1248,val AUC: 0.8641, val AP: 0.8686,test AUC: 0.8614, test AP: 0.8624\n",
      "Epoch: 055,train AUC: 0.9130, train AP: 0.8977, loss:1.1168,val AUC: 0.8613, val AP: 0.8640,test AUC: 0.8602, test AP: 0.8614\n",
      "Epoch: 056,train AUC: 0.9145, train AP: 0.9005, loss:1.1092,val AUC: 0.8648, val AP: 0.8692,test AUC: 0.8647, test AP: 0.8654\n",
      "Epoch: 057,train AUC: 0.9146, train AP: 0.9018, loss:1.1072,val AUC: 0.8667, val AP: 0.8706,test AUC: 0.8664, test AP: 0.8684\n",
      "Epoch: 058,train AUC: 0.9141, train AP: 0.9015, loss:1.0913,val AUC: 0.8650, val AP: 0.8705,test AUC: 0.8644, test AP: 0.8678\n",
      "Epoch: 059,train AUC: 0.9148, train AP: 0.9015, loss:1.1135,val AUC: 0.8632, val AP: 0.8694,test AUC: 0.8652, test AP: 0.8675\n",
      "Epoch: 060,train AUC: 0.9152, train AP: 0.9011, loss:1.1009,val AUC: 0.8615, val AP: 0.8678,test AUC: 0.8630, test AP: 0.8626\n",
      "Epoch: 061,train AUC: 0.9166, train AP: 0.9028, loss:1.0881,val AUC: 0.8634, val AP: 0.8708,test AUC: 0.8644, test AP: 0.8631\n",
      "Epoch: 062,train AUC: 0.9179, train AP: 0.9052, loss:1.1138,val AUC: 0.8674, val AP: 0.8746,test AUC: 0.8656, test AP: 0.8640\n",
      "Epoch: 063,train AUC: 0.9180, train AP: 0.9060, loss:1.0936,val AUC: 0.8670, val AP: 0.8746,test AUC: 0.8654, test AP: 0.8643\n",
      "Epoch: 064,train AUC: 0.9182, train AP: 0.9050, loss:1.0885,val AUC: 0.8663, val AP: 0.8735,test AUC: 0.8624, test AP: 0.8619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 065,train AUC: 0.9188, train AP: 0.9043, loss:1.0812,val AUC: 0.8666, val AP: 0.8734,test AUC: 0.8640, test AP: 0.8613\n",
      "Epoch: 066,train AUC: 0.9212, train AP: 0.9070, loss:1.1038,val AUC: 0.8704, val AP: 0.8744,test AUC: 0.8700, test AP: 0.8664\n",
      "Epoch: 067,train AUC: 0.9215, train AP: 0.9076, loss:1.0891,val AUC: 0.8705, val AP: 0.8724,test AUC: 0.8695, test AP: 0.8656\n",
      "Epoch: 068,train AUC: 0.9225, train AP: 0.9083, loss:1.0752,val AUC: 0.8676, val AP: 0.8681,test AUC: 0.8677, test AP: 0.8647\n",
      "Epoch: 069,train AUC: 0.9217, train AP: 0.9077, loss:1.0555,val AUC: 0.8636, val AP: 0.8648,test AUC: 0.8637, test AP: 0.8619\n",
      "Epoch: 070,train AUC: 0.9224, train AP: 0.9095, loss:1.0854,val AUC: 0.8642, val AP: 0.8674,test AUC: 0.8647, test AP: 0.8627\n",
      "Epoch: 071,train AUC: 0.9241, train AP: 0.9123, loss:1.1010,val AUC: 0.8699, val AP: 0.8722,test AUC: 0.8705, test AP: 0.8670\n",
      "Epoch: 072,train AUC: 0.9252, train AP: 0.9121, loss:1.0673,val AUC: 0.8707, val AP: 0.8721,test AUC: 0.8708, test AP: 0.8667\n",
      "Epoch: 073,train AUC: 0.9248, train AP: 0.9104, loss:1.0548,val AUC: 0.8706, val AP: 0.8698,test AUC: 0.8706, test AP: 0.8655\n",
      "Epoch: 074,train AUC: 0.9251, train AP: 0.9107, loss:1.0865,val AUC: 0.8732, val AP: 0.8723,test AUC: 0.8707, test AP: 0.8650\n",
      "Epoch: 075,train AUC: 0.9266, train AP: 0.9139, loss:1.0712,val AUC: 0.8735, val AP: 0.8759,test AUC: 0.8724, test AP: 0.8673\n",
      "Epoch: 076,train AUC: 0.9269, train AP: 0.9153, loss:1.0675,val AUC: 0.8717, val AP: 0.8753,test AUC: 0.8704, test AP: 0.8665\n",
      "Epoch: 077,train AUC: 0.9269, train AP: 0.9161, loss:1.0754,val AUC: 0.8743, val AP: 0.8802,test AUC: 0.8698, test AP: 0.8661\n",
      "Epoch: 078,train AUC: 0.9274, train AP: 0.9161, loss:1.0511,val AUC: 0.8748, val AP: 0.8769,test AUC: 0.8686, test AP: 0.8625\n",
      "Epoch: 079,train AUC: 0.9278, train AP: 0.9161, loss:1.0813,val AUC: 0.8779, val AP: 0.8801,test AUC: 0.8718, test AP: 0.8650\n",
      "Epoch: 080,train AUC: 0.9273, train AP: 0.9148, loss:1.0518,val AUC: 0.8780, val AP: 0.8797,test AUC: 0.8740, test AP: 0.8678\n",
      "Epoch: 081,train AUC: 0.9272, train AP: 0.9136, loss:1.0351,val AUC: 0.8775, val AP: 0.8790,test AUC: 0.8729, test AP: 0.8673\n",
      "Epoch: 082,train AUC: 0.9280, train AP: 0.9150, loss:1.0478,val AUC: 0.8788, val AP: 0.8816,test AUC: 0.8744, test AP: 0.8700\n",
      "Epoch: 083,train AUC: 0.9289, train AP: 0.9164, loss:1.0823,val AUC: 0.8774, val AP: 0.8805,test AUC: 0.8755, test AP: 0.8716\n",
      "Epoch: 084,train AUC: 0.9291, train AP: 0.9166, loss:1.0520,val AUC: 0.8758, val AP: 0.8804,test AUC: 0.8750, test AP: 0.8717\n",
      "Epoch: 085,train AUC: 0.9298, train AP: 0.9189, loss:1.0592,val AUC: 0.8765, val AP: 0.8812,test AUC: 0.8762, test AP: 0.8737\n",
      "Epoch: 086,train AUC: 0.9297, train AP: 0.9189, loss:1.0594,val AUC: 0.8765, val AP: 0.8812,test AUC: 0.8768, test AP: 0.8747\n",
      "Epoch: 087,train AUC: 0.9289, train AP: 0.9175, loss:1.0408,val AUC: 0.8744, val AP: 0.8788,test AUC: 0.8758, test AP: 0.8744\n",
      "Epoch: 088,train AUC: 0.9299, train AP: 0.9181, loss:1.0498,val AUC: 0.8754, val AP: 0.8808,test AUC: 0.8769, test AP: 0.8745\n",
      "Epoch: 089,train AUC: 0.9305, train AP: 0.9187, loss:1.0710,val AUC: 0.8759, val AP: 0.8812,test AUC: 0.8790, test AP: 0.8757\n",
      "Epoch: 090,train AUC: 0.9311, train AP: 0.9196, loss:1.0442,val AUC: 0.8809, val AP: 0.8886,test AUC: 0.8809, test AP: 0.8770\n",
      "Epoch: 091,train AUC: 0.9311, train AP: 0.9194, loss:1.0570,val AUC: 0.8830, val AP: 0.8909,test AUC: 0.8814, test AP: 0.8767\n",
      "Epoch: 092,train AUC: 0.9320, train AP: 0.9198, loss:1.0775,val AUC: 0.8834, val AP: 0.8909,test AUC: 0.8808, test AP: 0.8762\n",
      "Epoch: 093,train AUC: 0.9322, train AP: 0.9199, loss:1.0511,val AUC: 0.8840, val AP: 0.8920,test AUC: 0.8805, test AP: 0.8754\n",
      "Epoch: 094,train AUC: 0.9340, train AP: 0.9223, loss:1.0326,val AUC: 0.8865, val AP: 0.8952,test AUC: 0.8840, test AP: 0.8786\n",
      "Epoch: 095,train AUC: 0.9343, train AP: 0.9231, loss:1.0229,val AUC: 0.8883, val AP: 0.8963,test AUC: 0.8862, test AP: 0.8817\n",
      "Epoch: 096,train AUC: 0.9349, train AP: 0.9240, loss:1.0362,val AUC: 0.8900, val AP: 0.8971,test AUC: 0.8872, test AP: 0.8835\n",
      "Epoch: 097,train AUC: 0.9351, train AP: 0.9240, loss:1.0304,val AUC: 0.8915, val AP: 0.8973,test AUC: 0.8865, test AP: 0.8829\n",
      "Epoch: 098,train AUC: 0.9352, train AP: 0.9239, loss:1.0581,val AUC: 0.8931, val AP: 0.8991,test AUC: 0.8845, test AP: 0.8814\n",
      "Epoch: 099,train AUC: 0.9355, train AP: 0.9238, loss:1.0267,val AUC: 0.8946, val AP: 0.8977,test AUC: 0.8839, test AP: 0.8805\n",
      "Epoch: 100,train AUC: 0.9372, train AP: 0.9269, loss:1.0535,val AUC: 0.8962, val AP: 0.9025,test AUC: 0.8872, test AP: 0.8848\n",
      "Epoch: 101,train AUC: 0.9372, train AP: 0.9268, loss:1.0441,val AUC: 0.8948, val AP: 0.9021,test AUC: 0.8867, test AP: 0.8838\n",
      "Epoch: 102,train AUC: 0.9355, train AP: 0.9241, loss:1.0252,val AUC: 0.8916, val AP: 0.8981,test AUC: 0.8833, test AP: 0.8818\n",
      "Epoch: 103,train AUC: 0.9343, train AP: 0.9220, loss:1.0287,val AUC: 0.8909, val AP: 0.8965,test AUC: 0.8819, test AP: 0.8804\n",
      "Epoch: 104,train AUC: 0.9362, train AP: 0.9242, loss:1.0653,val AUC: 0.8938, val AP: 0.9008,test AUC: 0.8843, test AP: 0.8837\n",
      "Epoch: 105,train AUC: 0.9374, train AP: 0.9258, loss:1.0310,val AUC: 0.8946, val AP: 0.9024,test AUC: 0.8854, test AP: 0.8845\n",
      "Epoch: 106,train AUC: 0.9375, train AP: 0.9253, loss:1.0239,val AUC: 0.8946, val AP: 0.9020,test AUC: 0.8840, test AP: 0.8824\n",
      "Epoch: 107,train AUC: 0.9382, train AP: 0.9260, loss:1.0226,val AUC: 0.8954, val AP: 0.9026,test AUC: 0.8830, test AP: 0.8818\n",
      "Epoch: 108,train AUC: 0.9400, train AP: 0.9293, loss:1.0265,val AUC: 0.8963, val AP: 0.9049,test AUC: 0.8844, test AP: 0.8859\n",
      "Epoch: 109,train AUC: 0.9394, train AP: 0.9284, loss:1.0123,val AUC: 0.8939, val AP: 0.9037,test AUC: 0.8825, test AP: 0.8874\n",
      "Epoch: 110,train AUC: 0.9380, train AP: 0.9265, loss:1.0144,val AUC: 0.8909, val AP: 0.9020,test AUC: 0.8808, test AP: 0.8859\n",
      "Epoch: 111,train AUC: 0.9370, train AP: 0.9254, loss:1.0215,val AUC: 0.8903, val AP: 0.9019,test AUC: 0.8804, test AP: 0.8849\n",
      "Epoch: 112,train AUC: 0.9381, train AP: 0.9271, loss:1.0263,val AUC: 0.8938, val AP: 0.9044,test AUC: 0.8825, test AP: 0.8865\n",
      "Epoch: 113,train AUC: 0.9391, train AP: 0.9282, loss:1.0159,val AUC: 0.8956, val AP: 0.9062,test AUC: 0.8836, test AP: 0.8870\n",
      "Epoch: 114,train AUC: 0.9408, train AP: 0.9300, loss:0.9938,val AUC: 0.8993, val AP: 0.9076,test AUC: 0.8851, test AP: 0.8871\n",
      "Epoch: 115,train AUC: 0.9406, train AP: 0.9292, loss:1.0180,val AUC: 0.8979, val AP: 0.9049,test AUC: 0.8847, test AP: 0.8844\n",
      "Epoch: 116,train AUC: 0.9398, train AP: 0.9284, loss:1.0326,val AUC: 0.8944, val AP: 0.9023,test AUC: 0.8853, test AP: 0.8846\n",
      "Epoch: 117,train AUC: 0.9405, train AP: 0.9297, loss:1.0098,val AUC: 0.8939, val AP: 0.9050,test AUC: 0.8867, test AP: 0.8874\n",
      "Epoch: 118,train AUC: 0.9406, train AP: 0.9302, loss:0.9928,val AUC: 0.8931, val AP: 0.9050,test AUC: 0.8865, test AP: 0.8883\n",
      "Epoch: 119,train AUC: 0.9405, train AP: 0.9300, loss:1.0098,val AUC: 0.8926, val AP: 0.9049,test AUC: 0.8842, test AP: 0.8862\n",
      "Epoch: 120,train AUC: 0.9412, train AP: 0.9308, loss:1.0051,val AUC: 0.8932, val AP: 0.9058,test AUC: 0.8848, test AP: 0.8867\n",
      "Epoch: 121,train AUC: 0.9439, train AP: 0.9343, loss:1.0117,val AUC: 0.8964, val AP: 0.9102,test AUC: 0.8895, test AP: 0.8918\n",
      "Epoch: 122,train AUC: 0.9442, train AP: 0.9345, loss:1.0223,val AUC: 0.8986, val AP: 0.9114,test AUC: 0.8914, test AP: 0.8940\n",
      "Epoch: 123,train AUC: 0.9429, train AP: 0.9322, loss:0.9992,val AUC: 0.8974, val AP: 0.9093,test AUC: 0.8906, test AP: 0.8918\n",
      "Epoch: 124,train AUC: 0.9427, train AP: 0.9314, loss:1.0064,val AUC: 0.8985, val AP: 0.9095,test AUC: 0.8907, test AP: 0.8908\n",
      "Epoch: 125,train AUC: 0.9445, train AP: 0.9339, loss:1.0007,val AUC: 0.9006, val AP: 0.9118,test AUC: 0.8921, test AP: 0.8926\n",
      "Epoch: 126,train AUC: 0.9453, train AP: 0.9355, loss:0.9776,val AUC: 0.9015, val AP: 0.9120,test AUC: 0.8926, test AP: 0.8939\n",
      "Epoch: 127,train AUC: 0.9451, train AP: 0.9354, loss:1.0047,val AUC: 0.9005, val AP: 0.9106,test AUC: 0.8893, test AP: 0.8909\n",
      "Epoch: 128,train AUC: 0.9417, train AP: 0.9308, loss:0.9833,val AUC: 0.8955, val AP: 0.9081,test AUC: 0.8841, test AP: 0.8870\n",
      "Epoch: 129,train AUC: 0.9454, train AP: 0.9357, loss:1.0106,val AUC: 0.9006, val AP: 0.9130,test AUC: 0.8890, test AP: 0.8914\n",
      "Epoch: 130,train AUC: 0.9465, train AP: 0.9367, loss:0.9936,val AUC: 0.9023, val AP: 0.9131,test AUC: 0.8905, test AP: 0.8908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 131,train AUC: 0.9460, train AP: 0.9353, loss:1.0260,val AUC: 0.8993, val AP: 0.9085,test AUC: 0.8902, test AP: 0.8891\n",
      "Epoch: 132,train AUC: 0.9444, train AP: 0.9329, loss:1.0291,val AUC: 0.8956, val AP: 0.9026,test AUC: 0.8874, test AP: 0.8838\n",
      "Epoch: 133,train AUC: 0.9429, train AP: 0.9316, loss:1.0101,val AUC: 0.8910, val AP: 0.8989,test AUC: 0.8851, test AP: 0.8825\n",
      "Epoch: 134,train AUC: 0.9455, train AP: 0.9357, loss:1.0031,val AUC: 0.8940, val AP: 0.9051,test AUC: 0.8887, test AP: 0.8871\n",
      "Epoch: 135,train AUC: 0.9458, train AP: 0.9363, loss:0.9961,val AUC: 0.8965, val AP: 0.9071,test AUC: 0.8902, test AP: 0.8887\n",
      "Epoch: 136,train AUC: 0.9463, train AP: 0.9363, loss:1.0053,val AUC: 0.8970, val AP: 0.9088,test AUC: 0.8910, test AP: 0.8884\n",
      "Epoch: 137,train AUC: 0.9431, train AP: 0.9320, loss:0.9933,val AUC: 0.8925, val AP: 0.9054,test AUC: 0.8862, test AP: 0.8831\n",
      "Epoch: 138,train AUC: 0.9470, train AP: 0.9368, loss:1.0031,val AUC: 0.8982, val AP: 0.9112,test AUC: 0.8938, test AP: 0.8925\n",
      "Epoch: 139,train AUC: 0.9497, train AP: 0.9401, loss:0.9884,val AUC: 0.9034, val AP: 0.9143,test AUC: 0.8997, test AP: 0.9024\n",
      "Epoch: 140,train AUC: 0.9497, train AP: 0.9402, loss:1.0045,val AUC: 0.9025, val AP: 0.9126,test AUC: 0.8998, test AP: 0.9024\n",
      "Epoch: 141,train AUC: 0.9475, train AP: 0.9377, loss:0.9787,val AUC: 0.8975, val AP: 0.9080,test AUC: 0.8945, test AP: 0.8972\n",
      "Epoch: 142,train AUC: 0.9475, train AP: 0.9378, loss:0.9967,val AUC: 0.8975, val AP: 0.9076,test AUC: 0.8947, test AP: 0.8975\n",
      "Epoch: 143,train AUC: 0.9490, train AP: 0.9399, loss:0.9963,val AUC: 0.9007, val AP: 0.9105,test AUC: 0.8967, test AP: 0.9005\n",
      "Epoch: 144,train AUC: 0.9489, train AP: 0.9395, loss:0.9818,val AUC: 0.9004, val AP: 0.9098,test AUC: 0.8951, test AP: 0.8962\n",
      "Epoch: 145,train AUC: 0.9489, train AP: 0.9394, loss:0.9805,val AUC: 0.9002, val AP: 0.9085,test AUC: 0.8954, test AP: 0.8969\n",
      "Epoch: 146,train AUC: 0.9491, train AP: 0.9395, loss:0.9677,val AUC: 0.8986, val AP: 0.9070,test AUC: 0.8966, test AP: 0.8987\n",
      "Epoch: 147,train AUC: 0.9480, train AP: 0.9382, loss:0.9779,val AUC: 0.8956, val AP: 0.9043,test AUC: 0.8961, test AP: 0.8989\n",
      "Epoch: 148,train AUC: 0.9478, train AP: 0.9381, loss:0.9664,val AUC: 0.8947, val AP: 0.9037,test AUC: 0.8954, test AP: 0.8986\n",
      "Epoch: 149,train AUC: 0.9493, train AP: 0.9402, loss:1.0132,val AUC: 0.8960, val AP: 0.9055,test AUC: 0.8985, test AP: 0.9043\n",
      "Epoch: 150,train AUC: 0.9502, train AP: 0.9419, loss:0.9912,val AUC: 0.8965, val AP: 0.9068,test AUC: 0.9010, test AP: 0.9078\n",
      "Epoch: 151,train AUC: 0.9494, train AP: 0.9410, loss:0.9892,val AUC: 0.8958, val AP: 0.9062,test AUC: 0.8995, test AP: 0.9070\n",
      "Epoch: 152,train AUC: 0.9483, train AP: 0.9390, loss:0.9949,val AUC: 0.8950, val AP: 0.9047,test AUC: 0.8981, test AP: 0.9041\n",
      "Epoch: 153,train AUC: 0.9476, train AP: 0.9374, loss:0.9802,val AUC: 0.8957, val AP: 0.9053,test AUC: 0.8976, test AP: 0.9006\n",
      "Epoch: 154,train AUC: 0.9486, train AP: 0.9381, loss:0.9900,val AUC: 0.8994, val AP: 0.9100,test AUC: 0.9002, test AP: 0.9020\n",
      "Epoch: 155,train AUC: 0.9490, train AP: 0.9386, loss:0.9947,val AUC: 0.9009, val AP: 0.9115,test AUC: 0.9012, test AP: 0.9030\n",
      "Epoch: 156,train AUC: 0.9484, train AP: 0.9385, loss:0.9798,val AUC: 0.8998, val AP: 0.9104,test AUC: 0.8999, test AP: 0.9020\n",
      "Epoch: 157,train AUC: 0.9473, train AP: 0.9372, loss:0.9867,val AUC: 0.8961, val AP: 0.9061,test AUC: 0.8970, test AP: 0.8998\n",
      "Epoch: 158,train AUC: 0.9485, train AP: 0.9385, loss:0.9921,val AUC: 0.8982, val AP: 0.9045,test AUC: 0.8980, test AP: 0.9016\n",
      "Epoch: 159,train AUC: 0.9492, train AP: 0.9388, loss:0.9858,val AUC: 0.9019, val AP: 0.9064,test AUC: 0.9008, test AP: 0.9044\n",
      "Epoch: 160,train AUC: 0.9486, train AP: 0.9376, loss:1.0048,val AUC: 0.9017, val AP: 0.9057,test AUC: 0.9011, test AP: 0.9046\n",
      "Epoch: 161,train AUC: 0.9469, train AP: 0.9349, loss:0.9988,val AUC: 0.8993, val AP: 0.9028,test AUC: 0.8984, test AP: 0.9008\n",
      "Epoch: 162,train AUC: 0.9464, train AP: 0.9347, loss:0.9955,val AUC: 0.8952, val AP: 0.8972,test AUC: 0.8971, test AP: 0.8989\n",
      "Epoch: 163,train AUC: 0.9485, train AP: 0.9369, loss:0.9941,val AUC: 0.8986, val AP: 0.8997,test AUC: 0.9003, test AP: 0.9013\n",
      "Epoch: 164,train AUC: 0.9509, train AP: 0.9404, loss:0.9727,val AUC: 0.9047, val AP: 0.9068,test AUC: 0.9052, test AP: 0.9065\n",
      "Epoch: 165,train AUC: 0.9513, train AP: 0.9413, loss:0.9939,val AUC: 0.9044, val AP: 0.9064,test AUC: 0.9069, test AP: 0.9082\n",
      "Epoch: 166,train AUC: 0.9504, train AP: 0.9409, loss:1.0121,val AUC: 0.9015, val AP: 0.9043,test AUC: 0.9051, test AP: 0.9070\n",
      "Epoch: 167,train AUC: 0.9487, train AP: 0.9391, loss:0.9712,val AUC: 0.8992, val AP: 0.9017,test AUC: 0.9034, test AP: 0.9051\n",
      "Epoch: 168,train AUC: 0.9489, train AP: 0.9391, loss:0.9781,val AUC: 0.9009, val AP: 0.9053,test AUC: 0.9037, test AP: 0.9047\n",
      "Epoch: 169,train AUC: 0.9504, train AP: 0.9406, loss:0.9750,val AUC: 0.9027, val AP: 0.9059,test AUC: 0.9037, test AP: 0.9042\n",
      "Epoch: 170,train AUC: 0.9511, train AP: 0.9417, loss:0.9683,val AUC: 0.9024, val AP: 0.9066,test AUC: 0.9060, test AP: 0.9073\n",
      "Epoch: 171,train AUC: 0.9515, train AP: 0.9424, loss:0.9617,val AUC: 0.9026, val AP: 0.9072,test AUC: 0.9075, test AP: 0.9105\n",
      "Epoch: 172,train AUC: 0.9512, train AP: 0.9417, loss:0.9726,val AUC: 0.9029, val AP: 0.9071,test AUC: 0.9069, test AP: 0.9106\n",
      "Epoch: 173,train AUC: 0.9506, train AP: 0.9402, loss:0.9956,val AUC: 0.9037, val AP: 0.9072,test AUC: 0.9071, test AP: 0.9088\n",
      "Epoch: 174,train AUC: 0.9515, train AP: 0.9413, loss:0.9944,val AUC: 0.9053, val AP: 0.9087,test AUC: 0.9073, test AP: 0.9084\n",
      "Epoch: 175,train AUC: 0.9530, train AP: 0.9434, loss:0.9858,val AUC: 0.9069, val AP: 0.9091,test AUC: 0.9064, test AP: 0.9082\n",
      "Epoch: 176,train AUC: 0.9527, train AP: 0.9433, loss:0.9767,val AUC: 0.9044, val AP: 0.9069,test AUC: 0.9022, test AP: 0.9050\n",
      "Epoch: 177,train AUC: 0.9525, train AP: 0.9430, loss:0.9816,val AUC: 0.9025, val AP: 0.9057,test AUC: 0.9010, test AP: 0.9041\n",
      "Epoch: 178,train AUC: 0.9525, train AP: 0.9427, loss:0.9774,val AUC: 0.9038, val AP: 0.9057,test AUC: 0.9008, test AP: 0.9031\n",
      "Epoch: 179,train AUC: 0.9526, train AP: 0.9425, loss:0.9906,val AUC: 0.9066, val AP: 0.9078,test AUC: 0.9028, test AP: 0.9049\n",
      "Epoch: 180,train AUC: 0.9520, train AP: 0.9423, loss:0.9830,val AUC: 0.9061, val AP: 0.9085,test AUC: 0.9041, test AP: 0.9064\n",
      "Epoch: 181,train AUC: 0.9513, train AP: 0.9417, loss:0.9723,val AUC: 0.9051, val AP: 0.9081,test AUC: 0.9049, test AP: 0.9067\n",
      "Epoch: 182,train AUC: 0.9532, train AP: 0.9438, loss:0.9721,val AUC: 0.9072, val AP: 0.9110,test AUC: 0.9076, test AP: 0.9094\n",
      "Epoch: 183,train AUC: 0.9556, train AP: 0.9469, loss:0.9733,val AUC: 0.9105, val AP: 0.9165,test AUC: 0.9097, test AP: 0.9119\n",
      "Epoch: 184,train AUC: 0.9569, train AP: 0.9489, loss:0.9774,val AUC: 0.9126, val AP: 0.9210,test AUC: 0.9118, test AP: 0.9143\n",
      "Epoch: 185,train AUC: 0.9547, train AP: 0.9460, loss:0.9855,val AUC: 0.9080, val AP: 0.9166,test AUC: 0.9098, test AP: 0.9128\n",
      "Epoch: 186,train AUC: 0.9519, train AP: 0.9423, loss:0.9632,val AUC: 0.9024, val AP: 0.9100,test AUC: 0.9068, test AP: 0.9092\n",
      "Epoch: 187,train AUC: 0.9534, train AP: 0.9441, loss:0.9751,val AUC: 0.9064, val AP: 0.9140,test AUC: 0.9102, test AP: 0.9115\n",
      "Epoch: 188,train AUC: 0.9546, train AP: 0.9455, loss:0.9652,val AUC: 0.9095, val AP: 0.9176,test AUC: 0.9135, test AP: 0.9144\n",
      "Epoch: 189,train AUC: 0.9551, train AP: 0.9460, loss:0.9543,val AUC: 0.9066, val AP: 0.9133,test AUC: 0.9127, test AP: 0.9151\n",
      "Epoch: 190,train AUC: 0.9539, train AP: 0.9445, loss:0.9886,val AUC: 0.9011, val AP: 0.9059,test AUC: 0.9097, test AP: 0.9128\n",
      "Epoch: 191,train AUC: 0.9566, train AP: 0.9479, loss:0.9559,val AUC: 0.9044, val AP: 0.9105,test AUC: 0.9130, test AP: 0.9162\n",
      "Epoch: 192,train AUC: 0.9579, train AP: 0.9499, loss:0.9745,val AUC: 0.9086, val AP: 0.9151,test AUC: 0.9150, test AP: 0.9181\n",
      "Epoch: 193,train AUC: 0.9554, train AP: 0.9469, loss:0.9610,val AUC: 0.9060, val AP: 0.9130,test AUC: 0.9132, test AP: 0.9162\n",
      "Epoch: 194,train AUC: 0.9549, train AP: 0.9464, loss:0.9747,val AUC: 0.9085, val AP: 0.9159,test AUC: 0.9135, test AP: 0.9161\n",
      "Epoch: 195,train AUC: 0.9555, train AP: 0.9468, loss:0.9711,val AUC: 0.9116, val AP: 0.9189,test AUC: 0.9133, test AP: 0.9131\n",
      "Epoch: 196,train AUC: 0.9565, train AP: 0.9478, loss:0.9650,val AUC: 0.9121, val AP: 0.9193,test AUC: 0.9144, test AP: 0.9160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 197,train AUC: 0.9554, train AP: 0.9454, loss:0.9786,val AUC: 0.9083, val AP: 0.9150,test AUC: 0.9117, test AP: 0.9134\n",
      "Epoch: 198,train AUC: 0.9551, train AP: 0.9449, loss:0.9821,val AUC: 0.9072, val AP: 0.9129,test AUC: 0.9103, test AP: 0.9090\n",
      "Epoch: 199,train AUC: 0.9557, train AP: 0.9454, loss:0.9826,val AUC: 0.9099, val AP: 0.9147,test AUC: 0.9109, test AP: 0.9076\n",
      "Epoch: 200,train AUC: 0.9559, train AP: 0.9461, loss:0.9899,val AUC: 0.9118, val AP: 0.9166,test AUC: 0.9107, test AP: 0.9075\n",
      "Final Test epoch:184.0000,Final Test AUC: 0.9118,Final Test AP:0.9143\n"
     ]
    }
   ],
   "source": [
    "for time in range(2):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    transform = T.Compose([\n",
    "        T.ToDevice(device),\n",
    "        T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
    "                          split_labels=True, add_negative_train_samples=True),\n",
    "    ])\n",
    "\n",
    "    train_dataset, val_dataset, test_dataset = transform(data)\n",
    "    #print(\"Train Data:\\n\", train_dataset)\n",
    "    #print(\"\\nValidation Data:\\n\", val_dataset)\n",
    "    #print(\"\\nTest Data:\\n\", test_dataset)\n",
    "    HIDDEN_SIZE = 32\n",
    "    OUT_CHANNELS = 16\n",
    "    EPOCHS = 200\n",
    "    NUM_FEATURES=data.x.shape[1]\n",
    "    class GCNEncoder(nn.Module):\n",
    "        def __init__(self, in_channels, hidden_size, out_channels, dropout):\n",
    "            super(GCNEncoder, self).__init__()\n",
    "            self.conv1 = GCNConv(in_channels, hidden_size, cached=True)\n",
    "            self.conv2 = GCNConv(hidden_size, out_channels, cached=True) \n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        def forward(self, x, edge_index):\n",
    "            x_temp1 = self.conv1(x, edge_index).relu()\n",
    "            x_temp2 = self.dropout(x_temp1)\n",
    "            return self.conv2(x_temp2, edge_index)\n",
    "    class GATEncoder(nn.Module):\n",
    "        def __init__(self, in_channels, hidden_size, out_channels, dropout):\n",
    "            self.dropout=dropout\n",
    "            super(GATEncoder, self).__init__()\n",
    "            self.conv1 = GATConv(in_channels, hidden_size, heads=8, dropout=dropout)\n",
    "            self.conv2 = GATConv(hidden_size * 8, OUT_CHANNELS, heads=1,dropout=dropout)\n",
    "\n",
    "        def forward(self,x, edge_index):\n",
    "            x = F.dropout(x, p=self.dropout)\n",
    "            x = F.elu(self.conv1(x,edge_index))\n",
    "            x = F.dropout(x, p=self.dropout)\n",
    "            x = self.conv2(x, edge_index)\n",
    "            return x\n",
    "\n",
    "    class SAGEEncoder(nn.Module):\n",
    "        def __init__(self, in_channels, hidden_channels, out_channels, dropout):\n",
    "            super(SAGEEncoder, self).__init__()\n",
    "            self.convs = nn.ModuleList()\n",
    "            self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "            self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "            self.dropout = dropout\n",
    "\n",
    "        #def reset_parameters():\n",
    "            #for conv in self.convs:\n",
    "                #conv.reset_parameters()\n",
    "\n",
    "        def forward(self, x, edge_index):\n",
    "            x = self.convs[0](x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            x = self.convs[1](x, edge_index)\n",
    "\n",
    "            return x\n",
    "\n",
    "\n",
    "    gae_model = GAE(GCNEncoder(NUM_FEATURES, HIDDEN_SIZE, OUT_CHANNELS, 0))\n",
    "    gae_model = gae_model.to(device)\n",
    "    #print(gae_model)\n",
    "    def gae_train(train_data, gae_model, optimizer):\n",
    "        gae_model.train()\n",
    "        optimizer.zero_grad()\n",
    "        z = gae_model.encode(train_data.x, train_data.edge_index)\n",
    "        loss = gae_model.recon_loss(z, train_data.pos_edge_label_index.to(device))\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        return float(loss)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def gae_test(test_data, gae_model):\n",
    "        gae_model.eval()\n",
    "        z = gae_model.encode(test_data.x, test_data.edge_index)\n",
    "        return gae_model.test(z, test_data.pos_edge_label_index, test_data.neg_edge_label_index)\n",
    "    losses = []\n",
    "    test_aucs = []\n",
    "    test_aps = []\n",
    "    train_aucs = []\n",
    "    train_aps = []\n",
    "    val_aucs=[]\n",
    "    val_aps=[]\n",
    "\n",
    "    optimizer = torch.optim.Adam(gae_model.parameters(), lr=0.01)\n",
    "\n",
    "    best_val_auc = final_test_auc = final_test_ap =best_epoch= 0\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        loss = gae_train(train_dataset, gae_model, optimizer)\n",
    "        losses.append(loss)\n",
    "        auc, ap = gae_test(test_dataset, gae_model)\n",
    "        test_aucs.append(auc)\n",
    "        test_aps.append(ap)\n",
    "\n",
    "        train_auc, train_ap = gae_test(train_dataset, gae_model)\n",
    "        train_aucs.append(train_auc)\n",
    "        train_aps.append(train_ap)\n",
    "\n",
    "        val_auc, val_ap = gae_test(val_dataset, gae_model)\n",
    "        val_aucs.append(val_auc)\n",
    "        val_aps.append(val_ap)\n",
    "\n",
    "        if val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "            final_test_auc = auc\n",
    "            final_test_ap=ap\n",
    "            best_epoch=epoch\n",
    "        print('Epoch: {:03d},train AUC: {:.4f}, train AP: {:.4f}, loss:{:.4f},val AUC: {:.4f}, val AP: {:.4f},test AUC: {:.4f}, test AP: {:.4f}'.format(epoch, train_auc, train_ap, loss,val_auc, val_ap, auc, ap))\n",
    "        torch.save(gae_model, str(epoch)+'.pt')\n",
    "    n=best_epoch\n",
    "    print(f'Final Test epoch:{best_epoch:.4f},Final Test AUC: {final_test_auc:.4f},Final Test AP:{final_test_ap:.4f}')\n",
    "    result[0][time]=final_test_auc\n",
    "    result[1][time]=final_test_ap \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8906d2b2",
   "metadata": {},
   "source": [
    "3.预测新边"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "304b3ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.909166</td>\n",
       "      <td>0.909761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.915036</td>\n",
       "      <td>0.911061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.920493</td>\n",
       "      <td>0.926689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.907557</td>\n",
       "      <td>0.906336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.920460</td>\n",
       "      <td>0.925289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.918607</td>\n",
       "      <td>0.919550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.912038</td>\n",
       "      <td>0.913142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.895222</td>\n",
       "      <td>0.888136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.909401</td>\n",
       "      <td>0.907970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.912544</td>\n",
       "      <td>0.914900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.912052</td>\n",
       "      <td>0.912283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1\n",
       "0   0.909166  0.909761\n",
       "1   0.915036  0.911061\n",
       "2   0.920493  0.926689\n",
       "3   0.907557  0.906336\n",
       "4   0.920460  0.925289\n",
       "5   0.918607  0.919550\n",
       "6   0.912038  0.913142\n",
       "7   0.895222  0.888136\n",
       "8   0.909401  0.907970\n",
       "9   0.912544  0.914900\n",
       "10  0.912052  0.912283"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0][10]=np.mean(result[0][0:10])\n",
    "result[1][10]=np .mean(result[1][0:10])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0565d5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('E:\\\\GraphSAGE\\\\Scopus_2022_9_21_1\\\\result\\\\gcn_author1+author2.csv',header=0,index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49b1f4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load(str(n)+\".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "279efd88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0651, -0.3429,  0.3576,  ...,  0.1915, -0.1944,  0.0095],\n",
       "        [-0.1777,  0.0036,  0.1425,  ...,  0.1741, -0.1475, -0.1192],\n",
       "        [-0.1777,  0.0036,  0.1425,  ...,  0.1741, -0.1475, -0.1192],\n",
       "        ...,\n",
       "        [-0.1075,  0.0010, -0.6805,  ...,  0.6060,  0.1654, -0.3141],\n",
       "        [ 0.0282,  0.0865, -0.7341,  ...,  0.5466,  0.1595, -0.2990],\n",
       "        [ 0.3454,  0.0681, -0.2448,  ..., -0.1909, -0.2925, -0.2660]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = model.encode(data.x, data.edge_index)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "13712e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#z=z.detach().numpy()\n",
    "#norm1 = np.linalg.norm(z,axis=-1,keepdims=True)\n",
    "#norm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e410efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#z=z/norm1\n",
    "#z=torch.Tensor(z)\n",
    "#z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7d49446",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def decode_all(z):\n",
    "#        prob_adj = z @ z.t()\n",
    "#        return (prob_adj > 0).nonzero(as_tuple=False).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "542cbce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_all(z):\n",
    "        adj = torch.matmul(z, z.t())\n",
    "        return (torch.sigmoid(adj)>0.5).nonzero(as_tuple=False).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba8bbb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 11411469])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_edge_index = decode_all(z)\n",
    "final_edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa1a2646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4733, 4733])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_adj = torch.sigmoid(z @ z.t())\n",
    "prob_adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f854b189",
   "metadata": {},
   "outputs": [],
   "source": [
    "newedge=pd.DataFrame(final_edge_index.numpy()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf2d0a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7203723788261414,\n",
       " 0.6251851916313171,\n",
       " 0.6251851916313171,\n",
       " 0.955325722694397,\n",
       " 0.567082941532135,\n",
       " 0.567082941532135,\n",
       " 0.5365203022956848,\n",
       " 0.5365203022956848,\n",
       " 0.5706377029418945,\n",
       " 0.6238405704498291,\n",
       " 0.6426406502723694,\n",
       " 0.6426406502723694,\n",
       " 0.5054429769515991,\n",
       " 0.7823199033737183,\n",
       " 0.8509165644645691,\n",
       " 0.5327759981155396,\n",
       " 0.661300539970398,\n",
       " 0.5881945490837097,\n",
       " 0.6226270198822021,\n",
       " 0.5881945490837097,\n",
       " 0.6949578523635864,\n",
       " 0.5259444713592529,\n",
       " 0.52734375,\n",
       " 0.52734375,\n",
       " 0.52734375,\n",
       " 0.5842308402061462,\n",
       " 0.7368674874305725,\n",
       " 0.5214240550994873,\n",
       " 0.5214240550994873,\n",
       " 0.7255455851554871,\n",
       " 0.5497919321060181,\n",
       " 0.6305491924285889,\n",
       " 0.5439050793647766,\n",
       " 0.5439050793647766,\n",
       " 0.7010329961776733,\n",
       " 0.5734859108924866,\n",
       " 0.5573611855506897,\n",
       " 0.6041002869606018,\n",
       " 0.6641361713409424,\n",
       " 0.6064664721488953,\n",
       " 0.5860247015953064,\n",
       " 0.6074795722961426,\n",
       " 0.5300701856613159,\n",
       " 0.6595712900161743,\n",
       " 0.5300701856613159,\n",
       " 0.5492746233940125,\n",
       " 0.5068264007568359,\n",
       " 0.5218754410743713,\n",
       " 0.8016687631607056,\n",
       " 0.5068264007568359,\n",
       " 0.5148512125015259,\n",
       " 0.8243964314460754,\n",
       " 0.5104696750640869,\n",
       " 0.545488178730011,\n",
       " 0.545488178730011,\n",
       " 0.5271282196044922,\n",
       " 0.6402613520622253,\n",
       " 0.6438249945640564,\n",
       " 0.6086291074752808,\n",
       " 0.6402613520622253,\n",
       " 0.6086291074752808,\n",
       " 0.6378688216209412,\n",
       " 0.5726196765899658,\n",
       " 0.7918097376823425,\n",
       " 0.7627362608909607,\n",
       " 0.6080705523490906,\n",
       " 0.5095579028129578,\n",
       " 0.5095579028129578,\n",
       " 0.7466968894004822,\n",
       " 0.5822656154632568,\n",
       " 0.598440408706665,\n",
       " 0.598440408706665,\n",
       " 0.6306397914886475,\n",
       " 0.6679947376251221,\n",
       " 0.5935685038566589,\n",
       " 0.5935685038566589,\n",
       " 0.6144661903381348,\n",
       " 0.5304107069969177,\n",
       " 0.5304107069969177,\n",
       " 0.6064595580101013,\n",
       " 0.5698584914207458,\n",
       " 0.6572628021240234,\n",
       " 0.6247243881225586,\n",
       " 0.6126437783241272,\n",
       " 0.6126437783241272,\n",
       " 0.5540177226066589,\n",
       " 0.5024327039718628,\n",
       " 0.5061209201812744,\n",
       " 0.5024327039718628,\n",
       " 0.5817990303039551,\n",
       " 0.6361134052276611,\n",
       " 0.6399184465408325,\n",
       " 0.724591851234436,\n",
       " 0.5356982946395874,\n",
       " 0.5356982946395874,\n",
       " 0.5356982946395874,\n",
       " 0.6305409073829651,\n",
       " 0.6305409073829651,\n",
       " 0.9261595010757446,\n",
       " 0.7121577858924866,\n",
       " 0.625442385673523,\n",
       " 0.7090879678726196,\n",
       " 0.536949098110199,\n",
       " 0.6120324730873108,\n",
       " 0.6891958713531494,\n",
       " 0.6891958713531494,\n",
       " 0.6891958713531494,\n",
       " 0.8021102547645569,\n",
       " 0.62810879945755,\n",
       " 0.591810941696167,\n",
       " 0.8178998231887817,\n",
       " 0.5631557703018188,\n",
       " 0.5598760843276978,\n",
       " 0.6437348127365112,\n",
       " 0.5330232977867126,\n",
       " 0.5330232977867126,\n",
       " 0.6962734460830688,\n",
       " 0.5109113454818726,\n",
       " 0.7610949873924255,\n",
       " 0.6344186067581177,\n",
       " 0.6344186067581177,\n",
       " 0.6344186067581177,\n",
       " 0.6344186067581177,\n",
       " 0.5987067818641663,\n",
       " 0.6631401181221008,\n",
       " 0.6110041737556458,\n",
       " 0.5588604211807251,\n",
       " 0.5528560876846313,\n",
       " 0.5528561472892761,\n",
       " 0.6328262090682983,\n",
       " 0.5824378728866577,\n",
       " 0.5824378728866577,\n",
       " 0.9025055766105652,\n",
       " 0.653765857219696,\n",
       " 0.653765857219696,\n",
       " 0.5960477590560913,\n",
       " 0.5960477590560913,\n",
       " 0.5960477590560913,\n",
       " 0.7025297284126282,\n",
       " 0.6818158626556396,\n",
       " 0.7112231850624084,\n",
       " 0.5310205817222595,\n",
       " 0.5310205817222595,\n",
       " 0.5719382762908936,\n",
       " 0.5606517791748047,\n",
       " 0.5606517791748047,\n",
       " 0.606884777545929,\n",
       " 0.6425800919532776,\n",
       " 0.5687090754508972,\n",
       " 0.5687090754508972,\n",
       " 0.64863520860672,\n",
       " 0.9295670390129089,\n",
       " 0.64863520860672,\n",
       " 0.5302515625953674,\n",
       " 0.5183520913124084,\n",
       " 0.8659031987190247,\n",
       " 0.6304315328598022,\n",
       " 0.5100232362747192,\n",
       " 0.5054020285606384,\n",
       " 0.5139160752296448,\n",
       " 0.9179098010063171,\n",
       " 0.5139160752296448,\n",
       " 0.521155059337616,\n",
       " 0.53495854139328,\n",
       " 0.53495854139328,\n",
       " 0.6513098478317261,\n",
       " 0.605652928352356,\n",
       " 0.8516263365745544,\n",
       " 0.5870193243026733,\n",
       " 0.6385272145271301,\n",
       " 0.579174816608429,\n",
       " 0.5672619938850403,\n",
       " 0.5826773643493652,\n",
       " 0.5835625529289246,\n",
       " 0.6024764776229858,\n",
       " 0.673083484172821,\n",
       " 0.5826773643493652,\n",
       " 0.730695366859436,\n",
       " 0.5831868648529053,\n",
       " 0.7506161332130432,\n",
       " 0.6492198705673218,\n",
       " 0.6902274489402771,\n",
       " 0.6492198705673218,\n",
       " 0.636881947517395,\n",
       " 0.5155682563781738,\n",
       " 0.5512285232543945,\n",
       " 0.5455814003944397,\n",
       " 0.521314263343811,\n",
       " 0.5210490226745605,\n",
       " 0.521314263343811,\n",
       " 0.5735667943954468,\n",
       " 0.6202560067176819,\n",
       " 0.5735667943954468,\n",
       " 0.5798536539077759,\n",
       " 0.6641829013824463,\n",
       " 0.5493130683898926,\n",
       " 0.5735136270523071,\n",
       " 0.6027002930641174,\n",
       " 0.9105691909790039,\n",
       " 0.7748931646347046,\n",
       " 0.9437031149864197,\n",
       " 0.6233316659927368,\n",
       " 0.6117421388626099,\n",
       " 0.6117421388626099,\n",
       " 0.6117421388626099,\n",
       " 0.6253674030303955,\n",
       " 0.6669955253601074,\n",
       " 0.6130564212799072,\n",
       " 0.6640350818634033,\n",
       " 0.642859160900116,\n",
       " 0.5004968643188477,\n",
       " 0.5004968643188477,\n",
       " 0.5732097029685974,\n",
       " 0.6242340803146362,\n",
       " 0.8852887153625488,\n",
       " 0.6376906037330627,\n",
       " 0.6054818034172058,\n",
       " 0.6054818034172058,\n",
       " 0.7892249226570129,\n",
       " 0.8271167278289795,\n",
       " 0.556240439414978,\n",
       " 0.5832827687263489,\n",
       " 0.5457574129104614,\n",
       " 0.5829339027404785,\n",
       " 0.5853485465049744,\n",
       " 0.6068503856658936,\n",
       " 0.5853485465049744,\n",
       " 0.6123901009559631,\n",
       " 0.6123901009559631,\n",
       " 0.5785850882530212,\n",
       " 0.6878222823143005,\n",
       " 0.6230228543281555,\n",
       " 0.5903446674346924,\n",
       " 0.5882920622825623,\n",
       " 0.5304462313652039,\n",
       " 0.5675977468490601,\n",
       " 0.657221257686615,\n",
       " 0.5239589810371399,\n",
       " 0.832691490650177,\n",
       " 0.6846264004707336,\n",
       " 0.5239589810371399,\n",
       " 0.5788964033126831,\n",
       " 0.6746525168418884,\n",
       " 0.5788964033126831,\n",
       " 0.5788964033126831,\n",
       " 0.5031201243400574,\n",
       " 0.5325452089309692,\n",
       " 0.8085985779762268,\n",
       " 0.5325452089309692,\n",
       " 0.5071704983711243,\n",
       " 0.7154814004898071,\n",
       " 0.5233216881752014,\n",
       " 0.6401996612548828,\n",
       " 0.5881291031837463,\n",
       " 0.5881291031837463,\n",
       " 0.8800700902938843,\n",
       " 0.573246955871582,\n",
       " 0.6188315153121948,\n",
       " 0.5778288245201111,\n",
       " 0.5122648477554321,\n",
       " 0.5605934262275696,\n",
       " 0.5031201243400574,\n",
       " 0.6332826614379883,\n",
       " 0.5708290934562683,\n",
       " 0.5680354833602905,\n",
       " 0.5680354833602905,\n",
       " 0.6111340522766113,\n",
       " 0.6835952401161194,\n",
       " 0.6536263227462769,\n",
       " 0.6835952401161194,\n",
       " 0.6835952401161194,\n",
       " 0.5528923869132996,\n",
       " 0.6807695627212524,\n",
       " 0.7759474515914917,\n",
       " 0.5723574161529541,\n",
       " 0.5723574161529541,\n",
       " 0.7458481788635254,\n",
       " 0.8388935923576355,\n",
       " 0.6272733211517334,\n",
       " 0.6214739680290222,\n",
       " 0.5111202597618103,\n",
       " 0.5098885297775269,\n",
       " 0.5098885297775269,\n",
       " 0.6200867891311646,\n",
       " 0.5635059475898743,\n",
       " 0.592401921749115,\n",
       " 0.592401921749115,\n",
       " 0.6664696335792542,\n",
       " 0.5378977656364441,\n",
       " 0.5378977656364441,\n",
       " 0.6006457805633545,\n",
       " 0.5651401281356812,\n",
       " 0.6006457805633545,\n",
       " 0.6006457805633545,\n",
       " 0.6149498820304871,\n",
       " 0.6996985673904419,\n",
       " 0.6828349232673645,\n",
       " 0.5217838883399963,\n",
       " 0.565066933631897,\n",
       " 0.5551208853721619,\n",
       " 0.8104079961776733,\n",
       " 0.6969850063323975,\n",
       " 0.546276867389679,\n",
       " 0.6371011734008789,\n",
       " 0.5711734890937805,\n",
       " 0.6410569548606873,\n",
       " 0.7220638394355774,\n",
       " 0.6410569548606873,\n",
       " 0.641057014465332,\n",
       " 0.6521201133728027,\n",
       " 0.8410131931304932,\n",
       " 0.5412732362747192,\n",
       " 0.5576338768005371,\n",
       " 0.5225256085395813,\n",
       " 0.6550534963607788,\n",
       " 0.8642635941505432,\n",
       " 0.6550535559654236,\n",
       " 0.6416161060333252,\n",
       " 0.5972225069999695,\n",
       " 0.6024496555328369,\n",
       " 0.6418837904930115,\n",
       " 0.6024496555328369,\n",
       " 0.5885964035987854,\n",
       " 0.7444238066673279,\n",
       " 0.5756673812866211,\n",
       " 0.5690684914588928,\n",
       " 0.5690684914588928,\n",
       " 0.5953218340873718,\n",
       " 0.5398879051208496,\n",
       " 0.5398879051208496,\n",
       " 0.5398879051208496,\n",
       " 0.5580452084541321,\n",
       " 0.5692957639694214,\n",
       " 0.7376144528388977,\n",
       " 0.8719301223754883,\n",
       " 0.6612608432769775,\n",
       " 0.642356812953949,\n",
       " 0.6431204080581665,\n",
       " 0.6431204080581665,\n",
       " 0.579800546169281,\n",
       " 0.5497288703918457,\n",
       " 0.6042322516441345,\n",
       " 0.9190829396247864,\n",
       " 0.6510221362113953,\n",
       " 0.6510221362113953,\n",
       " 0.5670737028121948,\n",
       " 0.5527424812316895,\n",
       " 0.5527424812316895,\n",
       " 0.5328499674797058,\n",
       " 0.6356088519096375,\n",
       " 0.5753783583641052,\n",
       " 0.5753783583641052,\n",
       " 0.5753783583641052,\n",
       " 0.5806517004966736,\n",
       " 0.5723719596862793,\n",
       " 0.6199060082435608,\n",
       " 0.6531047224998474,\n",
       " 0.5723719596862793,\n",
       " 0.6491335034370422,\n",
       " 0.5913240909576416,\n",
       " 0.5264012217521667,\n",
       " 0.5264012217521667,\n",
       " 0.5253369212150574,\n",
       " 0.7117827534675598,\n",
       " 0.5107372403144836,\n",
       " 0.5231123566627502,\n",
       " 0.5107372403144836,\n",
       " 0.7462030053138733,\n",
       " 0.6105031967163086,\n",
       " 0.6411287188529968,\n",
       " 0.569795548915863,\n",
       " 0.6804105639457703,\n",
       " 0.6219475865364075,\n",
       " 0.6912722587585449,\n",
       " 0.6912722587585449,\n",
       " 0.5206042528152466,\n",
       " 0.5206042528152466,\n",
       " 0.5697837471961975,\n",
       " 0.5757161378860474,\n",
       " 0.5863970518112183,\n",
       " 0.5481134057044983,\n",
       " 0.5481134057044983,\n",
       " 0.6350610852241516,\n",
       " 0.6350610852241516,\n",
       " 0.637669563293457,\n",
       " 0.7847560048103333,\n",
       " 0.5137819051742554,\n",
       " 0.5166358351707458,\n",
       " 0.5170690417289734,\n",
       " 0.7187836766242981,\n",
       " 0.517885148525238,\n",
       " 0.5998160243034363,\n",
       " 0.6386200785636902,\n",
       " 0.7270167469978333,\n",
       " 0.6090468168258667,\n",
       " 0.6091207265853882,\n",
       " 0.5286148190498352,\n",
       " 0.5525890588760376,\n",
       " 0.5525890588760376,\n",
       " 0.7281779050827026,\n",
       " 0.566754162311554,\n",
       " 0.5677459239959717,\n",
       " 0.5677459239959717,\n",
       " 0.7625523805618286,\n",
       " 0.7506998181343079,\n",
       " 0.7228834629058838,\n",
       " 0.5561089515686035,\n",
       " 0.5516443848609924,\n",
       " 0.5516443848609924,\n",
       " 0.5516443848609924,\n",
       " 0.5516443848609924,\n",
       " 0.5382914543151855,\n",
       " 0.5026930570602417,\n",
       " 0.5930671691894531,\n",
       " 0.8690713047981262,\n",
       " 0.7492239475250244,\n",
       " 0.7096967101097107,\n",
       " 0.7096967101097107,\n",
       " 0.7492240071296692,\n",
       " 0.5094030499458313,\n",
       " 0.5470911860466003,\n",
       " 0.6048644185066223,\n",
       " 0.6266868114471436,\n",
       " 0.5269432067871094,\n",
       " 0.5489938855171204,\n",
       " 0.5489938855171204,\n",
       " 0.5269432067871094,\n",
       " 0.5997897386550903,\n",
       " 0.5835567712783813,\n",
       " 0.5716536641120911,\n",
       " 0.5931290984153748,\n",
       " 0.6094413995742798,\n",
       " 0.6683728694915771,\n",
       " 0.5548689961433411,\n",
       " 0.5924925804138184,\n",
       " 0.5548689961433411,\n",
       " 0.7071906328201294,\n",
       " 0.5208142399787903,\n",
       " 0.5208142399787903,\n",
       " 0.5439783930778503,\n",
       " 0.5439783930778503,\n",
       " 0.5811574459075928,\n",
       " 0.5972623229026794,\n",
       " 0.5546769499778748,\n",
       " 0.5546769499778748,\n",
       " 0.5546769499778748,\n",
       " 0.60090571641922,\n",
       " 0.60090571641922,\n",
       " 0.5536822080612183,\n",
       " 0.5413366556167603,\n",
       " 0.5906380414962769,\n",
       " 0.5536822080612183,\n",
       " 0.6325057744979858,\n",
       " 0.6325057744979858,\n",
       " 0.6325057744979858,\n",
       " 0.6163179278373718,\n",
       " 0.5048232674598694,\n",
       " 0.6588589549064636,\n",
       " 0.8320971131324768,\n",
       " 0.6241159439086914,\n",
       " 0.5962553024291992,\n",
       " 0.5756503939628601,\n",
       " 0.5756503939628601,\n",
       " 0.5756503939628601,\n",
       " 0.5756503939628601,\n",
       " 0.5527741312980652,\n",
       " 0.6762083768844604,\n",
       " 0.5951501131057739,\n",
       " 0.7523199915885925,\n",
       " 0.6233868598937988,\n",
       " 0.6608576774597168,\n",
       " 0.550126850605011,\n",
       " 0.7161492109298706,\n",
       " 0.5371006727218628,\n",
       " 0.5062368512153625,\n",
       " 0.5062368512153625,\n",
       " 0.5062368512153625,\n",
       " 0.5765544772148132,\n",
       " 0.6028163433074951,\n",
       " 0.5765544772148132,\n",
       " 0.5308099389076233,\n",
       " 0.5519852638244629,\n",
       " 0.6028163433074951,\n",
       " 0.6028163433074951,\n",
       " 0.5429893732070923,\n",
       " 0.5404636859893799,\n",
       " 0.6527549028396606,\n",
       " 0.6616977453231812,\n",
       " 0.6616977453231812,\n",
       " 0.6616977453231812,\n",
       " 0.6213138699531555,\n",
       " 0.6411681771278381,\n",
       " 0.631695568561554,\n",
       " 0.5907829403877258,\n",
       " 0.5128712058067322,\n",
       " 0.5992704629898071,\n",
       " 0.5194328427314758,\n",
       " 0.5510870218276978,\n",
       " 0.5946661829948425,\n",
       " 0.5510870218276978,\n",
       " 0.5552616715431213,\n",
       " 0.5330930948257446,\n",
       " 0.5007047653198242,\n",
       " 0.5330930948257446,\n",
       " 0.53434818983078,\n",
       " 0.8479733467102051,\n",
       " 0.620283842086792,\n",
       " 0.5753465294837952,\n",
       " 0.553178608417511,\n",
       " 0.602459728717804,\n",
       " 0.5753465294837952,\n",
       " 0.6591041088104248,\n",
       " 0.5006045699119568,\n",
       " 0.5777101516723633,\n",
       " 0.5421298146247864,\n",
       " 0.5328431129455566,\n",
       " 0.5453885793685913,\n",
       " 0.554425060749054,\n",
       " 0.6909379959106445,\n",
       " 0.5806736350059509,\n",
       " 0.5275803804397583,\n",
       " 0.5524659752845764,\n",
       " 0.541325032711029,\n",
       " 0.5904250741004944,\n",
       " 0.5524659752845764,\n",
       " 0.5217509269714355,\n",
       " 0.733497142791748,\n",
       " 0.5115091800689697,\n",
       " 0.5507952570915222,\n",
       " 0.5085861086845398,\n",
       " 0.5085861086845398,\n",
       " 0.5085861086845398,\n",
       " 0.557719886302948,\n",
       " 0.5305161476135254,\n",
       " 0.5918774604797363,\n",
       " 0.5083955526351929,\n",
       " 0.5673498511314392,\n",
       " 0.559778094291687,\n",
       " 0.559778094291687,\n",
       " 0.6979381442070007,\n",
       " 0.5848954916000366,\n",
       " 0.5424498915672302,\n",
       " 0.5709009170532227,\n",
       " 0.5116478800773621,\n",
       " 0.7076401710510254,\n",
       " 0.8867089152336121,\n",
       " 0.683232307434082,\n",
       " 0.7685447335243225,\n",
       " 0.7000744342803955,\n",
       " 0.6681790351867676,\n",
       " 0.7389108538627625,\n",
       " 0.772663950920105,\n",
       " 0.6637718677520752,\n",
       " 0.6313331723213196,\n",
       " 0.8366028070449829,\n",
       " 0.6143117547035217,\n",
       " 0.5834289789199829,\n",
       " 0.5768660306930542,\n",
       " 0.6665148735046387,\n",
       " 0.5653073787689209,\n",
       " 0.6779504418373108,\n",
       " 0.5174844861030579,\n",
       " 0.5889676213264465,\n",
       " 0.5889676213264465,\n",
       " 0.6716710329055786,\n",
       " 0.6441694498062134,\n",
       " 0.6441694498062134,\n",
       " 0.6441694498062134,\n",
       " 0.640326738357544,\n",
       " 0.6653057932853699,\n",
       " 0.6168180108070374,\n",
       " 0.6653057932853699,\n",
       " 0.6170696020126343,\n",
       " 0.6401488780975342,\n",
       " 0.5709879398345947,\n",
       " 0.5709879398345947,\n",
       " 0.5858086943626404,\n",
       " 0.5709879398345947,\n",
       " 0.5709879398345947,\n",
       " 0.8466439843177795,\n",
       " 0.574367105960846,\n",
       " 0.5680869221687317,\n",
       " 0.610202968120575,\n",
       " 0.6097827553749084,\n",
       " 0.5295763611793518,\n",
       " 0.5346295237541199,\n",
       " 0.5800274014472961,\n",
       " 0.5800274014472961,\n",
       " 0.5512698292732239,\n",
       " 0.5512698292732239,\n",
       " 0.5512698292732239,\n",
       " 0.511730432510376,\n",
       " 0.589740514755249,\n",
       " 0.5036964416503906,\n",
       " 0.6721115112304688,\n",
       " 0.5052299499511719,\n",
       " 0.50520920753479,\n",
       " 0.5196360349655151,\n",
       " 0.5196360349655151,\n",
       " 0.7134745121002197,\n",
       " 0.6499680876731873,\n",
       " 0.6482046246528625,\n",
       " 0.6066650748252869,\n",
       " 0.6037360429763794,\n",
       " 0.5852347016334534,\n",
       " 0.5658203959465027,\n",
       " 0.551305890083313,\n",
       " 0.5658203959465027,\n",
       " 0.5791077613830566,\n",
       " 0.7619422674179077,\n",
       " 0.6673953533172607,\n",
       " 0.7258567214012146,\n",
       " 0.635701596736908,\n",
       " 0.635701596736908,\n",
       " 0.635701596736908,\n",
       " 0.635701596736908,\n",
       " 0.6773987412452698,\n",
       " 0.5489831566810608,\n",
       " 0.5489831566810608,\n",
       " 0.5387086272239685,\n",
       " 0.6298439502716064,\n",
       " 0.6764914989471436,\n",
       " 0.7278792858123779,\n",
       " 0.5361674427986145,\n",
       " 0.642051100730896,\n",
       " 0.642051100730896,\n",
       " 0.642051100730896,\n",
       " 0.5626175999641418,\n",
       " 0.7424784302711487,\n",
       " 0.5869109034538269,\n",
       " 0.5728771686553955,\n",
       " 0.5406538844108582,\n",
       " 0.5576527714729309,\n",
       " 0.5406538844108582,\n",
       " 0.5651678442955017,\n",
       " 0.5894032120704651,\n",
       " 0.5651678442955017,\n",
       " 0.5858571529388428,\n",
       " 0.5858572125434875,\n",
       " 0.5858572125434875,\n",
       " 0.5916829109191895,\n",
       " 0.5916829109191895,\n",
       " 0.5916829109191895,\n",
       " 0.5916829109191895,\n",
       " 0.5228208303451538,\n",
       " 0.502945601940155,\n",
       " 0.5228208303451538,\n",
       " 0.502945601940155,\n",
       " 0.7099829912185669,\n",
       " 0.583823561668396,\n",
       " 0.6018986105918884,\n",
       " 0.5950132608413696,\n",
       " 0.583823561668396,\n",
       " 0.7935499548912048,\n",
       " 0.6264429092407227,\n",
       " 0.6714110374450684,\n",
       " 0.6092815399169922,\n",
       " 0.6392756104469299,\n",
       " 0.5266059637069702,\n",
       " 0.5543949604034424,\n",
       " 0.5238320827484131,\n",
       " 0.5276148915290833,\n",
       " 0.5117960572242737,\n",
       " 0.5877635478973389,\n",
       " 0.6678737998008728,\n",
       " 0.6832008361816406,\n",
       " 0.6115795969963074,\n",
       " 0.6598713397979736,\n",
       " 0.9155056476593018,\n",
       " 0.657904326915741,\n",
       " 0.6553691029548645,\n",
       " 0.6357207894325256,\n",
       " 0.77653968334198,\n",
       " 0.673088014125824,\n",
       " 0.6736688017845154,\n",
       " 0.5814428329467773,\n",
       " 0.5814428329467773,\n",
       " 0.5995550751686096,\n",
       " 0.5995550751686096,\n",
       " 0.6229850053787231,\n",
       " 0.7277489900588989,\n",
       " 0.6817755103111267,\n",
       " 0.592555820941925,\n",
       " 0.5521684885025024,\n",
       " 0.5496091842651367,\n",
       " 0.5449377298355103,\n",
       " 0.5760922431945801,\n",
       " 0.6608548760414124,\n",
       " 0.5777466893196106,\n",
       " 0.6917372941970825,\n",
       " 0.8199099898338318,\n",
       " 0.7556087374687195,\n",
       " 0.6408557891845703,\n",
       " 0.6464073657989502,\n",
       " 0.6739860773086548,\n",
       " 0.6109297275543213,\n",
       " 0.6335433125495911,\n",
       " 0.613276481628418,\n",
       " 0.5888980031013489,\n",
       " 0.5633718371391296,\n",
       " 0.5444045662879944,\n",
       " 0.5437332391738892,\n",
       " 0.7959997057914734,\n",
       " 0.7914987802505493,\n",
       " 0.7840147614479065,\n",
       " 0.7278581857681274,\n",
       " 0.5170056223869324,\n",
       " 0.5587604641914368,\n",
       " 0.5587604641914368,\n",
       " 0.6769733428955078,\n",
       " 0.6377003192901611,\n",
       " 0.7037546038627625,\n",
       " 0.6377003192901611,\n",
       " 0.5946215391159058,\n",
       " 0.5623947381973267,\n",
       " 0.6778776049613953,\n",
       " 0.5623947381973267,\n",
       " 0.5959073305130005,\n",
       " 0.6929762363433838,\n",
       " 0.5531318783760071,\n",
       " 0.5531318187713623,\n",
       " 0.5685091018676758,\n",
       " 0.5609523057937622,\n",
       " 0.5531318187713623,\n",
       " 0.5300087332725525,\n",
       " 0.6172630786895752,\n",
       " 0.5997719764709473,\n",
       " 0.5784027576446533,\n",
       " 0.6021867394447327,\n",
       " 0.7695387601852417,\n",
       " 0.5759018063545227,\n",
       " 0.6064260005950928,\n",
       " 0.5759018063545227,\n",
       " 0.6908925175666809,\n",
       " 0.663913905620575,\n",
       " 0.5726314783096313,\n",
       " 0.5523806810379028,\n",
       " 0.6891762614250183,\n",
       " 0.7606605291366577,\n",
       " 0.6156300902366638,\n",
       " 0.6156300902366638,\n",
       " 0.6158351898193359,\n",
       " 0.6421902775764465,\n",
       " 0.6244083642959595,\n",
       " 0.6231661438941956,\n",
       " 0.654851496219635,\n",
       " 0.6608749032020569,\n",
       " 0.6212751865386963,\n",
       " 0.6271419525146484,\n",
       " 0.5150076746940613,\n",
       " 0.5726991295814514,\n",
       " 0.5150076746940613,\n",
       " 0.5150076746940613,\n",
       " 0.6571930646896362,\n",
       " 0.6571930646896362,\n",
       " 0.6571930646896362,\n",
       " 0.5784769654273987,\n",
       " 0.6571930646896362,\n",
       " 0.5697300434112549,\n",
       " 0.5935989022254944,\n",
       " 0.5788765549659729,\n",
       " 0.5788765549659729,\n",
       " 0.5788765549659729,\n",
       " 0.5788765549659729,\n",
       " 0.530356764793396,\n",
       " 0.530356764793396,\n",
       " 0.5734540224075317,\n",
       " 0.5302462577819824,\n",
       " 0.5376477241516113,\n",
       " 0.5376477241516113,\n",
       " 0.8186621069908142,\n",
       " 0.7606450319290161,\n",
       " 0.7881767749786377,\n",
       " 0.704168438911438,\n",
       " 0.7049208879470825,\n",
       " 0.6098505258560181,\n",
       " 0.6098505258560181,\n",
       " 0.6086714863777161,\n",
       " 0.5643228888511658,\n",
       " 0.5643228888511658,\n",
       " 0.5252373218536377,\n",
       " 0.5398167371749878,\n",
       " 0.531182587146759,\n",
       " 0.6319948434829712,\n",
       " 0.6442800760269165,\n",
       " 0.6829389333724976,\n",
       " 0.8178436160087585,\n",
       " 0.5952946543693542,\n",
       " 0.5998504757881165,\n",
       " 0.5690421462059021,\n",
       " 0.6191763877868652,\n",
       " 0.6423600316047668,\n",
       " 0.5927342772483826,\n",
       " 0.591774582862854,\n",
       " 0.6414442658424377,\n",
       " 0.5821816921234131,\n",
       " 0.6358581185340881,\n",
       " 0.5810467600822449,\n",
       " 0.7761527299880981,\n",
       " 0.7412334084510803,\n",
       " 0.7412334084510803,\n",
       " 0.7412334084510803,\n",
       " 0.5334804058074951,\n",
       " 0.6205260157585144,\n",
       " 0.6522682309150696,\n",
       " 0.6522682309150696,\n",
       " 0.7375756502151489,\n",
       " 0.5194023847579956,\n",
       " 0.5773241519927979,\n",
       " 0.5773241519927979,\n",
       " 0.5773241519927979,\n",
       " 0.6610673666000366,\n",
       " 0.6610673666000366,\n",
       " 0.7086957097053528,\n",
       " 0.5992804765701294,\n",
       " 0.6062151193618774,\n",
       " 0.5953144431114197,\n",
       " 0.6689553260803223,\n",
       " 0.6483349800109863,\n",
       " 0.6548917293548584,\n",
       " 0.8155898451805115,\n",
       " 0.6258183717727661,\n",
       " 0.6261513829231262,\n",
       " 0.6548917293548584,\n",
       " 0.6772590279579163,\n",
       " 0.6772590279579163,\n",
       " 0.6772590279579163,\n",
       " 0.726642906665802,\n",
       " 0.7693091034889221,\n",
       " 0.7693091034889221,\n",
       " 0.7259414196014404,\n",
       " 0.532252311706543,\n",
       " 0.532252311706543,\n",
       " 0.6450300812721252,\n",
       " 0.6450300812721252,\n",
       " 0.6450300812721252,\n",
       " 0.6450300216674805,\n",
       " 0.6491665244102478,\n",
       " 0.6491665244102478,\n",
       " 0.7224335074424744,\n",
       " 0.6491665244102478,\n",
       " 0.5263298153877258,\n",
       " 0.8364844918251038,\n",
       " 0.6713939309120178,\n",
       " 0.5243794918060303,\n",
       " 0.6049222946166992,\n",
       " 0.7257533073425293,\n",
       " 0.8284170031547546,\n",
       " 0.7257533073425293,\n",
       " 0.7257533073425293,\n",
       " 0.7257533073425293,\n",
       " 0.7257533073425293,\n",
       " 0.5285606384277344,\n",
       " 0.673160195350647,\n",
       " 0.6343993544578552,\n",
       " 0.6094841361045837,\n",
       " 0.5810889601707458,\n",
       " 0.5973769426345825,\n",
       " 0.5087182521820068,\n",
       " 0.5087182521820068,\n",
       " 0.5087182521820068,\n",
       " 0.5871337056159973,\n",
       " 0.5808164477348328,\n",
       " 0.596997082233429,\n",
       " 0.596997082233429,\n",
       " 0.596997082233429,\n",
       " 0.596997082233429,\n",
       " 0.6907171010971069,\n",
       " 0.811097264289856,\n",
       " 0.5897643566131592,\n",
       " 0.8412073254585266,\n",
       " 0.6313896179199219,\n",
       " 0.6320574283599854,\n",
       " 0.5522814989089966,\n",
       " 0.5776281952857971,\n",
       " 0.5699794292449951,\n",
       " 0.5460610389709473,\n",
       " 0.520106315612793,\n",
       " 0.5181179642677307,\n",
       " 0.5532227754592896,\n",
       " 0.5918917655944824,\n",
       " 0.7609301805496216,\n",
       " 0.7373471260070801,\n",
       " 0.797048032283783,\n",
       " 0.5369360446929932,\n",
       " 0.7685126662254333,\n",
       " 0.6631461977958679,\n",
       " 0.5925350785255432,\n",
       " 0.5708248019218445,\n",
       " 0.5498493313789368,\n",
       " 0.5925350785255432,\n",
       " 0.5611166954040527,\n",
       " 0.5925350785255432,\n",
       " 0.5768740177154541,\n",
       " 0.6482948660850525,\n",
       " 0.6751682758331299,\n",
       " 0.6482948660850525,\n",
       " 0.6297617554664612,\n",
       " 0.7712371945381165,\n",
       " 0.6297109127044678,\n",
       " 0.6354703307151794,\n",
       " 0.7299070358276367,\n",
       " 0.5807384848594666,\n",
       " 0.6966683864593506,\n",
       " 0.6169894933700562,\n",
       " 0.580876886844635,\n",
       " 0.7142560482025146,\n",
       " 0.6591394543647766,\n",
       " 0.6681081652641296,\n",
       " 0.6536673903465271,\n",
       " 0.7190764546394348,\n",
       " 0.5395472645759583,\n",
       " 0.6047060489654541,\n",
       " 0.5872952938079834,\n",
       " 0.6279259920120239,\n",
       " 0.5406040549278259,\n",
       " 0.514385461807251,\n",
       " 0.6677482724189758,\n",
       " 0.530214250087738,\n",
       " 0.547938883304596,\n",
       " 0.5202890634536743,\n",
       " 0.5587518215179443,\n",
       " 0.5312493443489075,\n",
       " 0.5312493443489075,\n",
       " 0.5542263984680176,\n",
       " 0.5107718110084534,\n",
       " 0.5094818472862244,\n",
       " 0.6843357086181641,\n",
       " 0.5809750556945801,\n",
       " 0.6531975865364075,\n",
       " 0.5183798670768738,\n",
       " 0.5183798670768738,\n",
       " 0.623883068561554,\n",
       " 0.7670928835868835,\n",
       " 0.629729151725769,\n",
       " 0.6263860464096069,\n",
       " 0.5924503207206726,\n",
       " 0.5950770974159241,\n",
       " 0.5783528089523315,\n",
       " 0.5441209077835083,\n",
       " 0.5800867080688477,\n",
       " 0.5800867080688477,\n",
       " 0.5800867080688477,\n",
       " 0.5291151404380798,\n",
       " 0.5789539217948914,\n",
       " 0.5324793457984924,\n",
       " 0.5345531702041626,\n",
       " 0.5816277861595154,\n",
       " 0.6722128987312317,\n",
       " 0.6722690463066101,\n",
       " 0.6702716946601868,\n",
       " 0.6816715598106384,\n",
       " 0.6516633629798889,\n",
       " 0.5653387904167175,\n",
       " 0.5663276314735413,\n",
       " 0.6148317456245422,\n",
       " 0.6233140826225281,\n",
       " 0.6589518189430237,\n",
       " 0.6589518189430237,\n",
       " 0.5505454540252686,\n",
       " 0.5505454540252686,\n",
       " 0.6284605264663696,\n",
       " 0.6284605264663696,\n",
       " 0.7268624901771545,\n",
       " 0.6284605264663696,\n",
       " 0.6725871562957764,\n",
       " 0.665534257888794,\n",
       " 0.7994667291641235,\n",
       " 0.665534257888794,\n",
       " 0.665534257888794,\n",
       " 0.5352333188056946,\n",
       " 0.510307788848877,\n",
       " 0.7061324119567871,\n",
       " 0.5485591888427734,\n",
       " 0.5485591888427734,\n",
       " 0.6968259215354919,\n",
       " 0.6126852631568909,\n",
       " 0.6126852631568909,\n",
       " 0.6294969916343689,\n",
       " 0.569404661655426,\n",
       " 0.6717979907989502,\n",
       " 0.6450642943382263,\n",
       " 0.671205461025238,\n",
       " 0.5572719573974609,\n",
       " 0.6649107336997986,\n",
       " 0.5475203394889832,\n",
       " 0.5071297883987427,\n",
       " 0.6538770198822021,\n",
       " 0.9249736070632935,\n",
       " 0.5836142301559448,\n",
       " 0.5848068594932556,\n",
       " 0.6828176379203796,\n",
       " 0.5520364046096802,\n",
       " 0.6333463788032532,\n",
       " 0.6635391712188721,\n",
       " 0.5420613288879395,\n",
       " 0.5420613288879395,\n",
       " 0.5136086940765381,\n",
       " 0.6934728026390076,\n",
       " 0.7008107900619507,\n",
       " ...]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=[]\n",
    "for i in range(newedge.shape[0]):\n",
    "    l.append(float(prob_adj[newedge[0][i]][newedge[1][i]]))\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9b4aba8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>dot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1080701</th>\n",
       "      <td>441</td>\n",
       "      <td>2720</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6269004</th>\n",
       "      <td>2585</td>\n",
       "      <td>3514</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512566</th>\n",
       "      <td>3515</td>\n",
       "      <td>3497</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512565</th>\n",
       "      <td>3515</td>\n",
       "      <td>3496</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512564</th>\n",
       "      <td>3515</td>\n",
       "      <td>3494</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5932826</th>\n",
       "      <td>2446</td>\n",
       "      <td>112</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5932827</th>\n",
       "      <td>2446</td>\n",
       "      <td>113</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277668</th>\n",
       "      <td>113</td>\n",
       "      <td>2446</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273052</th>\n",
       "      <td>111</td>\n",
       "      <td>2446</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5932824</th>\n",
       "      <td>2446</td>\n",
       "      <td>110</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11411469 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         source  target  dot\n",
       "1080701     441    2720  1.0\n",
       "6269004    2585    3514  1.0\n",
       "8512566    3515    3497  1.0\n",
       "8512565    3515    3496  1.0\n",
       "8512564    3515    3494  1.0\n",
       "...         ...     ...  ...\n",
       "5932826    2446     112  0.5\n",
       "5932827    2446     113  0.5\n",
       "277668      113    2446  0.5\n",
       "273052      111    2446  0.5\n",
       "5932824    2446     110  0.5\n",
       "\n",
       "[11411469 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newedge['dot']=l\n",
    "newedge=newedge.sort_values(by='dot',ascending=False)\n",
    "newedge.columns=['source','target','dot']\n",
    "newedge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d212c47f",
   "metadata": {},
   "source": [
    "探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "95c8ed45",
   "metadata": {},
   "outputs": [],
   "source": [
    "oldedge=edges_data_biderect\n",
    "oldedge.reset_index(drop=True, inplace=True)\n",
    "oldedge.columns=['source','target','dot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "33bdf82f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>dot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12638</th>\n",
       "      <td>3746.0</td>\n",
       "      <td>3748.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11123</th>\n",
       "      <td>2031.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>233.0</td>\n",
       "      <td>454.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>233.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28948</th>\n",
       "      <td>1130.0</td>\n",
       "      <td>3536.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6548</th>\n",
       "      <td>2262.0</td>\n",
       "      <td>2263.0</td>\n",
       "      <td>0.002695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>1381.0</td>\n",
       "      <td>3764.0</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12714</th>\n",
       "      <td>3764.0</td>\n",
       "      <td>1381.0</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17571</th>\n",
       "      <td>167.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>196.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34566 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       source  target       dot\n",
       "12638  3746.0  3748.0  1.000000\n",
       "11123  2031.0  3400.0  1.000000\n",
       "2497    233.0   454.0  1.000000\n",
       "2496    233.0   442.0  1.000000\n",
       "28948  1130.0  3536.0  1.000000\n",
       "...       ...     ...       ...\n",
       "6548   2262.0  2263.0  0.002695\n",
       "29997  1381.0  3764.0  0.000086\n",
       "12714  3764.0  1381.0  0.000086\n",
       "17571   167.0   196.0  0.000010\n",
       "288     196.0   167.0  0.000010\n",
       "\n",
       "[34566 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(oldedge.shape[0]):\n",
    "    oldedge['dot'][i]=float(prob_adj[int(oldedge['source'][i])][int(oldedge['target'][i])])\n",
    "oldedge=oldedge.sort_values(by='dot',ascending=False)\n",
    "oldedge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "180033ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "oldedge.to_csv('E:\\\\GraphSAGE\\\\Scopus_2022_9_21_1\\\\result\\\\oldedge_sort1.csv',sep=',',index=0)\n",
    "newedge.to_csv('E:\\\\GraphSAGE\\\\Scopus_2022_9_21_1\\\\result\\\\newedge_sort1.csv',sep=',',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4a3c99be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>dot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8881201</th>\n",
       "      <td>3562.0</td>\n",
       "      <td>1822.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780856</th>\n",
       "      <td>3517.0</td>\n",
       "      <td>2385.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780790</th>\n",
       "      <td>3517.0</td>\n",
       "      <td>1876.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3908858</th>\n",
       "      <td>1558.0</td>\n",
       "      <td>4405.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3908859</th>\n",
       "      <td>1558.0</td>\n",
       "      <td>4406.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897095</th>\n",
       "      <td>748.0</td>\n",
       "      <td>1103.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756971</th>\n",
       "      <td>1103.0</td>\n",
       "      <td>747.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7648569</th>\n",
       "      <td>3053.0</td>\n",
       "      <td>2842.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7131793</th>\n",
       "      <td>2842.0</td>\n",
       "      <td>3053.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894061</th>\n",
       "      <td>747.0</td>\n",
       "      <td>1103.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11736237 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         source  target  dot\n",
       "8881201  3562.0  1822.0  1.0\n",
       "8780856  3517.0  2385.0  1.0\n",
       "8780790  3517.0  1876.0  1.0\n",
       "3908858  1558.0  4405.0  1.0\n",
       "3908859  1558.0  4406.0  1.0\n",
       "...         ...     ...  ...\n",
       "1897095   748.0  1103.0  0.5\n",
       "2756971  1103.0   747.0  0.5\n",
       "7648569  3053.0  2842.0  0.5\n",
       "7131793  2842.0  3053.0  0.5\n",
       "1894061   747.0  1103.0  0.5\n",
       "\n",
       "[11736237 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otheredge=pd.concat([newedge,oldedge,oldedge])\n",
    "otheredge=otheredge.drop_duplicates(subset=['source','target'],keep=False)\n",
    "otheredge=otheredge.sort_values(by='dot',ascending=False)\n",
    "otheredge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "80e3ee60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>dot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8881201</th>\n",
       "      <td>3562.0</td>\n",
       "      <td>1822.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780856</th>\n",
       "      <td>3517.0</td>\n",
       "      <td>2385.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780790</th>\n",
       "      <td>3517.0</td>\n",
       "      <td>1876.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3908858</th>\n",
       "      <td>1558.0</td>\n",
       "      <td>4405.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3908859</th>\n",
       "      <td>1558.0</td>\n",
       "      <td>4406.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10945344</th>\n",
       "      <td>4405.0</td>\n",
       "      <td>2705.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10945345</th>\n",
       "      <td>4405.0</td>\n",
       "      <td>2716.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10945346</th>\n",
       "      <td>4405.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10945349</th>\n",
       "      <td>4405.0</td>\n",
       "      <td>2728.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10945347</th>\n",
       "      <td>4405.0</td>\n",
       "      <td>2721.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20211 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          source  target  dot\n",
       "8881201   3562.0  1822.0  1.0\n",
       "8780856   3517.0  2385.0  1.0\n",
       "8780790   3517.0  1876.0  1.0\n",
       "3908858   1558.0  4405.0  1.0\n",
       "3908859   1558.0  4406.0  1.0\n",
       "...          ...     ...  ...\n",
       "10945344  4405.0  2705.0  1.0\n",
       "10945345  4405.0  2716.0  1.0\n",
       "10945346  4405.0  2720.0  1.0\n",
       "10945349  4405.0  2728.0  1.0\n",
       "10945347  4405.0  2721.0  1.0\n",
       "\n",
       "[20211 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otheredge[otheredge['dot']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c7b1c0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "otheredge.to_csv('E:\\\\GraphSAGE\\\\Scopus_2022_9_21_1\\\\result\\\\otheredge_sort1.csv',sep=',',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0fdf7142",
   "metadata": {},
   "outputs": [],
   "source": [
    "otheredge1 = otheredge.drop(otheredge[otheredge['source']==otheredge['target']].index)\n",
    "otheredge1.reset_index(drop=True, inplace=True)\n",
    "otheredge1.to_csv('E:\\\\GraphSAGE\\\\Scopus_2022_9_21_1\\\\result\\\\otheredge_sort_noselfcircle1.csv',sep=',',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ce0d4216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>dot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3562.0</td>\n",
       "      <td>1822.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3517.0</td>\n",
       "      <td>2385.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3517.0</td>\n",
       "      <td>1876.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1558.0</td>\n",
       "      <td>4405.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1558.0</td>\n",
       "      <td>4406.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>4191.0</td>\n",
       "      <td>4405.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>3535.0</td>\n",
       "      <td>2671.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1477.0</td>\n",
       "      <td>2721.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>548.0</td>\n",
       "      <td>2721.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>3586.0</td>\n",
       "      <td>2262.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      source  target  dot\n",
       "0     3562.0  1822.0  1.0\n",
       "1     3517.0  2385.0  1.0\n",
       "2     3517.0  1876.0  1.0\n",
       "3     1558.0  4405.0  1.0\n",
       "4     1558.0  4406.0  1.0\n",
       "...      ...     ...  ...\n",
       "1995  4191.0  4405.0  1.0\n",
       "1996  3535.0  2671.0  1.0\n",
       "1997  1477.0  2721.0  1.0\n",
       "1998   548.0  2721.0  1.0\n",
       "1999  3586.0  2262.0  1.0\n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otheredge2=otheredge1[0:2000]\n",
    "otheredge2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "81457f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_77044\\1426314943.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  otheredge2['source'][i]=otheredge2['target'][i]\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_77044\\1426314943.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  otheredge2['target'][i]=mid\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_77044\\1426314943.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  otheredge2['source'][i]=otheredge2['source'][i]\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_77044\\1426314943.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  otheredge2['target'][i]=otheredge2['target'][i]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>dot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1822.0</td>\n",
       "      <td>3562.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2385.0</td>\n",
       "      <td>3517.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1876.0</td>\n",
       "      <td>3517.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1558.0</td>\n",
       "      <td>4405.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1558.0</td>\n",
       "      <td>4406.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>4191.0</td>\n",
       "      <td>4405.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>2671.0</td>\n",
       "      <td>3535.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1477.0</td>\n",
       "      <td>2721.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>548.0</td>\n",
       "      <td>2721.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2262.0</td>\n",
       "      <td>3586.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      source  target  dot\n",
       "0     1822.0  3562.0  1.0\n",
       "1     2385.0  3517.0  1.0\n",
       "2     1876.0  3517.0  1.0\n",
       "3     1558.0  4405.0  1.0\n",
       "4     1558.0  4406.0  1.0\n",
       "...      ...     ...  ...\n",
       "1995  4191.0  4405.0  1.0\n",
       "1996  2671.0  3535.0  1.0\n",
       "1997  1477.0  2721.0  1.0\n",
       "1998   548.0  2721.0  1.0\n",
       "1999  2262.0  3586.0  1.0\n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(otheredge2.shape[0]):\n",
    "    if otheredge2['source'][i]<otheredge2['target'][i]:\n",
    "        otheredge2['source'][i]=otheredge2['source'][i]\n",
    "        otheredge2['target'][i]=otheredge2['target'][i]\n",
    "    else:\n",
    "        mid=otheredge2['source'][i]\n",
    "        otheredge2['source'][i]=otheredge2['target'][i]\n",
    "        otheredge2['target'][i]=mid\n",
    "otheredge2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fd9146b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>dot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1822.0</td>\n",
       "      <td>3562.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2385.0</td>\n",
       "      <td>3517.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1876.0</td>\n",
       "      <td>3517.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1558.0</td>\n",
       "      <td>4405.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1558.0</td>\n",
       "      <td>4406.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>4191.0</td>\n",
       "      <td>4405.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927</th>\n",
       "      <td>2671.0</td>\n",
       "      <td>3535.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>1477.0</td>\n",
       "      <td>2721.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>548.0</td>\n",
       "      <td>2721.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>2262.0</td>\n",
       "      <td>3586.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1931 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      source  target  dot\n",
       "0     1822.0  3562.0  1.0\n",
       "1     2385.0  3517.0  1.0\n",
       "2     1876.0  3517.0  1.0\n",
       "3     1558.0  4405.0  1.0\n",
       "4     1558.0  4406.0  1.0\n",
       "...      ...     ...  ...\n",
       "1926  4191.0  4405.0  1.0\n",
       "1927  2671.0  3535.0  1.0\n",
       "1928  1477.0  2721.0  1.0\n",
       "1929   548.0  2721.0  1.0\n",
       "1930  2262.0  3586.0  1.0\n",
       "\n",
       "[1931 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otheredge2=otheredge2.drop_duplicates(keep=\"first\")\n",
    "otheredge2.reset_index(drop=True,inplace=True)\n",
    "otheredge2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "640cb55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'lda',\n",
       " 1: 'hierarchical agglomerative clustering',\n",
       " 2: 'discipline topic',\n",
       " 3: 'data visualization',\n",
       " 4: 'datadriven',\n",
       " 5: 'citation pattern',\n",
       " 6: 'hathi trust digital library',\n",
       " 7: 'potential tool development',\n",
       " 8: 'compute education',\n",
       " 9: 'liberal art compute',\n",
       " 10: 'liberal education',\n",
       " 11: 'coproduction',\n",
       " 12: 'climate change',\n",
       " 13: 'social science and humanity',\n",
       " 14: 'conceptual lens',\n",
       " 15: 'pest control technique',\n",
       " 16: 'agricultural improvement',\n",
       " 17: 'entomological investigation',\n",
       " 18: 'palaeography',\n",
       " 19: 'multidisciplinary collaboration',\n",
       " 20: 'computational mean',\n",
       " 21: 'humanity research',\n",
       " 22: 'bibliometric evaluation',\n",
       " 23: 'book review',\n",
       " 24: 'journal quality indicator',\n",
       " 25: 'lap',\n",
       " 26: 'library',\n",
       " 27: 'collaboration',\n",
       " 28: 'sustainability',\n",
       " 29: 'document',\n",
       " 30: 'use case',\n",
       " 31: 'activity theory',\n",
       " 32: 'compute community',\n",
       " 33: 'social science',\n",
       " 34: 'citation analysis',\n",
       " 35: 'isi',\n",
       " 36: 'internet outage',\n",
       " 37: 'disaster',\n",
       " 38: 'dependent',\n",
       " 39: 'interactive whiteboard',\n",
       " 40: 'creative teaching',\n",
       " 41: 'literacy',\n",
       " 42: 'mathematics',\n",
       " 43: 'wholeclass teaching',\n",
       " 44: 'safety argument deconstruction',\n",
       " 45: 'adversarial counterargument',\n",
       " 46: 'gsn',\n",
       " 47: 'annotation tool',\n",
       " 48: 'humanity compute',\n",
       " 49: 'online chopin variorum edition',\n",
       " 50: 'compute science',\n",
       " 51: 'digital scholarship',\n",
       " 52: 'cyberinfrastructure',\n",
       " 53: 'text creation partnership',\n",
       " 54: 'escience',\n",
       " 55: 'high performance computing tool',\n",
       " 56: 'frontend representation',\n",
       " 57: 'modern manuscript material',\n",
       " 58: 'corpus',\n",
       " 59: 'ancient french legend of roland',\n",
       " 60: 'xml semantic encoding',\n",
       " 61: 'information density',\n",
       " 62: 'history literary work',\n",
       " 63: 'longrange correlation',\n",
       " 64: 'human writing',\n",
       " 65: 'scholarly communication',\n",
       " 66: 'bibliometrics characteristic',\n",
       " 67: 'selfcitation ratio',\n",
       " 68: 'disciplinary turfpolity',\n",
       " 69: 'geopolitical metaphor',\n",
       " 70: 'operative conception',\n",
       " 71: 'feminist',\n",
       " 72: 'knowledge representation',\n",
       " 73: 'scholarly production model',\n",
       " 74: 'semantic markup',\n",
       " 75: 'database journal',\n",
       " 76: 'comparison',\n",
       " 77: 'manuscript review',\n",
       " 78: 'metric collection',\n",
       " 79: 'temporality effect',\n",
       " 80: 'literary',\n",
       " 81: 'text analysis',\n",
       " 82: 'time cognition',\n",
       " 83: 'computer science',\n",
       " 84: 'digital library',\n",
       " 85: 'ept',\n",
       " 86: 'dhi',\n",
       " 87: 'value chain',\n",
       " 88: 'project work',\n",
       " 89: 'virtual reality',\n",
       " 90: 'cultural history',\n",
       " 91: 'multiculture',\n",
       " 92: 'correlation',\n",
       " 93: 'literary text',\n",
       " 94: 'selfsimilarity',\n",
       " 95: 'additive markov chain',\n",
       " 96: 'longrange memory',\n",
       " 97: 'computer',\n",
       " 98: 'data processing',\n",
       " 99: 'gis',\n",
       " 100: 'cultural heritage',\n",
       " 101: 'digital resource',\n",
       " 102: 'historiography',\n",
       " 103: 'science and technology history',\n",
       " 104: 'tacit objectknowledge',\n",
       " 105: 'spatial data',\n",
       " 106: 'data analysis',\n",
       " 107: 'textual encoding',\n",
       " 108: 'stroke makeup',\n",
       " 109: 'roman text',\n",
       " 110: 'scientific literature',\n",
       " 111: 'associative concept',\n",
       " 112: 'concept space',\n",
       " 113: 'hebbian  information retrieval',\n",
       " 114: 'forensic linguistics',\n",
       " 115: 'tamper detection',\n",
       " 116: 'signal cutting identify',\n",
       " 117: 'text analysis tool',\n",
       " 118: 'critical analysis',\n",
       " 119: 'literary criticism',\n",
       " 120: 'public humanity program',\n",
       " 121: 'primitive set',\n",
       " 122: 'high education',\n",
       " 123: 'interdiscipline',\n",
       " 124: 'methodological',\n",
       " 125: 'exchange obstacle',\n",
       " 126: 'cooperation opportunity',\n",
       " 127: 'spectrum',\n",
       " 128: 'webtool',\n",
       " 129: 'internet resource',\n",
       " 130: 'university language learning',\n",
       " 131: 'implementation strategy',\n",
       " 132: 'ulysses',\n",
       " 133: 'text style',\n",
       " 134: 'multivariate statistic',\n",
       " 135: 'rom',\n",
       " 136: 'electronic text  enterprise',\n",
       " 137: 'information literacy',\n",
       " 138: 'key definition',\n",
       " 139: 'skill',\n",
       " 140: 'model',\n",
       " 141: 'limitation',\n",
       " 142: 'speculation',\n",
       " 143: 'science fiction  prediction',\n",
       " 144: 'textual feature overlap',\n",
       " 145: 'concurrent document hierarchy',\n",
       " 146: 'humanistic research',\n",
       " 147: 'thesaurus lingua graecae',\n",
       " 148: 'technological literacy',\n",
       " 149: 'education',\n",
       " 150: 'nonscience student',\n",
       " 151: 'large document',\n",
       " 152: 'indexing tool',\n",
       " 153: 'management technique',\n",
       " 154: 'routledge encyclopedia',\n",
       " 155: 'hypertext',\n",
       " 156: 'multisequential narrative',\n",
       " 157: 'little dorrit',\n",
       " 158: 'allcicch conference',\n",
       " 159: 'art',\n",
       " 160: 'british folklore collection',\n",
       " 161: 'student scholarship',\n",
       " 162: 'citation politics',\n",
       " 163: 'digital book',\n",
       " 164: 'postcolonial and decolonial approach',\n",
       " 165: 'physical rare book',\n",
       " 166: 'digital rare book',\n",
       " 167: 'visualization',\n",
       " 168: 'memory of german pow',\n",
       " 169: 'geographic information system',\n",
       " 170: 'memory culture',\n",
       " 171: 'information science',\n",
       " 172: 'deep neural network',\n",
       " 173: 'decision model',\n",
       " 174: 'indigenous',\n",
       " 175: 'margin group',\n",
       " 176: 'critical study',\n",
       " 177: 'ischool',\n",
       " 178: 'crossdisciplinary',\n",
       " 179: 'journal publication',\n",
       " 180: 'inscription',\n",
       " 181: 'parse and annotate corpus',\n",
       " 182: 'search system',\n",
       " 183: 'metadata',\n",
       " 184: 'political speech',\n",
       " 185: 'epigraph',\n",
       " 186: 'intertextual connection',\n",
       " 187: 'digital representation',\n",
       " 188: 'modernist study',\n",
       " 189: 'public humanity',\n",
       " 190: 'journal of cinema and medium study',\n",
       " 191: 'historic inequity',\n",
       " 192: 'humanitarian',\n",
       " 193: 'digitisation',\n",
       " 194: 'sovereign power',\n",
       " 195: 'digital sovereignty',\n",
       " 196: 'art and architectural history',\n",
       " 197: 'shanghai memory',\n",
       " 198: 'city history',\n",
       " 199: 'crowdsourcing',\n",
       " 200: 'motivation model',\n",
       " 201: 'psychologicalsociological model',\n",
       " 202: 'information mapping',\n",
       " 203: 'disinformation identify',\n",
       " 204: 'textual analysis',\n",
       " 205: 'digital documentation',\n",
       " 206: 'visualisation',\n",
       " 207: 'human digitalities',\n",
       " 208: 'occupational gender segregation',\n",
       " 209: 'language without gender',\n",
       " 210: 'gendered language',\n",
       " 211: 'textual analytics',\n",
       " 212: 'machine',\n",
       " 213: 'anthropocene',\n",
       " 214: 'archival document',\n",
       " 215: 'engineering historical memory',\n",
       " 216: 'social network analysis',\n",
       " 217: 'literary communication network',\n",
       " 218: 'cultural leverage',\n",
       " 219: 'poetry community',\n",
       " 220: 'environmental history',\n",
       " 221: 'environmental science',\n",
       " 222: 'heterogeneous text corpus',\n",
       " 223: 'digital history',\n",
       " 224: 'control vocabulary',\n",
       " 225: 'opensource data',\n",
       " 226: 'biographical profile',\n",
       " 227: 'freedom narrative',\n",
       " 228: 'streetonomics',\n",
       " 229: 'cultural quantification',\n",
       " 230: 'society value system',\n",
       " 231: 'conceptual model',\n",
       " 232: 'multimodal thesis and dissertation',\n",
       " 233: 'artificial intelligence',\n",
       " 234: 'crisisintervention',\n",
       " 235: 'paradise lose',\n",
       " 236: 'difference examing',\n",
       " 237: 'text annotation',\n",
       " 238: 'comedias sueltas usa',\n",
       " 239: 'sueltas',\n",
       " 240: 'special collection librarianship',\n",
       " 241: 'geolinguistic diversity',\n",
       " 242: 'language indifference',\n",
       " 243: 'face detection',\n",
       " 244: 'cluster analysis',\n",
       " 245: 'historical personage',\n",
       " 246: 'social relationship',\n",
       " 247: 'digital scholarly edition',\n",
       " 248: 'archive',\n",
       " 249: 'recontextualisation',\n",
       " 250: 'share task',\n",
       " 251: 'blaketint',\n",
       " 252: 'book history',\n",
       " 253: 'color analysis',\n",
       " 254: 'music',\n",
       " 255: 'new medium',\n",
       " 256: 'viral medium',\n",
       " 257: 'ethic',\n",
       " 258: 'ancient china',\n",
       " 259: 'humanist',\n",
       " 260: 'china',\n",
       " 261: 'digital academic competence',\n",
       " 262: 'ground theory',\n",
       " 263: 'competence evaluation indicator system',\n",
       " 264: 'database development',\n",
       " 265: 'text mining',\n",
       " 266: 'chinese local private document',\n",
       " 267: 'historical philology',\n",
       " 268: 'education  datasets',\n",
       " 269: 'analytical tool',\n",
       " 270: 'laboratory',\n",
       " 271: 'natural hazard',\n",
       " 272: 'technological system',\n",
       " 273: 'infrastructure',\n",
       " 274: 'historical poetics',\n",
       " 275: 'definition of epic',\n",
       " 276: 'ming dynasty',\n",
       " 277: 'geographical visualization',\n",
       " 278: 'knowledge organization',\n",
       " 279: 'ontology',\n",
       " 280: 'historical event',\n",
       " 281: 'chinese oral memory',\n",
       " 282: 'knowledge linkage',\n",
       " 283: 'hermeneutics',\n",
       " 284: 'algorithm',\n",
       " 285: 'romantic disciplinarity',\n",
       " 286: 'african study',\n",
       " 287: 'culture sustainable development',\n",
       " 288: 'memory map',\n",
       " 289: 'urban memory',\n",
       " 290: 'knowledge map',\n",
       " 291: 'beijing city gate',\n",
       " 292: 'evolution',\n",
       " 293: 'historical analysis',\n",
       " 294: 'bibliometrics',\n",
       " 295: 'scholarly common',\n",
       " 296: 'beijing normal university',\n",
       " 297: 'historical scholarship',\n",
       " 298: 'digital approach',\n",
       " 299: 'ongoing reward',\n",
       " 300: 'intermediality',\n",
       " 301: 'multivocality',\n",
       " 302: 'multimedia',\n",
       " 303: 'metanarrative analogy',\n",
       " 304: 'neural network',\n",
       " 305: 'holocaust memory',\n",
       " 306: 'sentiment analysis',\n",
       " 307: 'longlived resource',\n",
       " 308: 'interface',\n",
       " 309: 'visual design',\n",
       " 310: 'belgian web',\n",
       " 311: 'web archive strategy',\n",
       " 312: 'digital heritage',\n",
       " 313: 'patentometrics',\n",
       " 314: 'stylistics',\n",
       " 315: 'compute',\n",
       " 316: 'digital assistance',\n",
       " 317: 'cultural asset',\n",
       " 318: 'human right',\n",
       " 319: 'audio archive',\n",
       " 320: 'brazilian chamber of deputy',\n",
       " 321: 'university archive',\n",
       " 322: 'historical record',\n",
       " 323: 'dig into data',\n",
       " 324: 'data management',\n",
       " 325: 'semistructured interview',\n",
       " 326: 'geovisualization',\n",
       " 327: 'museum',\n",
       " 328: 'soft power',\n",
       " 329: 'evaluation framework',\n",
       " 330: 'hebrew literature',\n",
       " 331: 'text encoding',\n",
       " 332: 'misconception',\n",
       " 333: 'language pattern',\n",
       " 334: 'word embed',\n",
       " 335: 'machine learning',\n",
       " 336: 'close reading',\n",
       " 337: 'distant reading',\n",
       " 338: 'origin',\n",
       " 339: 'online digital object',\n",
       " 340: 'persistence',\n",
       " 341: 'shelf life',\n",
       " 342: 'coptic',\n",
       " 343: 'optical character recognition',\n",
       " 344: 'print text',\n",
       " 345: 'program diagnostics',\n",
       " 346: 'correctness  coherence',\n",
       " 347: 'historical document',\n",
       " 348: 'quantitative analysis',\n",
       " 349: 'large visual corpus',\n",
       " 350: 'semantic metadata',\n",
       " 351: 'distant viewing',\n",
       " 352: 'interpretability',\n",
       " 353: 'publish material',\n",
       " 354: 'predigital period',\n",
       " 355: 'place concept',\n",
       " 356: 'information system',\n",
       " 357: 'geographically intelligent system',\n",
       " 358: 'medical history',\n",
       " 359: 'author verification',\n",
       " 360: 'topic modeling',\n",
       " 361: 'lsi',\n",
       " 362: 'digitize humanity',\n",
       " 363: 'numerical humanity',\n",
       " 364: 'humanity of the digital',\n",
       " 365: 'technical labor',\n",
       " 366: 'information institution',\n",
       " 367: 'digitization',\n",
       " 368: 'publishing praxis',\n",
       " 369: 'classroom reflect',\n",
       " 370: 'network analysis',\n",
       " 371: 'science history',\n",
       " 372: 'computational method',\n",
       " 373: 'historical profession',\n",
       " 374: 'information infrastructure',\n",
       " 375: 'information barrier',\n",
       " 376: 'immigrant worker',\n",
       " 377: 'korean',\n",
       " 378: 'news reporting',\n",
       " 379: 'critical discourse analysis',\n",
       " 380: 'cooccurrence analysis',\n",
       " 381: 'medical heritage library',\n",
       " 382: 'art history',\n",
       " 383: 'public open collaborative creation',\n",
       " 384: 'collaborative authorship',\n",
       " 385: 'picture',\n",
       " 386: 'light condition',\n",
       " 387: 'last supper',\n",
       " 388: 'intellectual property right',\n",
       " 389: 'creative common',\n",
       " 390: 'academic librarian',\n",
       " 391: 'apply science',\n",
       " 392: 'voyant tool',\n",
       " 393: 'faculty research',\n",
       " 394: 'word pattern',\n",
       " 395: 'agricultural communication',\n",
       " 396: 'digital',\n",
       " 397: 'computer graphic',\n",
       " 398: 'poland',\n",
       " 399: 'history',\n",
       " 400: 'linguistics',\n",
       " 401: 'data warehouse',\n",
       " 402: 'critical digital humanity',\n",
       " 403: 'capitalism',\n",
       " 404: 'mixedmethods',\n",
       " 405: 'assemblage',\n",
       " 406: 'postcolonial theory',\n",
       " 407: 'digital humanity  machine learning',\n",
       " 408: 'big data',\n",
       " 409: 'cognitive process',\n",
       " 410: 'early modern',\n",
       " 411: 'cultural activity map',\n",
       " 412: 'cultural figure network',\n",
       " 413: 'spatial humanity',\n",
       " 414: 'openness',\n",
       " 415: 'victorian',\n",
       " 416: 'statistic',\n",
       " 417: 'scholar collaboration',\n",
       " 418: 'periodical study',\n",
       " 419: 'emigre periodical',\n",
       " 420: 'culture',\n",
       " 421: 'graphical environment',\n",
       " 422: 'nonrepresentational approach',\n",
       " 423: 'model interpretation',\n",
       " 424: 'digital infrastructure',\n",
       " 425: 'humlabx',\n",
       " 426: 'collection',\n",
       " 427: 'database',\n",
       " 428: 'digital literary',\n",
       " 429: 'mexico',\n",
       " 430: 'digital carework',\n",
       " 431: 'diversity work',\n",
       " 432: 'affective labor',\n",
       " 433: 'selfrepresentation',\n",
       " 434: 'syrian refugee',\n",
       " 435: 'selfie',\n",
       " 436: 'news medium representation',\n",
       " 437: 'historical lexicography',\n",
       " 438: 'text study',\n",
       " 439: 'app',\n",
       " 440: 'satisfaction',\n",
       " 441: 'augment reality',\n",
       " 442: 'computer vision',\n",
       " 443: 'hieroglyph',\n",
       " 444: 'hoosc',\n",
       " 445: 'multimodal research',\n",
       " 446: 'online user behaviour',\n",
       " 447: 'news consumption pattern',\n",
       " 448: 'dialogism',\n",
       " 449: 'spoken language',\n",
       " 450: 'grammatical feature',\n",
       " 451: 'computational model',\n",
       " 452: 'knowledge creation',\n",
       " 453: 'recommender system',\n",
       " 454: 'deep learning',\n",
       " 455: 'lemmatization',\n",
       " 456: 'temporal convolution',\n",
       " 457: 'word embeddings',\n",
       " 458: 'public engagement',\n",
       " 459: 'digital technology',\n",
       " 460: 'rethink humanity',\n",
       " 461: 'textuality',\n",
       " 462: 'research library',\n",
       " 463: 'digital pedagogy',\n",
       " 464: 'acrl',\n",
       " 465: 'academic library',\n",
       " 466: 'partnership model',\n",
       " 467: 'online academic library',\n",
       " 468: 'information need',\n",
       " 469: 'data analysis tool',\n",
       " 470: 'digitization of ticket receipt',\n",
       " 471: 'community interaction',\n",
       " 472: 'science concept',\n",
       " 473: 'data',\n",
       " 474: 'digital curation',\n",
       " 475: 'innovation',\n",
       " 476: 'dialectology',\n",
       " 477: 'journal editor',\n",
       " 478: 'publish program',\n",
       " 479: 'geography',\n",
       " 480: 'global vision',\n",
       " 481: 'local definition',\n",
       " 482: 'russian folktale',\n",
       " 483: 'propplearner',\n",
       " 484: 'formalist theory',\n",
       " 485: 'deep annotation',\n",
       " 486: 'small language',\n",
       " 487: 'digital divide',\n",
       " 488: 'repository',\n",
       " 489: 'encyclopedia',\n",
       " 490: 'religious cultural history',\n",
       " 491: 'r package',\n",
       " 492: 'computational social science',\n",
       " 493: 'open data',\n",
       " 494: 'video record',\n",
       " 495: 'motion analysis',\n",
       " 496: 'information work',\n",
       " 497: 'research through design',\n",
       " 498: 'ngram corpus',\n",
       " 499: 'political discussion',\n",
       " 500: 'language',\n",
       " 501: 'deliberative communication',\n",
       " 502: 'automatic annotation',\n",
       " 503: 'disambiguation',\n",
       " 504: 'makerspaces',\n",
       " 505: 'entrepreneurship',\n",
       " 506: 'archaeology',\n",
       " 507: 'technical art history',\n",
       " 508: 'conflict',\n",
       " 509: 'thematic research collection',\n",
       " 510: 'decadence',\n",
       " 511: 'feminism',\n",
       " 512: 'gendered reading',\n",
       " 513: 'spanish civil war',\n",
       " 514: 'entomology',\n",
       " 515: 'digital world',\n",
       " 516: 'dissertation requirement',\n",
       " 517: 'social',\n",
       " 518: 'communitiesbased',\n",
       " 519: 'classical geography',\n",
       " 520: 'spatial model',\n",
       " 521: 'genocide',\n",
       " 522: 'incomplete data set',\n",
       " 523: 'emerge data source',\n",
       " 524: 'spectral imaging technology',\n",
       " 525: 'manuscript',\n",
       " 526: 'material feature',\n",
       " 527: 'victorian text',\n",
       " 528: 'open annotation',\n",
       " 529: 'hypothes',\n",
       " 530: 'technopedagogical tool',\n",
       " 531: 'oral data',\n",
       " 532: 'transcribing and comment tool',\n",
       " 533: 'mediumsized and small library',\n",
       " 534: 'discretely purchase',\n",
       " 535: 'database product',\n",
       " 536: 'ancient material',\n",
       " 537: 'technology teach',\n",
       " 538: 'intellectual history',\n",
       " 539: 'museum compute',\n",
       " 540: 'citation segmentation',\n",
       " 541: 'sparse  noisy data',\n",
       " 542: 'markov logic network',\n",
       " 543: 'intertextuality',\n",
       " 544: 'natural language processing',\n",
       " 545: 'semantic analysis',\n",
       " 546: 'essayontology workflow',\n",
       " 547: 'formal method',\n",
       " 548: 'interpretive method',\n",
       " 549: 'generic corpus',\n",
       " 550: 'query',\n",
       " 551: 'annotationtriggered style sheet',\n",
       " 552: 'visual art',\n",
       " 553: 'creative research',\n",
       " 554: 'journal',\n",
       " 555: 'online publication',\n",
       " 556: 'stylometry',\n",
       " 557: 'stylo',\n",
       " 558: 'computational text analysis',\n",
       " 559: 'scalar',\n",
       " 560: 'research university',\n",
       " 561: 'digital publication platform',\n",
       " 562: 'user experience',\n",
       " 563: 'topic model',\n",
       " 564: 'online source',\n",
       " 565: 'historic document',\n",
       " 566: 'academic literacy',\n",
       " 567: 'democracy',\n",
       " 568: 'software development',\n",
       " 569: 'program',\n",
       " 570: 'trading consequence',\n",
       " 571: 'perform art',\n",
       " 572: 'notation',\n",
       " 573: 'annotation',\n",
       " 574: 'denotation',\n",
       " 575: 'textual materiality',\n",
       " 576: 'ecocriticism',\n",
       " 577: 'portuguese literary',\n",
       " 578: 'selfregulation',\n",
       " 579: 'conceptual cluster',\n",
       " 580: 'mobile classroom',\n",
       " 581: 'critical pedagogy',\n",
       " 582: 'material culture',\n",
       " 583: 'entity recognition',\n",
       " 584: 'term extraction',\n",
       " 585: 'unstructured metadata mining',\n",
       " 586: 'digital collection',\n",
       " 587: 'impact assessment',\n",
       " 588: 'method concept',\n",
       " 589: 'methodology',\n",
       " 590: 'prosopography',\n",
       " 591: 'community',\n",
       " 592: 'coword analysis',\n",
       " 593: 'native sovereignty',\n",
       " 594: 'occom',\n",
       " 595: 'medium archaeology',\n",
       " 596: 'archaeological analysis',\n",
       " 597: 'igital memorialization',\n",
       " 598: 'cultural technology',\n",
       " 599: 'aid quilt',\n",
       " 600: 'collaborative creation',\n",
       " 601: 'knowledge engineering',\n",
       " 602: 'territorial intelligence',\n",
       " 603: 'shakespeare',\n",
       " 604: 'digital database',\n",
       " 605: 'microtasking',\n",
       " 606: 'macrotasking',\n",
       " 607: 'collaborative interpretation of text',\n",
       " 608: 'hypertext literature',\n",
       " 609: 'lecture',\n",
       " 610: 'development',\n",
       " 611: 'internationalization',\n",
       " 612: 'geographical diversity',\n",
       " 613: 'linguistic diversity',\n",
       " 614: 'collaborative publication',\n",
       " 615: 'joint publication',\n",
       " 616: 'multiauthored publication',\n",
       " 617: 'digital index',\n",
       " 618: 'open science',\n",
       " 619: 'historic property',\n",
       " 620: 'inventory data',\n",
       " 621: 'aggregation service',\n",
       " 622: 'conceptual reference model',\n",
       " 623: 'oral history',\n",
       " 624: 'rhetorical study',\n",
       " 625: 'cultural economy',\n",
       " 626: 'datadriven analysis and interpreting',\n",
       " 627: 'train initiative',\n",
       " 628: 'text mining software',\n",
       " 629: 'usability',\n",
       " 630: 'preservation',\n",
       " 631: 'ancient architecture',\n",
       " 632: '3d model',\n",
       " 633: 'digital geography',\n",
       " 634: 'baroque art',\n",
       " 635: 'web content',\n",
       " 636: 'semantics augment',\n",
       " 637: 'machineprocessable data',\n",
       " 638: 'semantic annotation',\n",
       " 639: 'publication',\n",
       " 640: 'crosscutting categorization',\n",
       " 641: 'philosophical concept',\n",
       " 642: 'digital resource representation',\n",
       " 643: 'middle age manuscript',\n",
       " 644: 'hypertextual',\n",
       " 645: 'textual criticism',\n",
       " 646: 'digital medium',\n",
       " 647: 'literature',\n",
       " 648: 'encyclopedia  rhetoric',\n",
       " 649: 'european fairy tale',\n",
       " 650: 'gendered representation',\n",
       " 651: 'body',\n",
       " 652: 'handcoded database',\n",
       " 653: 'omputational stylometry',\n",
       " 654: 'psychological profiling',\n",
       " 655: 'author identification',\n",
       " 656: 'personality',\n",
       " 657: 'medieval',\n",
       " 658: 'computerassisted analysis',\n",
       " 659: 'virtual object',\n",
       " 660: 'text',\n",
       " 661: 'text discrete',\n",
       " 662: 'text relationship',\n",
       " 663: 'language representation',\n",
       " 664: 'communicate intent',\n",
       " 665: 'secondary student',\n",
       " 666: 'reading practice',\n",
       " 667: 'digital experience',\n",
       " 668: 'xml markup',\n",
       " 669: 'victorian study',\n",
       " 670: 'institutional structure',\n",
       " 671: 'publication form',\n",
       " 672: 'institutional language',\n",
       " 673: 'content analysis',\n",
       " 674: 'public sector s priority',\n",
       " 675: 'institutional discourse',\n",
       " 676: 'book trade',\n",
       " 677: 'code',\n",
       " 678: 'new positivism',\n",
       " 679: 'historical approach',\n",
       " 680: 'critical epistemology',\n",
       " 681: 'speculative formalism',\n",
       " 682: 'scholarly work',\n",
       " 683: 'digital humanity scholar',\n",
       " 684: 'web',\n",
       " 685: 'new and emerge social medium',\n",
       " 686: 'electronic scholarly edition',\n",
       " 687: 'social edition',\n",
       " 688: 'peer learning',\n",
       " 689: 'public digital humanity',\n",
       " 690: 'collaborative research',\n",
       " 691: 'undergraduate',\n",
       " 692: 'print culture',\n",
       " 693: 'mass culture',\n",
       " 694: 'marginal public',\n",
       " 695: 'attribution',\n",
       " 696: 'ownership',\n",
       " 697: 'heritage',\n",
       " 698: 'google ancient place',\n",
       " 699: 'book corpus',\n",
       " 700: 'location identify',\n",
       " 701: 'geographic clustering',\n",
       " 702: 'sculpture mapping',\n",
       " 703: 'online',\n",
       " 704: 'social medium',\n",
       " 705: 'assemblage theory',\n",
       " 706: 'actornetwork theory',\n",
       " 707: 'archival theory',\n",
       " 708: 'digital historiography',\n",
       " 709: 'computational standard',\n",
       " 710: 'elearning',\n",
       " 711: 'online education',\n",
       " 712: 'social and economic force',\n",
       " 713: 'current role',\n",
       " 714: 'literary computing',\n",
       " 715: 'semiautomatic generate instance',\n",
       " 716: 'literary character representation',\n",
       " 717: 'digital humanity community',\n",
       " 718: 'collaborative approach',\n",
       " 719: 'digital revolution',\n",
       " 720: 'digital humanity  scholar',\n",
       " 721: 'developed market',\n",
       " 722: 'emerge market',\n",
       " 723: 'humanity pedagogy',\n",
       " 724: 'eliteracy training',\n",
       " 725: 'computer mapping',\n",
       " 726: 'cognitive structure',\n",
       " 727: 'border protocol',\n",
       " 728: 'topic map',\n",
       " 729: 'metalanguage',\n",
       " 730: 'collaborative infrastructure',\n",
       " 731: 'data digging',\n",
       " 732: 'oral discourse',\n",
       " 733: 'multiple language',\n",
       " 734: 'citation map',\n",
       " 735: 'a  hci',\n",
       " 736: 'text comparison',\n",
       " 737: 'digital creativity',\n",
       " 738: 'textual scholarship',\n",
       " 739: 'text culture',\n",
       " 740: 'interpretation',\n",
       " 741: 'text encode initiative',\n",
       " 742: 'teach',\n",
       " 743: 'online tutorial',\n",
       " 744: 'implicit assumption',\n",
       " 745: 'data mining',\n",
       " 746: 'humanity scholarship',\n",
       " 747: 'text encoders',\n",
       " 748: 'xmlbased repository',\n",
       " 749: 'linguistic knowledge',\n",
       " 750: 'sentiment lexicon',\n",
       " 751: 'sentiment term classification',\n",
       " 752: 'sentiment term extraction',\n",
       " 753: 'cultural analytics',\n",
       " 754: 'language of art',\n",
       " 755: 'crepč central register of publication activity',\n",
       " 756: 'research area classification',\n",
       " 757: 'research organisation',\n",
       " 758: 'research project',\n",
       " 759: 'research result',\n",
       " 760: 'researcher',\n",
       " 761: 'current research information system',\n",
       " 762: 'web of science core collection',\n",
       " 763: 'action recognitio',\n",
       " 764: 'modify bagofwords',\n",
       " 765: 'prominent camer',\n",
       " 766: 'support vector machine',\n",
       " 767: 'circular graph',\n",
       " 768: 'fuzzy classification',\n",
       " 769: 'mental map',\n",
       " 770: 'naive geography',\n",
       " 771: 'pattern match',\n",
       " 772: 'visual analytics',\n",
       " 773: 'connect europe facility  cef',\n",
       " 774: 'digital preservation',\n",
       " 775: 'earchiving',\n",
       " 776: 'fair principle',\n",
       " 777: 'bidirectional lstm',\n",
       " 778: 'convolutional neural network',\n",
       " 779: 'dictionary',\n",
       " 780: 'levenshteindistance',\n",
       " 781: 'climate crisis',\n",
       " 782: 'decarbonization',\n",
       " 783: 'energy democracy',\n",
       " 784: 'energy justice',\n",
       " 785: 'equity',\n",
       " 786: 'automatic generation',\n",
       " 787: 'creative computing',\n",
       " 788: 'creativity rule',\n",
       " 789: 'filmstory creation',\n",
       " 790: 'humanlike scriptwriting',\n",
       " 791: 'elearning system',\n",
       " 792: 'education research',\n",
       " 793: 'educational data mining',\n",
       " 794: 'interactive learning environment',\n",
       " 795: 'learn analytics',\n",
       " 796: 'learn management system',\n",
       " 797: 'soft compute',\n",
       " 798: 'systematic literature review',\n",
       " 799: 'argumentation analysis',\n",
       " 800: 'discourse analysis',\n",
       " 801: 'information reuse',\n",
       " 802: 'information visualization',\n",
       " 803: 'software assistance',\n",
       " 804: 'viscourse',\n",
       " 805: 'crosslinguistic distant reading',\n",
       " 806: 'embodied ontology',\n",
       " 807: 'flat logic',\n",
       " 808: 'literary repetition',\n",
       " 809: 'psychodramatic effect',\n",
       " 810: 'textual surface',\n",
       " 811: 'thick compute',\n",
       " 812: 'translation',\n",
       " 813: 'health and medical data',\n",
       " 814: 'international data protection',\n",
       " 815: 'organ donation',\n",
       " 816: 'patient record',\n",
       " 817: 'postmortem privacy',\n",
       " 818: 'posthumous medical data donation',\n",
       " 819: 'core research cluster of disaster science planning session',\n",
       " 820: 'disaster medicine',\n",
       " 821: 'disaster preparedness',\n",
       " 822: 'train program',\n",
       " 823: 'world bosai forum2019',\n",
       " 824: 'genetic editing',\n",
       " 825: 'james joyce',\n",
       " 826: 'scholarly edit',\n",
       " 827: 'bollywood',\n",
       " 828: 'digital necropolitics',\n",
       " 829: 'partition',\n",
       " 830: 'postcolonial study',\n",
       " 831: 'emotion recognition',\n",
       " 832: 'pca',\n",
       " 833: 'prosody',\n",
       " 834: 'recognition rate',\n",
       " 835: 'historical concept',\n",
       " 836: 'information retrieval',\n",
       " 837: 'knowledge retrieval',\n",
       " 838: 'ontologybased knowledge retrieval',\n",
       " 839: 'semantic web',\n",
       " 840: 'apply compute → art and humanity',\n",
       " 841: 'concept and paradigm',\n",
       " 842: 'humancentered compute → visualization',\n",
       " 843: 'visualization theory',\n",
       " 844: 'classical arabic corpus',\n",
       " 845: 'hadith authenticity',\n",
       " 846: 'hadith science',\n",
       " 847: 'hadith text mining',\n",
       " 848: 'islamic knowledge',\n",
       " 849: 'survey',\n",
       " 850: 'digital study',\n",
       " 851: 'informatics',\n",
       " 852: 'korea',\n",
       " 853: 'new frontier',\n",
       " 854: 'technological advance',\n",
       " 855: 'cultural analysis humanity',\n",
       " 856: 'genetic ancestry',\n",
       " 857: 'historical society',\n",
       " 858: 'intersectionality',\n",
       " 859: 'bucknell university',\n",
       " 860: 'liberal art',\n",
       " 861: 'wellesley college',\n",
       " 862: 'domaindriven data mining',\n",
       " 863: 'historical musicology',\n",
       " 864: 'music informatics',\n",
       " 865: 'music information retrieval',\n",
       " 866: 'optical music recognition',\n",
       " 867: 'incentive',\n",
       " 868: 'information asymmetry',\n",
       " 869: 'quality improvement',\n",
       " 870: 'supplier failure',\n",
       " 871: 'citespace',\n",
       " 872: 'digital cultural heritage',\n",
       " 873: 'library and information service',\n",
       " 874: 'visualization analysis',\n",
       " 875: 'vosviewer',\n",
       " 876: 'folktale',\n",
       " 877: 'gm',\n",
       " 878: 'great mekong subregion',\n",
       " 879: 'music librarianship',\n",
       " 880: 'music theory',\n",
       " 881: 'musicology',\n",
       " 882: 'law',\n",
       " 883: 'policy',\n",
       " 884: 'principle of robotics',\n",
       " 885: 'robot',\n",
       " 886: 'blockbased programming',\n",
       " 887: 'computer science education',\n",
       " 888: 'explicit parallel compute',\n",
       " 889: 'language for pdc and hpc',\n",
       " 890: 'parallel computational pattern',\n",
       " 891: 'pedagogical tool',\n",
       " 892: 'program environment',\n",
       " 893: 'visual programming',\n",
       " 894: 'c curriculum',\n",
       " 895: 'parallel and distribute compute',\n",
       " 896: 'alloy',\n",
       " 897: 'corrosion',\n",
       " 898: 'crystallographic structure',\n",
       " 899: 'scan electron microscopy',\n",
       " 900: 'corpus analysis',\n",
       " 901: 'webbased platform',\n",
       " 902: 'context',\n",
       " 903: 'cultural difference',\n",
       " 904: 'fan',\n",
       " 905: 'statistical analysis',\n",
       " 906: 'biblical study',\n",
       " 907: 'canon',\n",
       " 908: 'cultural capital',\n",
       " 909: 'encode',\n",
       " 910: 'marginalia',\n",
       " 911: 'markup',\n",
       " 912: 'religious study',\n",
       " 913: 'theory',\n",
       " 914: 'historical method',\n",
       " 915: 'humanity research and education',\n",
       " 916: 'philology',\n",
       " 917: 'scholarly ethic',\n",
       " 918: 'domain vocabulary',\n",
       " 919: 'hierarchical model',\n",
       " 920: 'image annotation',\n",
       " 921: 'semantic description',\n",
       " 922: 'friend recommendation',\n",
       " 923: 'social network',\n",
       " 924: 'virtual world',\n",
       " 925: 'digital object preservation',\n",
       " 926: 'world wide web',\n",
       " 927: 'decline of humanity',\n",
       " 928: 'compute history',\n",
       " 929: 'software engineering',\n",
       " 930: 'aggadic midrash',\n",
       " 931: 'bible exegesis',\n",
       " 932: 'explanation',\n",
       " 933: 'hebrewaramaic corpus',\n",
       " 934: 'homiletics',\n",
       " 935: 'information extraction',\n",
       " 936: 'question answer',\n",
       " 937: 'rabbinic literature',\n",
       " 938: 'text generation',\n",
       " 939: 'ancient text transcription',\n",
       " 940: 'handwritten text recognition',\n",
       " 941: 'iterative system',\n",
       " 942: 'language modelling',\n",
       " 943: 'multimodal system',\n",
       " 944: 'speech dictation',\n",
       " 945: 'cloud compute',\n",
       " 946: 'dataintensive research',\n",
       " 947: 'highperformance computing',\n",
       " 948: 'infrastructure a a service',\n",
       " 949: 'aurignacian',\n",
       " 950: 'heinrich stadial 4',\n",
       " 951: 'iberian peninsula',\n",
       " 952: 'neanderthal',\n",
       " 953: 'paleoenvironment',\n",
       " 954: 'upper pleistocene',\n",
       " 955: 'amplified reading',\n",
       " 956: 'digital reading',\n",
       " 957: 'ebooks',\n",
       " 958: 'enhance ebooks',\n",
       " 959: 'neurocognitive',\n",
       " 960: 'data integration',\n",
       " 961: 'link data',\n",
       " 962: 'information science history',\n",
       " 963: 'bibliographic system',\n",
       " 964: 'library system',\n",
       " 965: 'acm curriculum design',\n",
       " 966: 'philosophy',\n",
       " 967: 'social psychology',\n",
       " 968: 'methodological common',\n",
       " 969: 'primitive',\n",
       " 970: 'digital archive',\n",
       " 971: 'gcube',\n",
       " 972: 'virtual research environment',\n",
       " 973: 'blogosphere',\n",
       " 974: 'digital method',\n",
       " 975: 'hyperlink analysis',\n",
       " 976: 'internet archive',\n",
       " 977: 'social networking site',\n",
       " 978: 'wikipedia',\n",
       " 979: 'cybercartographic atlas framework',\n",
       " 980: 'cybercartographic atlas',\n",
       " 981: 'cybercartography',\n",
       " 982: 'indigenous mapping',\n",
       " 983: 'iteration',\n",
       " 984: 'theory and practice',\n",
       " 985: 'access grid',\n",
       " 986: 'high performance compute',\n",
       " 987: 'virtual workbench',\n",
       " 988: 'academic staff',\n",
       " 989: 'electronic book',\n",
       " 990: 'monographics',\n",
       " 991: 'communication technology',\n",
       " 992: 'electronic medium',\n",
       " 993: 'humanistic philosophy',\n",
       " 994: 'research',\n",
       " 995: 'science',\n",
       " 996: 'program language curriculum',\n",
       " 997: 'affect',\n",
       " 998: 'information task',\n",
       " 999: 'search pattern',\n",
       " ...}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_dict = dict(zip(nodes_data.index,nodes_data[0]))\n",
    "project_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "58e8c020",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_77044\\168160840.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  otheredge2['source'][i]=project_dict[int(otheredge2['source'][i])]\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_77044\\168160840.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  otheredge2['target'][i]=project_dict[int(otheredge2['target'][i])]\n"
     ]
    }
   ],
   "source": [
    "for i in range (otheredge2.shape[0]):\n",
    "    otheredge2['source'][i]=project_dict[int(otheredge2['source'][i])]\n",
    "    otheredge2['target'][i]=project_dict[int(otheredge2['target'][i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c06deb63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>dot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>semantic enrichment</td>\n",
       "      <td>georeferencing</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>telemedicine</td>\n",
       "      <td>scientific paper visualization</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shape grammar</td>\n",
       "      <td>scientific paper visualization</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eastern europe</td>\n",
       "      <td>collection access</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eastern europe</td>\n",
       "      <td>heritage collection</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>british museum</td>\n",
       "      <td>collection access</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927</th>\n",
       "      <td>digital sociology</td>\n",
       "      <td>textmining</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>autoencoders</td>\n",
       "      <td>wikidata politics</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>interpretive method</td>\n",
       "      <td>wikidata politics</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>provenance</td>\n",
       "      <td>evangelicalism</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1931 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   source                          target  dot\n",
       "0     semantic enrichment                  georeferencing  1.0\n",
       "1            telemedicine  scientific paper visualization  1.0\n",
       "2           shape grammar  scientific paper visualization  1.0\n",
       "3          eastern europe               collection access  1.0\n",
       "4          eastern europe             heritage collection  1.0\n",
       "...                   ...                             ...  ...\n",
       "1926       british museum               collection access  1.0\n",
       "1927    digital sociology                      textmining  1.0\n",
       "1928         autoencoders               wikidata politics  1.0\n",
       "1929  interpretive method               wikidata politics  1.0\n",
       "1930           provenance                  evangelicalism  1.0\n",
       "\n",
       "[1931 rows x 3 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otheredge2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bd98d172",
   "metadata": {},
   "outputs": [],
   "source": [
    "otheredge2.to_csv('E:\\\\GraphSAGE\\\\Scopus_2022_9_21_1\\\\result\\\\topic_otheredge_sort_noselfcircle3_4.csv',sep=',',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1ed169c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "def plot_training_stats(title, losses, test_auc, test_ap, train_auc, train_ap):\n",
    "    \"\"\"\n",
    "    绘制训练过程中损失和性能指标的变化\n",
    "    \n",
    "    Args\n",
    "    ---- \n",
    "    losses, test_auc, test_ap, train_auc, train_ap: 训练过程的输出列表\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    ax2 = ax.twinx()\n",
    "\n",
    "    ax.set_xlabel(\"Training Epochs\")\n",
    "    ax2.set_ylabel(\"Performance Metric\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "\n",
    "    plt.title(title)\n",
    "    p1, = ax.plot(losses, \"b-\", label=\"training loss\")\n",
    "    p2, = ax2.plot(test_auc, \"r-\", label=\"test AUC\")\n",
    "    p3, = ax2.plot(test_ap, \"g-\", label=\"test AP\")\n",
    "    p4, = ax2.plot(train_auc, \"o-\", label=\"train AUC\")\n",
    "    p5, = ax2.plot(train_ap, \"v-\", label=\"train AP\")\n",
    "    plt.legend(handles=[p1, p2, p3, p4, p5])\n",
    "    plt.show()\n",
    "\n",
    "plot_training_stats('GAE', losses, test_auc, test_ap, train_aucs, train_aps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429f0764",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch]",
   "language": "python",
   "name": "conda-env-.conda-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
